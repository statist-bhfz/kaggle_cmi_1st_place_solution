{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aef47a-4008-4677-9190-2e18ca9c6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5458eb2-5527-4f3e-b6ba-d09d669e7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../input/cmi-detect-behavior-with-sensor-data/\"\n",
    "OUTPUT_DIR = \"../../models/debug/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042e9699-6714-479c-94bb-5d2e4681607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle missing values in quaternion data intelligently\n",
    "    \n",
    "    Key insight: Quaternions must have unit length |q| = 1\n",
    "    If one component is missing, we can reconstruct it from the others\n",
    "    \"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            # No missing values, normalize to unit quaternion\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]  # Identity quaternion\n",
    "                \n",
    "        elif missing_count == 1:\n",
    "            # One missing value, reconstruct using unit quaternion constraint\n",
    "            # |w|² + |x|² + |y|² + |z|² = 1\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            \n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                # Choose sign for continuity with previous quaternion\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            # More than one missing value, use identity quaternion\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/10): # Assuming 10Hz sampling rate\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "def preprocess_left_handed(l_tr):\n",
    "    rot_cleaned = handle_quaternion_missing_values(l_tr[[\"rot_w\",\"rot_x\", \"rot_y\", \"rot_z\"]].to_numpy())\n",
    "    rot_scipy = rot_cleaned[:, [1, 2, 3, 0]]\n",
    "    \n",
    "    norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "    if np.any(norms < 1e-8):\n",
    "        # Replace problematic quaternions with identity\n",
    "        mask = norms < 1e-8\n",
    "        rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n",
    "        print(\"yes\")\n",
    "    \n",
    "    r = R.from_quat(rot_scipy)\n",
    "    tmp = r.as_euler(\"xyz\")\n",
    "    tmp[:,1] = - tmp[:,1]\n",
    "    tmp[:,2] = - tmp[:,2]\n",
    "    r = R.from_euler(\"xyz\", tmp)\n",
    "    tmp = r.as_quat()\n",
    "    l_tr = l_tr.with_columns(pl.DataFrame(tmp, schema=[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]))\n",
    "    l_tr = l_tr.with_columns(-pl.col(\"acc_x\"))\n",
    "    \n",
    "    tmp = l_tr[[\"thm_3\", \"thm_5\"]]\n",
    "    tmp.columns = [\"thm_5\", \"thm_3\"]\n",
    "    l_tr = l_tr.with_columns(tmp)\n",
    "    \n",
    "    swap_1_2_4_base = [[0,7],[1,6],[2,5],[3,4], [4,3], [5,2],[6,1],[7,0]]\n",
    "    swap_3_5_base = [[0,56],[8,48],[16,40], [24,32],[32,24], [40,16],[48,8], [56,0]]\n",
    "    \n",
    "    swap_1_2_4 = list()\n",
    "    for i in range(0,64,8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_1_2_4_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_1_2_4 += ll\n",
    "    \n",
    "    swap_3_5 = list()\n",
    "    for i in range(8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_3_5_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_3_5 += ll\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[k].alias(l))\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[l].alias(k))\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for i in [1,2,4]:\n",
    "        for (k, l) in swap_1_2_4:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    \n",
    "    for i in [3,5]:\n",
    "        for (k, l) in swap_3_5:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    return l_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ff7b95-5613-401b-92a5-739f80d95a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3844748d-8fcd-4d2a-bb06-6d6a97d4fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede65d5-d4f6-436e-8bdf-c3a4e336eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pl.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n",
    "no_gesture = 'SEQ_011975'\n",
    "tr = tr.filter(pl.col(\"sequence_id\") != no_gesture)\n",
    "\n",
    "#null_seqs = pl.read_csv(\"../input/null_seqs.csv\")\n",
    "#tr = tr.filter(~pl.col(\"sequence_id\").is_in(null_seqs[:,0].implode()))\n",
    "\n",
    "demo = pl.read_csv(os.path.join(INPUT_DIR,\"train_demographics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b126b7-b35b-45ba-9497-1e2bf12cf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_subjs = demo.filter(pl.col(\"handedness\") == 1)[\"subject\"].to_list()\n",
    "l_subjs = demo.filter(pl.col(\"handedness\") == 0)[\"subject\"].to_list()\n",
    "\n",
    "r_subjs.remove(\"SUBJ_019262\") # these subjects wore the device on the wrong side of the wrist and score worse then left handers.\n",
    "r_subjs.remove(\"SUBJ_045235\") # further, tof and thm are probably not salvagable, but maybe imu can be adjusted, could look into later\n",
    "\n",
    "r_new = tr.filter(pl.col(\"subject\").is_in(r_subjs))\n",
    "l_new = tr.filter(pl.col(\"subject\").is_in(l_subjs))\n",
    "\n",
    "l_new = preprocess_left_handed(l_new)\n",
    "    \n",
    "tr = pl.concat([r_new, l_new])\n",
    "tr = tr.sort(by=\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e40d59-0fce-40a7-9685-c3d124c02f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tr.filter(pl.col(\"sequence_counter\") ==0)[:,[\"sequence_id\", \"subject\",\"gesture\"]]\n",
    "labels = labels.sort(by=\"gesture\")\n",
    "label_encoder = LabelEncoder()\n",
    "labels = labels.with_columns(pl.Series(label_encoder.fit_transform(labels[\"gesture\"])).alias(\"gesture\"))\n",
    "oh_encoder = OneHotEncoder()\n",
    "onehotted = oh_encoder.fit_transform(pl.DataFrame(labels[\"gesture\"])).toarray()\n",
    "onehotted = pl.DataFrame(onehotted, orient=\"row\", schema=label_encoder.classes_.tolist())\n",
    "labels = labels.hstack(onehotted)\n",
    "labels_df = labels.sort(by=\"sequence_id\")\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR,\"encoder.pkl\"), \"wb\") as f:\n",
    "    dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55199cc-f9cb-44dc-86d3-4eb0d9f50143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for (idx, df) in tr.group_by(\"sequence_id\", maintain_order = True):\n",
    "    df = df.with_columns(pl.col(\"acc_x\").diff().alias(\"diff_x\"))\n",
    "    df = df.with_columns(pl.col(\"acc_y\").diff().alias(\"diff_y\"))\n",
    "    df = df.with_columns(pl.col(\"acc_z\").diff().alias(\"diff_z\"))\n",
    "    df = df.with_columns((pl.col(\"acc_x\").pow(2) + pl.col(\"acc_y\").pow(2) + pl.col(\"acc_z\").pow(2)).sqrt().alias(\"mag\"))\n",
    "    df = df.with_columns((2*pl.col(\"rot_w\").arccos()).alias(\"angle\"))\n",
    "    \n",
    "    ang_vel = calculate_angular_velocity_from_quat(df)\n",
    "    ang_dist = calculate_angular_distance(df)\n",
    "    df = df.with_columns(pl.DataFrame(ang_vel, schema=[\"ang_vel_x\", \"ang_vel_y\", \"ang_vel_z\"]))\n",
    "    df = df.with_columns(pl.Series(ang_dist).alias(\"ang_dist\"))\n",
    "    \n",
    "    dfs.append(df)\n",
    "tr = pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a057e43-24bb-4b97-b34a-72fae33975c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c583c685-b8e3-49e0-bc26-f37dcd7007dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_cols = [\"acc_x\",\"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "diff_cols = [\"diff_x\", \"diff_y\", \"diff_z\"]\n",
    "extra_imu = [\"mag\", \"angle\"]\n",
    "extra_extra_imu = [\"ang_vel_x\", \"ang_vel_y\", \"ang_vel_z\", \"ang_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8000898e-178a-422e-88b9-2c9ae58618c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = imu_cols+diff_cols + extra_imu + extra_extra_imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45abf977-704c-41a4-96fc-aa6de4d5d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac2425b-0518-410c-a474-141c9a0a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(tr_df, labels_df, target_cols, scaler):\n",
    "\n",
    "    tr_df = tr_df.with_columns(pl.col(target_cols).replace([float(\"inf\"), float(\"-inf\"), float(\"nan\")], None))\n",
    "    scaled = pl.DataFrame(scaler.fit_transform(tr_df[target_cols]), schema=target_cols)\n",
    "    tr_df = tr_df.with_columns(scaled)\n",
    "    \n",
    "    tr_df = tr_df.with_columns(pl.col(target_cols).replace([float(\"inf\"), float(\"-inf\"), float(\"nan\")], None))\n",
    "    tr_df =tr_df.fill_null(0)\n",
    "    \n",
    "    seq_length = 128\n",
    "    x_tr = np.zeros((tr_df.filter(pl.col(\"sequence_counter\")  == 0).shape[0], len(target_cols), seq_length))\n",
    "    for e, (idx, df) in enumerate(tr_df.group_by(\"sequence_id\", maintain_order=True)):\n",
    "        x_tr[e, :,-df.shape[0]:] = df[target_cols].to_numpy()[-seq_length:,:].T\n",
    "    \n",
    "    y_tr = labels_df[:,3:].to_numpy()\n",
    "    \n",
    "    return x_tr, y_tr, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd04d34b-b340-4943-a825-c058e267a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, noise_factor=120):\n",
    "        self.data = data\n",
    "        self.targets = torch.Tensor(targets)\n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        if self.noise_factor:\n",
    "            r = np.random.rand(x.shape[0], x.shape[1])/self.noise_factor - 1/(2*self.noise_factor)\n",
    "            x = x+r\n",
    "            x = x.astype(np.float32)\n",
    "        \n",
    "        r = np.random.uniform(0.75,1.5)\n",
    "        x[:3,:] = x[:3,:]*r\n",
    "        x[7:,:] = x[7:,:]*r\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class TestTimeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = torch.Tensor(targets)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94d9519-0adc-4814-af35-971b0e3f03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.res_layer = torch.nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=\"same\")\n",
    "        else:\n",
    "            self.res_layer = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        if self.res_layer is None:\n",
    "            x = torch.add(x, res)\n",
    "        else: \n",
    "            x = torch.add(x, self.res_layer(res))\n",
    "        return x \n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualBlockSE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.se = SEBlock(out_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.res_layer = nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=\"same\")\n",
    "            self.res_bn = nn.BatchNorm1d(out_channels)\n",
    "        else:\n",
    "            self.res_layer = None\n",
    "            self.res_bn = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.se(x)\n",
    "        if self.res_layer is None:\n",
    "            x = torch.add(x, res)\n",
    "        else: \n",
    "            x = torch.add(x, self.res_bn(self.res_layer(res)))\n",
    "        x = F.relu(x)\n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c7cd80-0e5b-4644-80e1-b35a172390c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " class RNNet(nn.Module):\n",
    "    def __init__(self, chan=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block0_0 = ResidualBlock(4, chan,3)\n",
    "        self.block0_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block0_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block1_0 = ResidualBlock(5, chan,3)\n",
    "        self.block1_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block1_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block2_0 = ResidualBlock(3, chan,3)\n",
    "        self.block2_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block2_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block3_0 = ResidualBlock(4, chan,3)\n",
    "        self.block3_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block3_2 = ResidualBlock(chan, chan, 3)\n",
    "        \n",
    "        self.rnn = nn.GRU(4*chan, 128,\n",
    "            num_layers = 2, \n",
    "            batch_first =True,\n",
    "            bidirectional=True)\n",
    "\n",
    "        self.fc0 = nn.Linear(256, 256)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(256, 18)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        in1 = torch.cat([x[:,:3,:], x[:,10:11,:]], dim=1)\n",
    "        in2 = torch.cat([x[:,3:7,:], x[:,11:12,:]], dim=1)\n",
    "        in3 = x[:,7:10,:]\n",
    "        in4 = x[:,12:,:]\n",
    "        x0 = self.block0_2(self.block0_1(self.block0_0(in1)))\n",
    "        x1 = self.block1_2(self.block1_1(self.block1_0(in2)))\n",
    "        x2 = self.block2_2(self.block2_1(self.block2_0(in3)))\n",
    "        x3 = self.block3_2(self.block3_1(self.block3_0(in4)))\n",
    "        \n",
    "        x = torch.cat([x0,x1,x2,x3], dim=1)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x,_ = self.rnn(x)\n",
    "        x = self.drop(F.relu(self.fc0(x)))\n",
    "        x = self.fc1(x)\n",
    "        x = x[:,-30:,:].mean(axis=1)\n",
    "        return x \n",
    "\n",
    " class RNNetSE(nn.Module):\n",
    "    def __init__(self, chan=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block0_0 = ResidualBlockSE(4, chan,3)\n",
    "        self.block0_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block0_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block1_0 = ResidualBlockSE(5, chan,3)\n",
    "        self.block1_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block1_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block2_0 = ResidualBlockSE(3, chan,3)\n",
    "        self.block2_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block2_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block3_0 = ResidualBlockSE(4, chan,3)\n",
    "        self.block3_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block3_2 = ResidualBlockSE(chan, chan, 3)\n",
    "        \n",
    "        self.rnn = nn.GRU(4*chan, 128,\n",
    "            num_layers = 2, \n",
    "            batch_first =True,\n",
    "            bidirectional=True)\n",
    "\n",
    "        self.fc0 = nn.Linear(256, 256)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(256, 18)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        in1 = torch.cat([x[:,:3,:], x[:,10:11,:]], dim=1)\n",
    "        in2 = torch.cat([x[:,3:7,:], x[:,11:12,:]], dim=1)\n",
    "        in3 = x[:,7:10,:]\n",
    "        in4 = x[:,12:,:]\n",
    "        x0 = self.block0_2(self.block0_1(self.block0_0(in1)))\n",
    "        x1 = self.block1_2(self.block1_1(self.block1_0(in2)))\n",
    "        x2 = self.block2_2(self.block2_1(self.block2_0(in3)))\n",
    "        x3 = self.block3_2(self.block3_1(self.block3_0(in4)))\n",
    "        \n",
    "        x = torch.cat([x0,x1,x2,x3], dim=1)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x,_ = self.rnn(x)\n",
    "        x = self.drop(F.relu(self.fc0(x)))\n",
    "        x = self.fc1(x)\n",
    "        x = x[:,-30:,:].mean(axis=1)\n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,n_blocks=2, chan=64, kern=5, kern_increase=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block0_0 = ResidualBlock(4, chan,3)\n",
    "        self.block0_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block0_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block1_0 = ResidualBlock(5, chan,3)\n",
    "        self.block1_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block1_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block2_0 = ResidualBlock(3, chan,3)\n",
    "        self.block2_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block2_2 = ResidualBlock(chan, chan, 3)\n",
    "\n",
    "        self.block3_0 = ResidualBlock(4, chan,3)\n",
    "        self.block3_1 = ResidualBlock(chan, chan,3)\n",
    "        self.block3_2 = ResidualBlock(chan, chan, 3)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_blocks+1):\n",
    "            if i == 0:\n",
    "                self.layers.append(ResidualBlock(4*chan, 4*chan,kern))\n",
    "            else:\n",
    "                self.layers.append(ResidualBlock((4*chan)*2**((i-1)//2), (4*chan)*2**(i//2),kern+kern_increase*i))\n",
    "        self.pool = nn.MaxPool1d(2,2)  \n",
    "        self.fc0 = nn.Linear((4*chan)*2**(i//2), 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in1 = torch.cat([x[:,:3,:], x[:,10:11,:]], dim=1)\n",
    "        in2 = torch.cat([x[:,3:7,:], x[:,11:12,:]], dim=1)\n",
    "        in3 = x[:,7:10,:]\n",
    "        in4 = x[:,12:,:]\n",
    "        x0 = self.block0_2(self.block0_1(self.block0_0(in1)))\n",
    "        x1 = self.block1_2(self.block1_1(self.block1_0(in2)))\n",
    "        x2 = self.block2_2(self.block2_1(self.block2_0(in3)))\n",
    "        x3 = self.block3_2(self.block3_1(self.block3_0(in4)))\n",
    "        \n",
    "        x = torch.cat([x0,x1,x2,x3], dim=1)\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            x = self.pool(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        x = torch.mean(x, dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        return x \n",
    "\n",
    "class NetSE(nn.Module):\n",
    "    def __init__(self,n_blocks=2, chan=64, kern=5, kern_increase=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block0_0 = ResidualBlockSE(4, chan,3)\n",
    "        self.block0_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block0_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block1_0 = ResidualBlockSE(5, chan,3)\n",
    "        self.block1_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block1_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block2_0 = ResidualBlockSE(3, chan,3)\n",
    "        self.block2_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block2_2 = ResidualBlockSE(chan, chan, 3)\n",
    "\n",
    "        self.block3_0 = ResidualBlockSE(4, chan,3)\n",
    "        self.block3_1 = ResidualBlockSE(chan, chan,3)\n",
    "        self.block3_2 = ResidualBlockSE(chan, chan, 3)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_blocks+1):\n",
    "            if i == 0:\n",
    "                self.layers.append(ResidualBlockSE(4*chan, 4*chan,kern))\n",
    "            else:\n",
    "                self.layers.append(ResidualBlockSE((4*chan)*2**((i-1)//2), (4*chan)*2**(i//2),kern+kern_increase*i))\n",
    "        self.pool = nn.MaxPool1d(2,2)  \n",
    "        self.fc0 = nn.Linear((4*chan)*2**(i//2), 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in1 = torch.cat([x[:,:3,:], x[:,10:11,:]], dim=1)\n",
    "        in2 = torch.cat([x[:,3:7,:], x[:,11:12,:]], dim=1)\n",
    "        in3 = x[:,7:10,:]\n",
    "        in4 = x[:,12:,:]\n",
    "        x0 = self.block0_2(self.block0_1(self.block0_0(in1)))\n",
    "        x1 = self.block1_2(self.block1_1(self.block1_0(in2)))\n",
    "        x2 = self.block2_2(self.block2_1(self.block2_0(in3)))\n",
    "        x3 = self.block3_2(self.block3_1(self.block3_0(in4)))\n",
    "        \n",
    "        x = torch.cat([x0,x1,x2,x3], dim=1)\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            x = self.pool(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        x = torch.mean(x, dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        return x \n",
    "\n",
    "# https://www.kaggle.com/code/takoihiraokazu/cv-ensemble-sub-0607-1\n",
    "class RnnModelImu(nn.Module):\n",
    "    def __init__(\n",
    "        self, dropout=0.2,\n",
    "        input_numerical_size=16,\n",
    "        numeraical_linear_size = 128,\n",
    "        model_size = 128,\n",
    "        linear_out = 128,\n",
    "        out_size=18):\n",
    "        super(RnnModelImu, self).__init__()\n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.linear_out  = nn.Sequential(\n",
    "                nn.Linear(model_size*2, \n",
    "                          linear_out),\n",
    "                nn.LayerNorm(linear_out),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(linear_out, \n",
    "                          out_size))\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, numerical_array):\n",
    "        numerical_array = numerical_array.permute(0, 2, 1)\n",
    "        numerical_embedding = self.numerical_linear(numerical_array)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output[:,-30:,:].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06801a2-c37a-4acb-a1ee-ab1d4625b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4689173e-1a80-42bc-b374-e8466a24232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr, scaler = prep_data(tr, labels_df, target_cols, scaler)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR,\"imuonly_scaler.pkl\"), \"wb\") as f:\n",
    "    dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b513b66-551f-4c6a-b9d6-659ab99a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea434179-8a40-4eb8-afa1-22e146344836",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26f9599-0ba1-42a4-8703-dfe12cfcaf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(40):   \n",
    "    net = RNNet().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))\n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(60): \n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_cnngru128_itr{p}\"))\n",
    "    print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b7a42a-43eb-4bc0-8719-4a9e1bb1f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(40):   \n",
    "    net = Net().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))   \n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    itr = 0\n",
    "    for epoch in range(80):\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_cnn64chan_itr{p}\"))\n",
    "    print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac65740-6ebc-4b3e-a053-8dfe85c38cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(40):   \n",
    "    net = RnnModelImu().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))\n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    itr = 0\n",
    "    for epoch in range(60): \n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_densegru_itr{p}\"))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a99e50c9-95d5-4ce1-85c6-ade928d0260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(40):   \n",
    "    net = RNNetSE().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))\n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(60): \n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_cnngru128SE_itr{p}\"))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3a8a4b-1db6-4bb2-a20e-b34eae886a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(40):   \n",
    "    net = NetSE().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))   \n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    itr = 0\n",
    "    for epoch in range(80):\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_cnn64chanSE_itr{p}\"))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05fbd5a6-604f-48f9-bf66-ccd5a0c0f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033852232893308\n"
     ]
    }
   ],
   "source": [
    "print((time.time()-start)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4b8a2-2be9-40dd-b38a-2ec7f3b419fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
