{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aef47a-4008-4677-9190-2e18ca9c6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41db6413-0a1d-4a97-b600-aadddb94b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../input/cmi-detect-behavior-with-sensor-data/\"\n",
    "OUTPUT_DIR = \"../../models/debug/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042e9699-6714-479c-94bb-5d2e4681607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle missing values in quaternion data intelligently\n",
    "    \n",
    "    Key insight: Quaternions must have unit length |q| = 1\n",
    "    If one component is missing, we can reconstruct it from the others\n",
    "    \"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            # No missing values, normalize to unit quaternion\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]  # Identity quaternion\n",
    "                \n",
    "        elif missing_count == 1:\n",
    "            # One missing value, reconstruct using unit quaternion constraint\n",
    "            # |w|² + |x|² + |y|² + |z|² = 1\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            \n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                # Choose sign for continuity with previous quaternion\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            # More than one missing value, use identity quaternion\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/10): # Assuming 10Hz sampling rate\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "def preprocess_left_handed(l_tr):\n",
    "    rot_cleaned = handle_quaternion_missing_values(l_tr[[\"rot_w\",\"rot_x\", \"rot_y\", \"rot_z\"]].to_numpy())\n",
    "    rot_scipy = rot_cleaned[:, [1, 2, 3, 0]]\n",
    "    \n",
    "    norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "    if np.any(norms < 1e-8):\n",
    "        # Replace problematic quaternions with identity\n",
    "        mask = norms < 1e-8\n",
    "        rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n",
    "        print(\"yes\")\n",
    "    \n",
    "    r = R.from_quat(rot_scipy)\n",
    "    tmp = r.as_euler(\"xyz\")\n",
    "    tmp[:,1] = - tmp[:,1]\n",
    "    tmp[:,2] = - tmp[:,2]\n",
    "    r = R.from_euler(\"xyz\", tmp)\n",
    "    tmp = r.as_quat()\n",
    "    l_tr = l_tr.with_columns(pl.DataFrame(tmp, schema=[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]))\n",
    "    l_tr = l_tr.with_columns(-pl.col(\"acc_x\"))\n",
    "    \n",
    "    tmp = l_tr[[\"thm_3\", \"thm_5\"]]\n",
    "    tmp.columns = [\"thm_5\", \"thm_3\"]\n",
    "    l_tr = l_tr.with_columns(tmp)\n",
    "    \n",
    "    swap_1_2_4_base = [[0,7],[1,6],[2,5],[3,4], [4,3], [5,2],[6,1],[7,0]]\n",
    "    swap_3_5_base = [[0,56],[8,48],[16,40], [24,32],[32,24], [40,16],[48,8], [56,0]]\n",
    "    \n",
    "    swap_1_2_4 = list()\n",
    "    for i in range(0,64,8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_1_2_4_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_1_2_4 += ll\n",
    "    \n",
    "    swap_3_5 = list()\n",
    "    for i in range(8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_3_5_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_3_5 += ll\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[k].alias(l))\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[l].alias(k))\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for i in [1,2,4]:\n",
    "        for (k, l) in swap_1_2_4:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    \n",
    "    for i in [3,5]:\n",
    "        for (k, l) in swap_3_5:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    return l_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ff7b95-5613-401b-92a5-739f80d95a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3844748d-8fcd-4d2a-bb06-6d6a97d4fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ede65d5-d4f6-436e-8bdf-c3a4e336eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pl.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n",
    "no_gesture = 'SEQ_011975'\n",
    "tr = tr.filter(pl.col(\"sequence_id\") != no_gesture)\n",
    "\n",
    "#null_seqs = pl.read_csv(\"../input/null_seqs.csv\")\n",
    "#tr = tr.filter(~pl.col(\"sequence_id\").is_in(null_seqs[:,0].implode()))\n",
    "\n",
    "demo = pl.read_csv(os.path.join(INPUT_DIR,\"train_demographics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b126b7-b35b-45ba-9497-1e2bf12cf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_subjs = demo.filter(pl.col(\"handedness\") == 1)[\"subject\"].to_list()\n",
    "l_subjs = demo.filter(pl.col(\"handedness\") == 0)[\"subject\"].to_list()\n",
    "\n",
    "r_subjs.remove(\"SUBJ_019262\") # these subjects wore the device on the wrong side of the wrist and score worse then left handers.\n",
    "r_subjs.remove(\"SUBJ_045235\") # further, tof and thm are probably not salvagable, but maybe imu can be adjusted, could look into later\n",
    "\n",
    "r_new = tr.filter(pl.col(\"subject\").is_in(r_subjs))\n",
    "l_new = tr.filter(pl.col(\"subject\").is_in(l_subjs))\n",
    "\n",
    "l_new = preprocess_left_handed(l_new)\n",
    "    \n",
    "tr = pl.concat([r_new, l_new])\n",
    "tr = tr.sort(by=\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e40d59-0fce-40a7-9685-c3d124c02f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tr.filter(pl.col(\"sequence_counter\") ==0)[:,[\"sequence_id\", \"subject\",\"gesture\"]]\n",
    "labels = labels.sort(by=\"gesture\")\n",
    "label_encoder = LabelEncoder()\n",
    "labels = labels.with_columns(pl.Series(label_encoder.fit_transform(labels[\"gesture\"])).alias(\"gesture\"))\n",
    "oh_encoder = OneHotEncoder()\n",
    "onehotted = oh_encoder.fit_transform(pl.DataFrame(labels[\"gesture\"])).toarray()\n",
    "onehotted = pl.DataFrame(onehotted, orient=\"row\", schema=label_encoder.classes_.tolist())\n",
    "labels = labels.hstack(onehotted)\n",
    "labels_df = labels.sort(by=\"sequence_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55199cc-f9cb-44dc-86d3-4eb0d9f50143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for (idx, df) in tr.group_by(\"sequence_id\", maintain_order = True):\n",
    "    df = df.with_columns(pl.col(\"acc_x\").diff().alias(\"diff_x\"))\n",
    "    df = df.with_columns(pl.col(\"acc_y\").diff().alias(\"diff_y\"))\n",
    "    df = df.with_columns(pl.col(\"acc_z\").diff().alias(\"diff_z\"))\n",
    "    df = df.with_columns((pl.col(\"acc_x\").pow(2) + pl.col(\"acc_y\").pow(2) + pl.col(\"acc_z\").pow(2)).sqrt().alias(\"mag\"))\n",
    "    df = df.with_columns((2*pl.col(\"rot_w\").arccos()).alias(\"angle\"))\n",
    "    \n",
    "    ang_vel = calculate_angular_velocity_from_quat(df)\n",
    "    ang_dist = calculate_angular_distance(df)\n",
    "    df = df.with_columns(pl.DataFrame(ang_vel, schema=[\"ang_vel_x\", \"ang_vel_y\", \"ang_vel_z\"]))\n",
    "    df = df.with_columns(pl.Series(ang_dist).alias(\"ang_dist\"))\n",
    "    \n",
    "    dfs.append(df)\n",
    "tr = pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a057e43-24bb-4b97-b34a-72fae33975c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c583c685-b8e3-49e0-bc26-f37dcd7007dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_cols = [\"acc_x\",\"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "diff_cols = [\"diff_x\", \"diff_y\", \"diff_z\"]\n",
    "extra_imu = [\"mag\", \"angle\"]\n",
    "extra_extra_imu = [\"ang_vel_x\", \"ang_vel_y\", \"ang_vel_z\", \"ang_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8000898e-178a-422e-88b9-2c9ae58618c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = imu_cols+diff_cols + extra_imu + extra_extra_imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45abf977-704c-41a4-96fc-aa6de4d5d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac2425b-0518-410c-a474-141c9a0a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(tr_df, labels_df, target_cols, scaler):\n",
    "\n",
    "    tr_df = tr_df.with_columns(pl.col(target_cols).replace([float(\"inf\"), float(\"-inf\"), float(\"nan\")], None))\n",
    "    scaled = pl.DataFrame(scaler.fit_transform(tr_df[target_cols]), schema=target_cols)\n",
    "    tr_df = tr_df.with_columns(scaled)\n",
    "    \n",
    "    tr_df = tr_df.with_columns(pl.col(target_cols).replace([float(\"inf\"), float(\"-inf\"), float(\"nan\")], None))\n",
    "    tr_df =tr_df.fill_null(0)\n",
    "    \n",
    "    seq_length = 128\n",
    "    x_tr = np.zeros((tr_df.filter(pl.col(\"sequence_counter\")  == 0).shape[0], len(target_cols), seq_length))\n",
    "    for e, (idx, df) in enumerate(tr_df.group_by(\"sequence_id\", maintain_order=True)):\n",
    "        x_tr[e, :,-df.shape[0]:] = df[target_cols].to_numpy()[-seq_length:,:].T\n",
    "    \n",
    "    y_tr = labels_df[:,3:].to_numpy()\n",
    "    \n",
    "    return x_tr, y_tr, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd04d34b-b340-4943-a825-c058e267a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets, noise_factor=120):\n",
    "        self.data = data\n",
    "        self.targets = torch.Tensor(targets)\n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        if self.noise_factor:\n",
    "            r = np.random.rand(x.shape[0], x.shape[1])/self.noise_factor - 1/(2*self.noise_factor)\n",
    "            x = x+r\n",
    "            x = x.astype(np.float32)\n",
    "        \n",
    "        r = np.random.uniform(0.75,1.5)\n",
    "        x[:3,:] = x[:3,:]*r\n",
    "        x[7:,:] = x[7:,:]*r\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class TestTimeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = torch.Tensor(targets)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c94d9519-0adc-4814-af35-971b0e3f03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "\n",
    "class ResidualSECNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, pool_size=1, dropout=0.0, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First conv block\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # SE block\n",
    "        self.se = SEBlock(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        self.pool_size = pool_size\n",
    "        self.pool = nn.MaxPool1d(pool_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "        self.gru = nn.GRU(out_channels, out_channels//2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        # First conv\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        # Second conv\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # SE block\n",
    "        out = self.se(out)\n",
    "        \n",
    "        # Add shortcut\n",
    "        \n",
    "        out += shortcut\n",
    "        \n",
    "        out = self.act(out)\n",
    "    \n",
    "        out = out + self.gru(out.transpose(1, 2))[0].transpose(1, 2)\n",
    "        \n",
    "        # Pool and dropout\n",
    "        if self.pool_size>1:\n",
    "            out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3c7cd80-0e5b-4644-80e1-b35a172390c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetImuResGru(nn.Module):\n",
    "    def __init__(self,n_blocks=2, chan=64, kern=5, kern_increase=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block0_0 = ResidualSECNNBlock(4, chan,3)\n",
    "        self.block0_1 = ResidualSECNNBlock(chan, chan,3)\n",
    "        self.block0_2 = ResidualSECNNBlock(chan, chan, 3)\n",
    "\n",
    "        self.block1_0 = ResidualSECNNBlock(5, chan,3)\n",
    "        self.block1_1 = ResidualSECNNBlock(chan, chan,3)\n",
    "        self.block1_2 = ResidualSECNNBlock(chan, chan, 3)\n",
    "\n",
    "        self.block2_0 = ResidualSECNNBlock(3, chan,3)\n",
    "        self.block2_1 = ResidualSECNNBlock(chan, chan,3)\n",
    "        self.block2_2 = ResidualSECNNBlock(chan, chan, 3)\n",
    "\n",
    "        self.block3_0 = ResidualSECNNBlock(4, chan,3)\n",
    "        self.block3_1 = ResidualSECNNBlock(chan, chan,3)\n",
    "        self.block3_2 = ResidualSECNNBlock(chan, chan, 3)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_blocks+1):\n",
    "            if i == 0:\n",
    "                self.layers.append(ResidualSECNNBlock(4*chan, 4*chan,kern))\n",
    "            else:\n",
    "                self.layers.append(ResidualSECNNBlock((4*chan)*2**((i-1)//2), (4*chan)*2**(i//2),kern+kern_increase*i))\n",
    "        self.pool = nn.MaxPool1d(2,2)  \n",
    "        self.fc0 = nn.Linear((4*chan)*2**(i//2), 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in1 = torch.cat([x[:,:3,:], x[:,10:11,:]], dim=1)\n",
    "        in2 = torch.cat([x[:,3:7,:], x[:,11:12,:]], dim=1)\n",
    "        in3 = x[:,7:10,:]\n",
    "        in4 = x[:,12:,:]\n",
    "        x0 = self.block0_2(self.block0_1(self.block0_0(in1)))\n",
    "        x1 = self.block1_2(self.block1_1(self.block1_0(in2)))\n",
    "        x2 = self.block2_2(self.block2_1(self.block2_0(in3)))\n",
    "        x3 = self.block3_2(self.block3_1(self.block3_0(in4)))\n",
    "        \n",
    "        x = torch.cat([x0,x1,x2,x3], dim=1)\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            x = self.pool(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        x = torch.mean(x, dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c06801a2-c37a-4acb-a1ee-ab1d4625b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4689173e-1a80-42bc-b374-e8466a24232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, y_tr, scaler = prep_data(tr, labels_df, target_cols, scaler)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR,\"imuonly_regular_scaler.pkl\"), \"wb\") as f:\n",
    "    dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b513b66-551f-4c6a-b9d6-659ab99a0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea434179-8a40-4eb8-afa1-22e146344836",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 35\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e26f9599-0ba1-42a4-8703-dfe12cfcaf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(20):   \n",
    "    net = NetImuResGru().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = MyDataset(x_tr.astype(np.float32), y_tr.astype(np.float32))\n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(80): \n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"imuonly_cnngru128_resgru_itr{p}\"))\n",
    "    print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05fbd5a6-604f-48f9-bf66-ccd5a0c0f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012240278522173565\n"
     ]
    }
   ],
   "source": [
    "print((time.time()-start)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4b8a2-2be9-40dd-b38a-2ec7f3b419fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
