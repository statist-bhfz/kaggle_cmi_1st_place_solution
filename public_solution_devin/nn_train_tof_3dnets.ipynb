{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aef47a-4008-4677-9190-2e18ca9c6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662311dc-9be2-4966-8276-bec9907c778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../input/cmi-detect-behavior-with-sensor-data/\"\n",
    "OUTPUT_DIR = \"../../models/debug/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdd7644-da96-4602-9af7-6ca85f3994b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle missing values in quaternion data intelligently\n",
    "    \n",
    "    Key insight: Quaternions must have unit length |q| = 1\n",
    "    If one component is missing, we can reconstruct it from the others\n",
    "    \"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            # No missing values, normalize to unit quaternion\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]  # Identity quaternion\n",
    "                \n",
    "        elif missing_count == 1:\n",
    "            # One missing value, reconstruct using unit quaternion constraint\n",
    "            # |w|² + |x|² + |y|² + |z|² = 1\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            \n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                # Choose sign for continuity with previous quaternion\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            # More than one missing value, use identity quaternion\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/10): # Assuming 10Hz sampling rate\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "# thanks: https://www.kaggle.com/code/nksusth/lb-0-78-quaternions-tf-bilstm-gru-attention\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pl.DataFrame):\n",
    "        quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist\n",
    "\n",
    "def preprocess_left_handed(l_tr):\n",
    "    rot_cleaned = handle_quaternion_missing_values(l_tr[[\"rot_w\",\"rot_x\", \"rot_y\", \"rot_z\"]].to_numpy())\n",
    "    rot_scipy = rot_cleaned[:, [1, 2, 3, 0]]\n",
    "    \n",
    "    norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "    if np.any(norms < 1e-8):\n",
    "        # Replace problematic quaternions with identity\n",
    "        mask = norms < 1e-8\n",
    "        rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n",
    "        print(\"yes\")\n",
    "    \n",
    "    r = R.from_quat(rot_scipy)\n",
    "    tmp = r.as_euler(\"xyz\")\n",
    "    tmp[:,1] = - tmp[:,1]\n",
    "    tmp[:,2] = - tmp[:,2]\n",
    "    r = R.from_euler(\"xyz\", tmp)\n",
    "    tmp = r.as_quat()\n",
    "    l_tr = l_tr.with_columns(pl.DataFrame(tmp, schema=[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]))\n",
    "    l_tr = l_tr.with_columns(-pl.col(\"acc_x\"))\n",
    "    \n",
    "    tmp = l_tr[[\"thm_3\", \"thm_5\"]]\n",
    "    tmp.columns = [\"thm_5\", \"thm_3\"]\n",
    "    l_tr = l_tr.with_columns(tmp)\n",
    "    \n",
    "    swap_1_2_4_base = [[0,7],[1,6],[2,5],[3,4], [4,3], [5,2],[6,1],[7,0]]\n",
    "    swap_3_5_base = [[0,56],[8,48],[16,40], [24,32],[32,24], [40,16],[48,8], [56,0]]\n",
    "    \n",
    "    swap_1_2_4 = list()\n",
    "    for i in range(0,64,8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_1_2_4_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_1_2_4 += ll\n",
    "    \n",
    "    swap_3_5 = list()\n",
    "    for i in range(8):\n",
    "        ll = list()\n",
    "        for (k,l) in swap_3_5_base:\n",
    "            ll.append([k+i, l+i])\n",
    "        swap_3_5 += ll\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[k].alias(l))\n",
    "    \n",
    "    for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n",
    "        l_tr = l_tr.with_columns(l_df[l].alias(k))\n",
    "    \n",
    "    l_df = l_tr\n",
    "    \n",
    "    for i in [1,2,4]:\n",
    "        for (k, l) in swap_1_2_4:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    \n",
    "    for i in [3,5]:\n",
    "        for (k, l) in swap_3_5:\n",
    "            l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n",
    "    return l_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ff7b95-5613-401b-92a5-739f80d95a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3844748d-8fcd-4d2a-bb06-6d6a97d4fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede65d5-d4f6-436e-8bdf-c3a4e336eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pl.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n",
    "no_gesture = 'SEQ_011975'\n",
    "tr = tr.filter(pl.col(\"sequence_id\") != no_gesture)\n",
    "\n",
    "#null_seqs = pl.read_csv(\"../input/null_seqs.csv\")\n",
    "#tr = tr.filter(~pl.col(\"sequence_id\").is_in(null_seqs[:,0].implode()))\n",
    "\n",
    "demo = pl.read_csv(os.path.join(INPUT_DIR,\"train_demographics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731a6160-d736-48de-8820-b7289490ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_subjs = demo.filter(pl.col(\"handedness\") == 1)[\"subject\"].to_list()\n",
    "l_subjs = demo.filter(pl.col(\"handedness\") == 0)[\"subject\"].to_list()\n",
    "\n",
    "r_subjs.remove(\"SUBJ_019262\") # these subjects wore the device on the wrong side of the wrist and score worse then left handers.\n",
    "r_subjs.remove(\"SUBJ_045235\") # further, tof and thm are probably not salvagable, but maybe imu can be adjusted, could look into later\n",
    "\n",
    "r_new = tr.filter(pl.col(\"subject\").is_in(r_subjs))\n",
    "l_new = tr.filter(pl.col(\"subject\").is_in(l_subjs))\n",
    "\n",
    "l_new = preprocess_left_handed(l_new)\n",
    " \n",
    "tr = pl.concat([r_new, l_new])\n",
    "tr = tr.sort(by=\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e40d59-0fce-40a7-9685-c3d124c02f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tr.filter(pl.col(\"sequence_counter\") ==0)[:,[\"sequence_id\", \"subject\",\"gesture\"]]\n",
    "labels = labels.sort(by=\"gesture\")\n",
    "label_encoder = LabelEncoder()\n",
    "labels = labels.with_columns(pl.Series(label_encoder.fit_transform(labels[\"gesture\"])).alias(\"gesture\"))\n",
    "oh_encoder = OneHotEncoder()\n",
    "onehotted = oh_encoder.fit_transform(pl.DataFrame(labels[\"gesture\"])).toarray()\n",
    "onehotted = pl.DataFrame(onehotted, orient=\"row\", schema=label_encoder.classes_.tolist())\n",
    "labels = labels.hstack(onehotted)\n",
    "labels_df = labels.sort(by=\"sequence_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1894e0b-8f1a-4add-b8b7-499443c0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tof_to_array(df, sensor, t):\n",
    "    l = list()\n",
    "    for i in range(8):\n",
    "        ll = list()\n",
    "        for j in range(8):\n",
    "            ll.append(df[t,f\"tof_{sensor}_v{i*8+j}\"])\n",
    "        l.append(ll)\n",
    "    return np.array(l)\n",
    "\n",
    "def tofdiff_to_array(df, sensor, t):\n",
    "    l = list()\n",
    "    for i in range(8):\n",
    "        ll = list()\n",
    "        for j in range(8):\n",
    "            ll.append(df[t,f\"tof_{sensor}_v{i*8+j}_diff\"])\n",
    "        l.append(ll)\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6160a277-8c1d-4b7e-9495-7875a9750f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seqs = tr.filter(pl.col(\"sequence_counter\") == 0).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "526c95ec-2984-4374-8725-7dbd98e3c967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 52s, sys: 13.7 s, total: 3min 6s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tof_arr = np.zeros((n_seqs, 5, 128, 8, 8))\n",
    "for e, (idx, df) in enumerate(tr.group_by(\"sequence_id\", maintain_order=True)):\n",
    "    start = max(df.shape[0]-128, 0)\n",
    "    offset = max(128-df.shape[0], 0)\n",
    "    for ee, i in enumerate(range(start, df.shape[0])):\n",
    "        for j in range(1,6):\n",
    "            tof_image = tof_to_array(df, j, i)\n",
    "            tof_arr[e,j-1,offset+ee,:,:] = tof_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c82cd9-efa6-44ed-86ec-e2e2ef2c735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.with_columns(pl.all().replace(-1, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "004920eb-8395-44c8-988c-0f35cfb4cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for e, (idx, df) in enumerate(tr.group_by(\"sequence_id\", maintain_order = True)):\n",
    "    df = df.with_columns(pl.lit(e).alias(\"subject_index\"))\n",
    "    for i in [f\"tof_{x}_v{y}\" for x in range(1,6) for y in range(64)]:\n",
    "        df = df.with_columns(pl.col(i).diff().alias(i+\"_diff\"))\n",
    "    \n",
    "    dfs.append(df)\n",
    "tr = pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d95ddeb-fb15-4686-9ff6-bf087682fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 56s, sys: 12.8 s, total: 6min 9s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tof_diff_arr = np.zeros((n_seqs, 10, 128, 8, 8))\n",
    "for e, (idx, df) in enumerate(tr.group_by(\"sequence_id\", maintain_order=True)):\n",
    "    start = max(df.shape[0]-128, 0)\n",
    "    offset = max(128-df.shape[0], 0)\n",
    "    for ee, i in enumerate(range(start, df.shape[0])):\n",
    "        for j in range(1,6):\n",
    "            tof_image = tof_to_array(df, j, i)\n",
    "            tof_diff_arr[e,j-1,offset+ee,:,:] = tof_image\n",
    "        for j in range(1,6):\n",
    "            tof_image = tofdiff_to_array(df, j, i)\n",
    "            tof_diff_arr[e,5+j-1,offset+ee,:,:] = tof_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac2425b-0518-410c-a474-141c9a0a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale_3d_fit_transform(data):\n",
    "    mean = np.nanmean(data, axis=(0,2))\n",
    "    \n",
    "    std = np.nanstd(data, axis=(0,2))\n",
    "    \n",
    "    mean = mean[np.newaxis,:,np.newaxis,:,:]\n",
    "    std = std[np.newaxis,:,np.newaxis,:,:]\n",
    "    \n",
    "    scaled_data = (data - mean) / std\n",
    "    return scaled_data, mean, std\n",
    "\n",
    "def standard_scale_3d_transform(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def prep_data_tof3d(tof_arr, labels_df):\n",
    "    tr_tof, mean, std = standard_scale_3d_fit_transform(tof_arr)\n",
    "    tr_tof = np.nan_to_num(tr_tof, 0)\n",
    "    y_tr = labels_df[:,3:].to_numpy()\n",
    "\n",
    "    return tr_tof, y_tr, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd04d34b-b340-4943-a825-c058e267a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTimeDataset3d(torch.utils.data.Dataset):\n",
    "    def __init__(self, tof_arr, targets):\n",
    "        self.targets = targets\n",
    "        self.tof_arr = tof_arr.astype(np.float32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        y = self.targets[index]\n",
    "        tof = self.tof_arr[index]\n",
    "        \n",
    "        return tof, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tof_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d9519-0adc-4814-af35-971b0e3f03cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c7cd80-0e5b-4644-80e1-b35a172390c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm3d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm3d(num_features=out_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.res_layer = torch.nn.Conv3d(in_channels, out_channels, kernel_size=1, padding=\"same\")\n",
    "        else:\n",
    "            self.res_layer = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        if self.res_layer is None:\n",
    "            x = torch.add(x, res)\n",
    "        else: \n",
    "            x = torch.add(x, self.res_layer(res)) # should the res layer have a relu? or batch norm?\n",
    "            # TODO experiment with the residual block\n",
    "        return x \n",
    "\n",
    "\n",
    "class RNNet3d(nn.Module):\n",
    "    def __init__(self, input_chan, chan=128):\n",
    "        super().__init__()\n",
    "        self.block0 = ResidualBlock3d(input_chan, chan, 3)\n",
    "        self.block1 = ResidualBlock3d(chan, chan, 3)\n",
    "        self.block2 = ResidualBlock3d(chan, chan, 3)\n",
    "\n",
    "        self.rnn = nn.GRU(chan, 128,\n",
    "            num_layers = 2, \n",
    "            batch_first =True,\n",
    "            bidirectional=True)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d((1,2,2))\n",
    "        self.fc0 = nn.Linear(256, 256)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(256, 18)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block0(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.squeeze(dim=[3,4])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x,_ = self.rnn(x)\n",
    "        x = self.drop(F.relu(self.fc0(x)))\n",
    "        x = self.fc1(x)\n",
    "        x = x[:,-30:,:].mean(axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f648051b-14e9-47db-8d93-80a341c3990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_tof, y_tr_tof, tof_mean, tof_std = prep_data_tof3d(tof_arr, labels_df)\n",
    "\n",
    "np.save(os.path.join(OUTPUT_DIR,\"tof_mean.npy\"), tof_mean)\n",
    "np.save(os.path.join(OUTPUT_DIR,\"tof_std.npy\"), tof_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8488422c-887f-4529-8478-dd3ba68fc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_tof_diff, y_tr_tof_diff, tof_diff_mean, tof_diff_std = prep_data_tof3d(tof_diff_arr, labels_df)\n",
    "\n",
    "np.save(os.path.join(OUTPUT_DIR,\"tof_diff_mean.npy\"), tof_diff_mean)\n",
    "np.save(os.path.join(OUTPUT_DIR,\"tof_diff_std.npy\"), tof_diff_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6345e8e-2e5c-4727-8f28-a20aff68db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ead10bc6-bb10-4503-aa39-7bc1e22f2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26f9599-0ba1-42a4-8703-dfe12cfcaf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(20):\n",
    "    net = RNNet3d(input_chan=5).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "    \n",
    "    tr_dataset = TestTimeDataset3d(x_tr_tof.astype(np.float32), y_tr_tof.astype(np.float32))\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(60):\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"alldata_tof3dnet_itr{p}\"))\n",
    "    print(p) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab925aa9-ade4-433b-9db9-1afa4f3876db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for p in range(20):\n",
    "\n",
    "    net = RNNet3d(input_chan=10).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "\n",
    "    \n",
    "    tr_dataset = TestTimeDataset3d(x_tr_tof_diff.astype(np.float32), y_tr_tof_diff.astype(np.float32))\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(tr_dataset, batch_size=64,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "\n",
    "    for epoch in range(60):\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model_state = net.state_dict()\n",
    "    torch.save(model_state, os.path.join(OUTPUT_DIR,f\"alldata_tof3dnet_diff_itr{p}\"))\n",
    "    print(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ca7193-e7dd-4839-84c1-2035c37fae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005151151948504977\n"
     ]
    }
   ],
   "source": [
    "print((time.time()-start_time)/60/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52768dc-273d-4e99-9fd6-312b3943b1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
