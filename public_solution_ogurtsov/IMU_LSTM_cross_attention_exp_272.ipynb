{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb659cf",
   "metadata": {
    "papermill": {
     "duration": 0.004514,
     "end_time": "2025-06-07T16:42:23.306864",
     "exception": false,
     "start_time": "2025-06-07T16:42:23.302350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CMI - Detect Behavior with Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36a537",
   "metadata": {
    "papermill": {
     "duration": 0.003311,
     "end_time": "2025-06-07T16:42:23.320847",
     "exception": false,
     "start_time": "2025-06-07T16:42:23.317536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMU_LSTM_cross_attention_exp_272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de18db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T16:42:23.328651Z",
     "iopub.status.busy": "2025-06-07T16:42:23.328448Z",
     "iopub.status.idle": "2025-06-07T16:42:38.979610Z",
     "shell.execute_reply": "2025-06-07T16:42:38.978784Z"
    },
    "papermill": {
     "duration": 15.656634,
     "end_time": "2025-06-07T16:42:38.981010",
     "exception": false,
     "start_time": "2025-06-07T16:42:23.324376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, warnings, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, LinearLR, ChainedScheduler\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "\n",
    "from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cf6ec",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2025-06-07T16:42:38.988942",
     "exception": false,
     "start_time": "2025-06-07T16:42:38.985242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51872c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T16:42:39.004570Z",
     "iopub.status.busy": "2025-06-07T16:42:39.004027Z",
     "iopub.status.idle": "2025-06-07T16:42:39.008773Z",
     "shell.execute_reply": "2025-06-07T16:42:39.008022Z"
    },
    "papermill": {
     "duration": 0.009975,
     "end_time": "2025-06-07T16:42:39.009796",
     "exception": false,
     "start_time": "2025-06-07T16:42:38.999821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DIR = Path(\"data\")\n",
    "EXPORT_DIR = \"models/exp_272\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok = True)\n",
    "EXPORT_DIR = Path(EXPORT_DIR)                                    \n",
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 94 \n",
    "LR_INIT = 5e-4 \n",
    "WD = 3e-4 \n",
    "MIXUP_ALPHA = 0.4 \n",
    "EPOCHS = 220\n",
    "PATIENCE = 30\n",
    "T_0 = 10\n",
    "\n",
    "ema_decay = 0.99\n",
    "\n",
    "ACC_COLS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "ROT_COLS = [\"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "\n",
    "FOCAL_LOSS = False\n",
    "CLASS_WEIGHTS = False\n",
    "DEL_SUBJ = False\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3beb5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2del = pd.read_csv(RAW_DIR / \"ids2del_prop_0.2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f43ca",
   "metadata": {
    "papermill": {
     "duration": 0.003529,
     "end_time": "2025-06-07T16:42:39.017292",
     "exception": false,
     "start_time": "2025-06-07T16:42:39.013763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98226555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothFocalLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.gamma = gamma\n",
    "        self.classes = classes\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        \n",
    "        # Create one-hot encoding of actual labels\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.classes - 1))\n",
    "            true_dist.scatter_(1, target.max(1)[1].unsqueeze(1), 1.0 - self.smoothing)\n",
    "        \n",
    "        # Calculate focal weight\n",
    "        pt = (true_dist * pred).sum(1)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = -torch.sum(true_dist * torch.log(pred + 1e-6), dim=1)\n",
    "        loss = focal_weight * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0611ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalTransform:\n",
    "    def __init__(self, always_apply: bool = False, p: float = 0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class OneOf:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        n_trns = len(self.transforms)\n",
    "        trns_idx = np.random.choice(n_trns)\n",
    "        trns = self.transforms[trns_idx]\n",
    "        return trns(y)\n",
    "    \n",
    "class TimeStretch(SignalTransform):\n",
    "    def __init__(self, max_rate=1.5, min_rate=0.5, always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_rate = max_rate\n",
    "        self.min_rate = min_rate\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def apply(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        Stretch a 1D or 2D array in time using linear interpolation.\n",
    "        After stretching, pad or crop at the beginning to match the original length.\n",
    "        Padding value is 0.\n",
    "        - x: np.ndarray of shape (L,) or (L, N)\n",
    "        \"\"\"\n",
    "        rate = np.random.uniform(self.min_rate, self.max_rate)\n",
    "        L = x.shape[0]\n",
    "        L_new = int(L / rate)\n",
    "        orig_idx = np.linspace(0, L - 1, num=L)\n",
    "        new_idx = np.linspace(0, L - 1, num=L_new)\n",
    "\n",
    "        if x.ndim == 1:\n",
    "            stretched = np.interp(new_idx, orig_idx, x)\n",
    "            # Pad or crop at the beginning\n",
    "            if L_new < L:\n",
    "                # Pad at the beginning\n",
    "                padded = np.zeros(L, dtype=stretched.dtype)\n",
    "                padded[-L_new:] = stretched\n",
    "                return padded\n",
    "            elif L_new > L:\n",
    "                # Crop at the beginning\n",
    "                return stretched[-L:]\n",
    "            else:\n",
    "                return stretched\n",
    "        elif x.ndim == 2:\n",
    "            stretched = np.stack([\n",
    "                np.interp(new_idx, orig_idx, x[:, i]) for i in range(x.shape[1])\n",
    "            ], axis=1)\n",
    "            if L_new < L:\n",
    "                padded = np.zeros((L, x.shape[1]), dtype=stretched.dtype)\n",
    "                padded[-L_new:, :] = stretched\n",
    "                return padded\n",
    "            elif L_new > L:\n",
    "                return stretched[-L:, :]\n",
    "            else:\n",
    "                return stretched\n",
    "        else:\n",
    "            raise ValueError(\"Only 1D or 2D arrays are supported.\")\n",
    "\n",
    "\n",
    "class TimeShift(SignalTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_shift_pct=0.25, padding_mode=\"replace\"):\n",
    "        super().__init__(always_apply, p)\n",
    "        \n",
    "        assert 0 <= max_shift_pct <= 1.0, \"`max_shift_pct` must be between 0 and 1\"\n",
    "        assert padding_mode in [\"replace\", \"zero\"], \"`padding_mode` must be either 'replace' or 'zero'\"\n",
    "        \n",
    "        self.max_shift_pct = max_shift_pct\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "    def apply(self, x: np.ndarray, **params):\n",
    "        assert x.ndim == 2, \"`x` must be a 2D array with shape (L, N)\"\n",
    "        \n",
    "        L = x.shape[0]\n",
    "        max_shift = int(L * self.max_shift_pct)\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "\n",
    "        # Roll along time axis (axis=0)\n",
    "        augmented = np.roll(x, shift, axis=0)\n",
    "\n",
    "        if self.padding_mode == \"zero\":\n",
    "            if shift > 0:\n",
    "                augmented[:shift, :] = 0\n",
    "            elif shift < 0:\n",
    "                augmented[shift:, :] = 0\n",
    "\n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8db1550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T16:42:39.055653Z",
     "iopub.status.busy": "2025-06-07T16:42:39.055439Z",
     "iopub.status.idle": "2025-06-07T16:42:39.061294Z",
     "shell.execute_reply": "2025-06-07T16:42:39.060609Z"
    },
    "papermill": {
     "duration": 0.011,
     "end_time": "2025-06-07T16:42:39.062318",
     "exception": false,
     "start_time": "2025-06-07T16:42:39.051318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle missing values in quaternion data intelligently\n",
    "    \n",
    "    Key insight: Quaternions must have unit length |q| = 1\n",
    "    If one component is missing, we can reconstruct it from the others\n",
    "    \"\"\"\n",
    "    rot_cleaned = rot_data.copy()\n",
    "    \n",
    "    for i in range(len(rot_data)):\n",
    "        row = rot_data[i]\n",
    "        missing_count = np.isnan(row).sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            # No missing values, normalize to unit quaternion\n",
    "            norm = np.linalg.norm(row)\n",
    "            if norm > 1e-8:\n",
    "                rot_cleaned[i] = row / norm\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]  # Identity quaternion\n",
    "                \n",
    "        elif missing_count == 1:\n",
    "            # One missing value, reconstruct using unit quaternion constraint\n",
    "            # |w|² + |x|² + |y|² + |z|² = 1\n",
    "            missing_idx = np.where(np.isnan(row))[0][0]\n",
    "            valid_values = row[~np.isnan(row)]\n",
    "            \n",
    "            sum_squares = np.sum(valid_values**2)\n",
    "            if sum_squares <= 1.0:\n",
    "                missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n",
    "                # Choose sign for continuity with previous quaternion\n",
    "                if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n",
    "                    if rot_cleaned[i-1, missing_idx] < 0:\n",
    "                        missing_value = -missing_value\n",
    "                rot_cleaned[i, missing_idx] = missing_value\n",
    "                rot_cleaned[i, ~np.isnan(row)] = valid_values\n",
    "            else:\n",
    "                rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "        else:\n",
    "            # More than one missing value, use identity quaternion\n",
    "            rot_cleaned[i] = [1.0, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    return rot_cleaned\n",
    "\n",
    "def compute_world_acceleration(acc: np.ndarray, rot: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert acceleration from device coordinates to world coordinates\n",
    "    \n",
    "    This is the key innovation: normalizing for device orientation\n",
    "    \n",
    "    Args:\n",
    "        acc: acceleration in device coordinates, shape (time_steps, 3) [x, y, z]\n",
    "        rot: rotation quaternion, shape (time_steps, 4) [w, x, y, z] (normalized)\n",
    "    \n",
    "    Returns:\n",
    "        acc_world: acceleration in world coordinates, shape (time_steps, 3)\n",
    "        \n",
    "    Why this matters:\n",
    "    - Device acceleration depends on how the watch is oriented on the wrist\n",
    "    - World acceleration is independent of device orientation\n",
    "    - This helps the model focus on actual hand motion rather than wrist rotation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert quaternion format from [w, x, y, z] to [x, y, z, w] for scipy\n",
    "        rot_scipy = rot[:, [1, 2, 3, 0]]\n",
    "        \n",
    "        # Verify quaternions are valid (non-zero norm)\n",
    "        norms = np.linalg.norm(rot_scipy, axis=1)\n",
    "        if np.any(norms < 1e-8):\n",
    "            # Replace problematic quaternions with identity\n",
    "            mask = norms < 1e-8\n",
    "            rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n",
    "        \n",
    "        # Create rotation object and apply transformation\n",
    "        r = R.from_quat(rot_scipy)\n",
    "        acc_world = r.apply(acc)\n",
    "        \n",
    "    except Exception:\n",
    "        # Fallback to original acceleration if transformation fails\n",
    "        print(\"Warning: World coordinate transformation failed, using device coordinates\")\n",
    "        acc_world = acc.copy()\n",
    "    \n",
    "    return acc_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b59bf6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200): # Assuming 200Hz sampling rate\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_vel = np.zeros((num_samples, 3))\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q_t = quat_values[i]\n",
    "        q_t_plus_dt = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isclose(q_t, 0)) or \\\n",
    "           np.all(np.isnan(q_t_plus_dt)) or np.all(np.isclose(q_t_plus_dt, 0)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "\n",
    "            # Calculate the relative rotation\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            \n",
    "            # Convert delta rotation to angular velocity vector\n",
    "            # The rotation vector (Euler axis * angle) scaled by 1/dt\n",
    "            # is a good approximation for small delta_rot\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError:\n",
    "            # If quaternion is invalid, angular velocity remains zero\n",
    "            pass\n",
    "            \n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = quat_values.shape[0]\n",
    "    angular_dist = np.zeros(num_samples)\n",
    "\n",
    "    for i in range(num_samples - 1):\n",
    "        q1 = quat_values[i]\n",
    "        q2 = quat_values[i+1]\n",
    "\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isclose(q1, 0)) or \\\n",
    "           np.all(np.isnan(q2)) or np.all(np.isclose(q2, 0)):\n",
    "            angular_dist[i] = 0 # Или np.nan, в зависимости от желаемого поведения\n",
    "            continue\n",
    "        try:\n",
    "            # Преобразование кватернионов в объекты Rotation\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Вычисление углового расстояния: 2 * arccos(|real(p * q*)|)\n",
    "            # где p* - сопряженный кватернион q\n",
    "            # В scipy.spatial.transform.Rotation, r1.inv() * r2 дает относительное вращение.\n",
    "            # Угол этого относительного вращения - это и есть угловое расстояние.\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            \n",
    "            # Угол rotation vector соответствует угловому расстоянию\n",
    "            # Норма rotation vector - это угол в радианах\n",
    "            angle = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "            angular_dist[i] = angle\n",
    "        except ValueError:\n",
    "            angular_dist[i] = 0 # В случае недействительных кватернионов\n",
    "            pass\n",
    "            \n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f470d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "\n",
    "    if isinstance(acc_data, pd.DataFrame):\n",
    "        acc_values = acc_data[[\"acc_x\", \"acc_y\", \"acc_z\"]].values\n",
    "    else:\n",
    "        acc_values = acc_data\n",
    "\n",
    "    if isinstance(rot_data, pd.DataFrame):\n",
    "        quat_values = rot_data[[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]].values\n",
    "    else:\n",
    "        quat_values = rot_data\n",
    "\n",
    "    num_samples = acc_values.shape[0]\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    \n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :] \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "             \n",
    "    return linear_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dde850fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Add world-frame acceleration features to the dataframe.\n",
    "\n",
    "    This function computes acceleration in world coordinates using quaternion orientation,\n",
    "    and appends these as new columns to the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe containing sensor data and metadata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with added world-frame acceleration columns.\n",
    "    \"\"\"\n",
    "\n",
    "    meta_cols = [\n",
    "        \"gesture\", \"gesture_int\", \"sequence_type\", \n",
    "        \"behavior\", \"orientation\", \"row_id\", \"subject\", \n",
    "        \"phase\", \"sequence_id\", \"sequence_counter\"\n",
    "    ]\n",
    "    feature_cols_all = [c for c in df.columns if c not in meta_cols]\n",
    "    other_cols = [c for c in feature_cols_all if (c.startswith(\"thm_\") or c.startswith(\"tof_\"))]\n",
    "    \n",
    "    # Add features https://www.kaggle.com/code/rktqwe/lb-0-77-linear-accel-tf-bilstm-gru-attention\n",
    "    df[\"acc_mag\"] = np.sqrt(df[\"acc_x\"]**2 + df[\"acc_y\"]**2 + df[\"acc_z\"]**2)\n",
    "    df[\"acc_mag_jerk\"] = df[\"acc_mag\"].diff().fillna(0)\n",
    "\n",
    "    # Jerk magnitude (rate of change of acceleration)\n",
    "    df[\"jerk_x\"] = np.gradient(df[\"acc_x\"])\n",
    "    df[\"jerk_y\"] = np.gradient(df[\"acc_y\"]) \n",
    "    df[\"jerk_z\"] = np.gradient(df[\"acc_z\"])\n",
    "    df[\"jerk_magnitude\"] = np.sqrt(df[\"jerk_x\"]**2 + df[\"jerk_y\"]**2 + df[\"jerk_z\"]**2)\n",
    "      \n",
    "    # Correlation between axes (rolling correlation)\n",
    "    cor_list = []\n",
    "    window = 20\n",
    "    for _, group in df.groupby(\"sequence_id\"):\n",
    "        group[\"acc_xy_corr\"] = group[\"acc_x\"].rolling(window).corr(group[\"acc_y\"]).fillna(0)\n",
    "        group[\"acc_xz_corr\"] = group[\"acc_x\"].rolling(window).corr(group[\"acc_z\"]).fillna(0)\n",
    "        group[\"acc_yz_corr\"] = group[\"acc_y\"].rolling(window).corr(group[\"acc_z\"]).fillna(0)\n",
    "        cor_list.append(group[[\"acc_xy_corr\", \"acc_xz_corr\", \"acc_yz_corr\"]].to_numpy())\n",
    "    cor_list = np.concatenate(cor_list, axis = 0)\n",
    "    df[[\"acc_xy_corr\", \"acc_xz_corr\", \"acc_yz_corr\"]] = cor_list\n",
    "\n",
    "    df[\"rot_angle\"] = 2 * np.arccos(df[\"rot_w\"].clip(-1, 1))\n",
    "    df[\"rot_angle_vel\"] = df[\"rot_angle\"].diff().fillna(0)   \n",
    "\n",
    "    print(\"Calculating angular velocity from quaternion derivatives...\")\n",
    "    angular_vel_list = []\n",
    "    for _, group in df.groupby(\"sequence_id\"):\n",
    "        rot_data_group = group[[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]]\n",
    "        angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n",
    "        angular_vel_list.append(angular_vel_group)\n",
    "    angular_vel_list = np.concatenate(angular_vel_list, axis = 0)\n",
    "    df[[\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"]] = angular_vel_list\n",
    "    \n",
    "    df[\"angular_vel_magnitude\"] = np.sqrt(\n",
    "        df[\"angular_vel_x\"]**2 + df[\"angular_vel_y\"]**2 + df[\"angular_vel_x\"]**2\n",
    "    )\n",
    "\n",
    "    print(\"Calculating angular distance between successive quaternions...\")\n",
    "    angular_distance_list = []\n",
    "    for _, group in df.groupby(\"sequence_id\"):\n",
    "        rot_data_group = group[[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]]\n",
    "        angular_dist_group = calculate_angular_distance(rot_data_group)\n",
    "        angular_distance_list.append(angular_dist_group)\n",
    "    angular_distance_list = np.concatenate(angular_distance_list, axis = 0)\n",
    "    df[\"angular_distance\"] = angular_distance_list\n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    ACC_COLS2 = [\"acc_x2\", \"acc_y2\", \"acc_z2\"]\n",
    "\n",
    "    linear_accel_list = []\n",
    "    for _, group in df.groupby(\"sequence_id\"):\n",
    "        acc_data_group = group[ACC_COLS]\n",
    "        rot_data_group = group[ROT_COLS]\n",
    "        linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n",
    "        linear_accel_list.append(linear_accel_group)\n",
    "    linear_accel_list  = np.concatenate(linear_accel_list , axis = 0)\n",
    "    df[ACC_COLS2] = linear_accel_list\n",
    "\n",
    "    # Add features https://www.kaggle.com/code/rktqwe/lb-0-77-linear-accel-tf-bilstm-gru-attention\n",
    "    df[\"acc_mag2\"] = np.sqrt(df[\"acc_x2\"]**2 + df[\"acc_y2\"]**2 + df[\"acc_z2\"]**2)\n",
    "    df[\"acc_mag_jerk2\"] = df[\"acc_mag2\"].diff().fillna(0)\n",
    "\n",
    "    # Jerk magnitude (rate of change of acceleration)\n",
    "    df[\"jerk_x2\"] = np.gradient(df[\"acc_x2\"])\n",
    "    df[\"jerk_y2\"] = np.gradient(df[\"acc_y2\"]) \n",
    "    df[\"jerk_z2\"] = np.gradient(df[\"acc_z2\"])\n",
    "    df[\"jerk_magnitude2\"] = np.sqrt(df[\"jerk_x2\"]**2 + df[\"jerk_y2\"]**2 + df[\"jerk_z2\"]**2)\n",
    "        \n",
    "    # Correlation between axes (rolling correlation)\n",
    "    cor_list = []\n",
    "    window = 20\n",
    "    for _, group in df.groupby(\"sequence_id\"):\n",
    "        group[\"acc_xy_corr2\"] = group[\"acc_x2\"].rolling(window).corr(group[\"acc_y2\"]).fillna(0)\n",
    "        group[\"acc_xz_corr2\"] = group[\"acc_x2\"].rolling(window).corr(group[\"acc_z2\"]).fillna(0)\n",
    "        group[\"acc_yz_corr2\"] = group[\"acc_y2\"].rolling(window).corr(group[\"acc_z2\"]).fillna(0)\n",
    "        cor_list.append(group[[\"acc_xy_corr2\", \"acc_xz_corr2\", \"acc_yz_corr2\"]].to_numpy())\n",
    "    cor_list = np.concatenate(cor_list, axis = 0)\n",
    "    df[[\"acc_xy_corr2\", \"acc_xz_corr2\", \"acc_yz_corr2\"]] = cor_list\n",
    "\n",
    "    df = df[meta_cols \n",
    "            + ACC_COLS + [\"acc_mag\", \"acc_mag_jerk\"] \n",
    "            + [\"jerk_x\", \"jerk_y\", \"jerk_z\", \"jerk_magnitude\"]\n",
    "            + [\"acc_xy_corr\", \"acc_xz_corr\", \"acc_yz_corr\"]\n",
    "            + ROT_COLS + [\"rot_angle\", \"rot_angle_vel\"] \n",
    "            + [\"angular_vel_x\", \"angular_vel_y\", \"angular_vel_z\"] \n",
    "            + [\"angular_vel_magnitude\", \"angular_distance\"] \n",
    "            + ACC_COLS2 + [\"acc_mag2\", \"acc_mag_jerk2\"] \n",
    "            + [\"jerk_x2\", \"jerk_y2\", \"jerk_z2\", \"jerk_magnitude2\"]\n",
    "            + [\"acc_xy_corr2\", \"acc_xz_corr2\", \"acc_yz_corr2\"] + other_cols]\n",
    "\n",
    "    df.replace(-np.inf, -1, inplace=True)\n",
    "    df.replace(np.inf, 1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def pad_sequences(\n",
    "    sequences: list[np.ndarray], \n",
    "    maxlen: int, \n",
    "    padding: str = \"pre\", \n",
    "    truncating: str = \"pre\", \n",
    "    dtype: str = \"float32\"\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    Pad sequences to the same length.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    sequences : list of numpy.ndarray\n",
    "        List of sequences (each sequence is a numpy array) to pad\n",
    "    maxlen : int\n",
    "        Maximum length of all sequences. Sequences longer than maxlen will be truncated\n",
    "    padding : str, optional (default=\"pre\")\n",
    "        \"pre\" or \"post\", pad either before or after each sequence\n",
    "    truncating : str, optional (default=\"pre\")\n",
    "        \"pre\" or \"post\", remove values from sequences larger than maxlen either at the\n",
    "        beginning or at the end\n",
    "    dtype : str, optional (default=\"float32\")\n",
    "        Type of the output array\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Padded sequences array of shape (len(sequences), maxlen, ...)\n",
    "    \"\"\"\n",
    "    \n",
    "    if padding not in [\"pre\", \"post\"]: \n",
    "        raise NotImplementedError(\"Invalid padding\")\n",
    "    if truncating not in [\"pre\", \"post\"]: \n",
    "        raise NotImplementedError(\"Invalid truncating\")\n",
    "    \n",
    "    n_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = max(len(s) for s in sequences)\n",
    "    \n",
    "    # Sample shape from first non empty sequence\n",
    "    # If no non-empty sequences, return array of shape (0, maxlen)\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "    \n",
    "    x = np.zeros((n_samples, maxlen) + sample_shape, dtype = dtype)\n",
    "    \n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        \n",
    "        if truncating == \"pre\":\n",
    "            s = s[-maxlen:] \n",
    "        elif truncating == \"post\":\n",
    "            s[:maxlen]\n",
    "\n",
    "        trunc = s.shape[0]\n",
    "        \n",
    "        if padding == \"pre\":\n",
    "            x[idx, -trunc:] = s\n",
    "        elif padding == \"post\":\n",
    "            x[idx, :trunc] = s\n",
    "            \n",
    "    return x\n",
    "\n",
    "def to_categorical(y, num_classes = None):\n",
    "    y = np.array(y, dtype = \"int\")\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    return np.eye(num_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32e2b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_quaternion(quat):\n",
    "    \"\"\"\n",
    "    Mirror a single quaternion through the YZ plane.\n",
    "\n",
    "    Args:\n",
    "        quat (array of shape (N, 4)): [w, x, y, z]\n",
    "\n",
    "    Returns:\n",
    "        mirrored (np.ndarray of shape (N, 4)): mirrored quaternion [w, x, y, z]\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.diag([-1, 1, 1])  # reflection through YZ\n",
    "    rot = R.from_quat(quat[:, [1, 2, 3, 0]])  # SciPy uses [x, y, z, w]\n",
    "    R_mat = rot.as_matrix()\n",
    "    R_flipped = P @ R_mat @ P\n",
    "    flipped = R.from_matrix(R_flipped).as_quat()\n",
    "    return flipped[:, [3, 0, 1, 2]]  # back to [w, x, y, z]\n",
    "\n",
    "\n",
    "def mirror_data(data):\n",
    "    \"\"\"\n",
    "    Mirror left-handed samples to match right-handed frame.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray of shape (N, 7)): sensor data\n",
    "    \n",
    "    Returns:\n",
    "        A new array with mirrored left-handed samples.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data[:, 0] = -data[:, 0]\n",
    "    data[:, 3:] = mirror_quaternion(data[:, 3:]) # [w, x, y, z]\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_left_handed(df, dem):\n",
    "    left_handed = dem[dem[\"handedness\"] == 0]\n",
    "    left_handed = df.loc[df[\"subject\"].isin(left_handed[\"subject\"])]\n",
    "    cols_to_transform = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "    left_handed_arr = left_handed[cols_to_transform].to_numpy()\n",
    "    df.loc[df[\"subject\"].isin(left_handed[\"subject\"]), cols_to_transform] = mirror_data(left_handed_arr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea3cf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEMA(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Model Exponential Moving Average (EMA).\n",
    "    \n",
    "    Maintains an exponential moving average of model parameters during training.\n",
    "    This helps improve model stability and performance by creating a temporal\n",
    "    ensemble of model parameters.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The model whose parameters will be averaged\n",
    "    decay : float, optional (default=0.99)\n",
    "        The decay rate for the exponential moving average.\n",
    "        Higher values (closer to 1) give more weight to past parameters.\n",
    "    device : torch.device, optional (default=None)\n",
    "        The device to store the EMA model on.\n",
    "        If None, will use the same device as the input model.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    update(model):\n",
    "        Updates the EMA parameters using the current model parameters\n",
    "    set(model):\n",
    "        Sets the EMA parameters directly from the current model parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay = 0.99, device = None):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        if self.device is not None:\n",
    "            self.module.to(device = device)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "\n",
    "        \"\"\"\n",
    "        Internal method to update EMA parameters.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model : torch.nn.Module\n",
    "            The current model\n",
    "        update_fn : callable\n",
    "            Function that defines how to update the EMA parameters\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(), \n",
    "                                      model.state_dict().values()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device = self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "\n",
    "    def update(self, model):\n",
    "\n",
    "        \"\"\"\n",
    "        Update the EMA parameters using the decay rate.\n",
    "        \n",
    "        new_parameter = decay * old_parameter + (1 - decay) * current_parameter\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model : torch.nn.Module\n",
    "            The current model whose parameters will be used to update the EMA\n",
    "        \"\"\"\n",
    "\n",
    "        self._update(model, update_fn = lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "\n",
    "    def set(self, model):\n",
    "\n",
    "        \"\"\"\n",
    "        Directly set the EMA parameters to the current model parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model : torch.nn.Module\n",
    "            The model whose parameters will be copied to the EMA\n",
    "        \"\"\"\n",
    "\n",
    "        self._update(model, update_fn = lambda e, m: m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa36a7c",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8c1a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating angular velocity from quaternion derivatives...\n",
      "Calculating angular distance between successive quaternions...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "dem = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"gesture_int\"] = le.fit_transform(df[\"gesture\"])\n",
    "np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "\n",
    "df[ROT_COLS] = handle_quaternion_missing_values(df[ROT_COLS].to_numpy())\n",
    "seq_list = []\n",
    "for _, seq in df.groupby(\"sequence_id\"):\n",
    "    seq = seq.ffill().bfill().fillna(0)\n",
    "    seq_list.append(seq)\n",
    "df = pd.concat(seq_list, axis = 0)\n",
    "\n",
    "# Mirror IMU data for left-handed\n",
    "df = process_left_handed(df, dem)\n",
    "\n",
    "# Add features\n",
    "df = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df790059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 IMU features\n"
     ]
    }
   ],
   "source": [
    "meta_cols = {\n",
    "    \"gesture\", \"gesture_int\", \"sequence_type\", \n",
    "    \"behavior\", \"orientation\", \"row_id\", \"subject\", \n",
    "    \"phase\", \"sequence_id\", \"sequence_counter\"\n",
    "}\n",
    "feature_cols_all = [c for c in df.columns if c not in meta_cols]\n",
    "imu_cols  = [c for c in feature_cols_all if not (c.startswith(\"thm_\") or c.startswith(\"tof_\"))]\n",
    "np.save(EXPORT_DIR / \"feature_cols_imu.npy\", np.array(imu_cols))\n",
    "print(f\"{len(imu_cols)} IMU features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1defe849",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    TimeShift(p = 0.35, padding_mode = \"zero\", max_shift_pct = 0.25),\n",
    "    TimeStretch(p = 0.35, max_rate = 1.5, min_rate = 0.5),\n",
    "])\n",
    "\n",
    "class MixupDataset(Dataset):\n",
    "    def __init__(self, X, y, transforms, alpha = 0.2, mode = \"train\"):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "        self.alpha = alpha\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        X, y = self.X[idx], self.y[idx]\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            if self.alpha > 0:\n",
    "                lam = np.random.beta(self.alpha, self.alpha)\n",
    "                idx2 = np.random.randint(len(self.X))\n",
    "                X = lam * X + (1 - lam) * self.X[idx2]\n",
    "                y = lam * y + (1 - lam) * self.y[idx2]\n",
    "            \n",
    "            X = self.transforms(X)\n",
    "        return torch.FloatTensor(X), torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44188b0f",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3913bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualSEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding='same', bias = False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding='same', bias = False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.se = SEBlock(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, padding='same', bias = False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weights = self.attention(x).squeeze(-1)\n",
    "        weights = F.softmax(weights, dim=1).unsqueeze(-1)\n",
    "        context = torch.sum(x * weights, dim=1)\n",
    "        return context\n",
    "    \n",
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross-attention module for multi-branch feature fusion.\n",
    "    Allows each branch to attend to features from other branches.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, num_heads=8, dropout=0.1):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = feature_dim // num_heads\n",
    "        \n",
    "        assert feature_dim % num_heads == 0, \"feature_dim must be divisible by num_heads\"\n",
    "        \n",
    "        # Linear projections for queries, keys, and values for each branch\n",
    "        self.q_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.k_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.v_linear = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        \n",
    "        # Output projection\n",
    "        self.out_linear = nn.Linear(feature_dim, feature_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Layer normalization for residual connection\n",
    "        self.layer_norm = nn.LayerNorm(feature_dim)\n",
    "        \n",
    "    def forward(self, query_branch, key_value_branches):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query_branch: (B, T, C) - the branch that will be updated\n",
    "            key_value_branches: List of (B, T, C) tensors - branches to attend to\n",
    "        Returns:\n",
    "            Updated query_branch with cross-attention: (B, T, C)\n",
    "        \"\"\"\n",
    "        B, T, C = query_branch.shape\n",
    "        \n",
    "        # Create queries from the query branch\n",
    "        Q = self.q_linear(query_branch)  # (B, T, C)\n",
    "        \n",
    "        # Concatenate all key-value branches for attention\n",
    "        all_kv = torch.stack(key_value_branches, dim=1)  # (B, num_branches, T, C)\n",
    "        num_branches = all_kv.shape[1]\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        all_kv = all_kv.reshape(B, num_branches * T, C)  # (B, num_branches*T, C)\n",
    "        \n",
    "        K = self.k_linear(all_kv)  # (B, num_branches*T, C)\n",
    "        V = self.v_linear(all_kv)  # (B, num_branches*T, C)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, T, head_dim)\n",
    "        K = K.view(B, num_branches * T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, num_branches*T, head_dim)\n",
    "        V = V.view(B, num_branches * T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, num_branches*T, head_dim)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)  # (B, num_heads, T, num_branches*T)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attn_output = torch.matmul(attn_weights, V)  # (B, num_heads, T, head_dim)\n",
    "        \n",
    "        # Concatenate heads and put through final linear layer\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, C)  # (B, T, C)\n",
    "        output = self.out_linear(attn_output)\n",
    "        \n",
    "        # Residual connection and layer normalization\n",
    "        output = self.layer_norm(query_branch + output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class IMUCrossAttentionFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross-attention fusion module for three IMU branches.\n",
    "    Each branch attends to the other two branches.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim=256, num_heads=8, dropout=0.1):\n",
    "        super(IMUCrossAttentionFusion, self).__init__()\n",
    "        \n",
    "        # Cross-attention modules for each branch\n",
    "        self.cross_attn1 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "        self.cross_attn2 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "        self.cross_attn3 = CrossAttention(feature_dim, num_heads, dropout)\n",
    "        \n",
    "    def forward(self, imu1, imu2, imu3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imu1, imu2, imu3: (B, T, C) tensors from each IMU branch\n",
    "        Returns:\n",
    "            Tuple of enhanced features: (enhanced_imu1, enhanced_imu2, enhanced_imu3)\n",
    "        \"\"\"\n",
    "        # Each branch attends to the other two branches\n",
    "        enhanced_imu1 = self.cross_attn1(imu1, [imu2, imu3])\n",
    "        enhanced_imu2 = self.cross_attn2(imu2, [imu1, imu3])\n",
    "        enhanced_imu3 = self.cross_attn3(imu3, [imu1, imu2])\n",
    "        \n",
    "        return enhanced_imu1, enhanced_imu2, enhanced_imu3\n",
    "    \n",
    "class OneBranchModel(nn.Module):\n",
    "    def __init__(self, imu_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.imu_dim = imu_dim\n",
    "        \n",
    "        # IMU branchs\n",
    "        self.imu_branch1 = nn.Sequential(\n",
    "            ResidualSEBlock(12, 128, 3, drop=0.3),\n",
    "            ResidualSEBlock(128, 256, 5, drop=0.3)\n",
    "        )\n",
    "        self.imu_branch2 = nn.Sequential(\n",
    "            ResidualSEBlock(11, 128, 3, drop=0.3),\n",
    "            ResidualSEBlock(128, 256, 5, drop=0.3)\n",
    "        )\n",
    "        self.imu_branch3 = nn.Sequential(\n",
    "            ResidualSEBlock(12, 128, 3, drop=0.3),\n",
    "            ResidualSEBlock(128, 256, 5, drop=0.3)\n",
    "        )\n",
    "        \n",
    "        self.cross_attention_fusion = IMUCrossAttentionFusion(\n",
    "            feature_dim=256, num_heads=8, dropout=0.1\n",
    "        )\n",
    "\n",
    "        # BiLSTM\n",
    "        self.bilstm = nn.LSTM(256*3, 512, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.4)   \n",
    "\n",
    "        # Attention\n",
    "        self.attention = AttentionLayer(1024)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 512, bias = False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256, bias = False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        imu = x[:, :, :self.imu_dim]\n",
    "\n",
    "        imu1 = self.imu_branch1(imu[:, :, :12].transpose(1, 2)).transpose(1, 2)\n",
    "        imu2 = self.imu_branch2(imu[:, :, 12:23].transpose(1, 2)).transpose(1, 2)\n",
    "        imu3 = self.imu_branch3(imu[:, :, 23:].transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "        # Apply cross-attention fusion between branches\n",
    "        imu1, imu2, imu3 = self.cross_attention_fusion(imu1, imu2, imu3)\n",
    "\n",
    "        merged = torch.cat((imu1, imu2, imu3), dim=2)\n",
    "\n",
    "        lstm_out, _ = self.bilstm(merged)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        attended = self.attention(lstm_out)\n",
    " \n",
    "        out = self.fc_layers(attended)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_fold(fold, train_inds, val_inds):\n",
    "\n",
    "    print(f\"Train fold №{fold}\")\n",
    "\n",
    "    # Split\n",
    "    df_train, df_val = df.iloc[train_inds], df.iloc[val_inds]\n",
    "    # Pad/crop length by percentile per fold\n",
    "    seq_lengths = [len(group) for _, group in df_train.groupby(\"sequence_id\")]\n",
    "    pad_len = int(np.percentile(seq_lengths, PAD_PERCENTILE))\n",
    "    np.save(EXPORT_DIR / f\"sequence_maxlen_fold{fold}.npy\", pad_len)\n",
    "    \n",
    "    # Remove problematic sequence if it exists\n",
    "    df_train = df_train[df_train[\"sequence_id\"] != \"SEQ_011975\"]\n",
    "    df_train = df_train[~df_train[\"sequence_id\"].isin(ids2del[\"sequence_id\"])]\n",
    "    if DEL_SUBJ:\n",
    "        df_train = df_train[~df_train[\"subject\"].isin([\"SUBJ_045235\", \"SUBJ_019262\"])]\n",
    "    \n",
    "    df_val = df_val[df_val[\"sequence_id\"] != \"SEQ_011975\"]\n",
    "    if DEL_SUBJ:\n",
    "        df_val = df_val[~df_val[\"subject\"].isin([\"SUBJ_045235\", \"SUBJ_019262\"])]\n",
    "\n",
    "    # For OOF preds\n",
    "    val_to_save = pd.DataFrame({\"sequence_id\": df_val[\"sequence_id\"].unique()})\n",
    "\n",
    "    # Create sequences train\n",
    "    seq_gp = df_train.groupby(\"sequence_id\")\n",
    "    X_list, y_list = [], []\n",
    "    for _, seq in seq_gp:\n",
    "        y_list.append(seq[\"gesture_int\"].iloc[0])\n",
    "        seq = seq[imu_cols]\n",
    "        mat = seq.to_numpy()\n",
    "        X_list.append(mat)\n",
    "        \n",
    "\n",
    "    X_tr = pad_sequences(X_list, maxlen = pad_len, padding = \"pre\", truncating = \"pre\")\n",
    "    y_tr = to_categorical(y_list, num_classes = len(le.classes_))\n",
    "\n",
    "    # Class weights\n",
    "    cw_vals = compute_class_weight(\"balanced\", classes = np.arange(len(le.classes_)), y = y_list)\n",
    "\n",
    "    # Create sequences val\n",
    "    seq_gp = df_val.groupby(\"sequence_id\")\n",
    "    X_list, y_list = [], []\n",
    "    for _, seq in seq_gp:\n",
    "        y_list.append(seq[\"gesture_int\"].iloc[0])\n",
    "        seq = seq[imu_cols]\n",
    "        mat = seq.to_numpy()\n",
    "        X_list.append(mat)\n",
    "        \n",
    "\n",
    "    X_val = pad_sequences(X_list, maxlen = pad_len, padding = \"pre\", truncating = \"pre\")\n",
    "    y_val = to_categorical(y_list, num_classes = len(le.classes_))\n",
    "\n",
    "    # Model\n",
    "    model = OneBranchModel(len(imu_cols), len(le.classes_)).to(device)\n",
    "    ema_model = ModelEMA(model, decay = ema_decay, device = device)\n",
    "    print(f\"Model has {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M parameters\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR_INIT, weight_decay = WD)\n",
    "\n",
    "    if FOCAL_LOSS:\n",
    "        criterion = SmoothFocalLoss(classes=len(le.classes_))\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(\n",
    "            weight = torch.FloatTensor(cw_vals).to(device) if CLASS_WEIGHTS else None,\n",
    "            label_smoothing = 0.1\n",
    "        )\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0 = T_0)\n",
    "    \n",
    "    train_dataset = MixupDataset(X_tr, y_tr, alpha = MIXUP_ALPHA, mode = \"train\", transforms = transforms)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
    "    val_dataset = MixupDataset(X_val, y_val, mode = \"valid\", transforms = transforms)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "\n",
    "    best_val_F1 = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(X_tr.shape)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            ema_model.update(model)\n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader)\n",
    "            \n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                out = ema_model.module(batch_X)\n",
    "                val_loss += criterion(out, batch_y).item()\n",
    "                out = F.softmax(out, dim=1)\n",
    "                outputs.append(out.cpu())\n",
    "            outputs = np.concatenate(outputs)\n",
    "\n",
    "        val_loss /= len(val_loader)   \n",
    "\n",
    "        val_F1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "            pd.DataFrame({\"gesture\": le.classes_[y_val.argmax(1)]}),\n",
    "            pd.DataFrame({\"gesture\": le.classes_[outputs.argmax(1)]})\n",
    "        )\n",
    "        \n",
    "        log_message = f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.4f} \\\n",
    "            Val Loss: {val_loss:.4f} Val F1: {val_F1:.3f}\"\n",
    "        print(log_message)\n",
    "        with open(EXPORT_DIR / f\"log_1branch_fold{fold}.txt\", \"a\") as f:\n",
    "            f.write(log_message + \"\\n\")\n",
    "    \n",
    "        if val_F1 > best_val_F1:\n",
    "            best_val_F1 = val_F1\n",
    "            patience_counter = 0\n",
    "            torch.save(\n",
    "                ema_model.module.state_dict(), \n",
    "                EXPORT_DIR / f\"one_branch_mixup_best_f1_fold{fold}.pt\"\n",
    "            )\n",
    "            print(f\"Model saved with F1 score: {best_val_F1:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"Early stopping after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "    val_to_save[le.classes_] = outputs\n",
    "    val_to_save.to_csv(EXPORT_DIR / f\"1branch_val_sequences_fold{fold}.csv\", index = False)\n",
    "    print(\"Training done - artefacts saved in\", EXPORT_DIR)\n",
    "\n",
    "    return best_val_F1, val_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47617575",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits = 5, shuffle = True, random_state = SEED)\n",
    "\n",
    "best_scores = []\n",
    "oof_preds = []\n",
    "\n",
    "for fold, (train_inds, val_inds) in enumerate(group_kfold.split(df, groups = df[\"subject\"])):\n",
    "    best_score, oof_pred = train_single_fold(fold, train_inds, val_inds)\n",
    "    best_scores.append(best_score)\n",
    "    oof_preds.append(oof_pred)\n",
    "\n",
    "oof_preds = pd.concat(oof_preds, axis = 0)\n",
    "oof_preds.to_csv(EXPORT_DIR / f\"1branch_val_sequences.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77687cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(best_scores).mean()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7611240,
     "sourceId": 12090659,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.238789,
   "end_time": "2025-06-07T16:42:49.463101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-07T16:42:19.224312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
