{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install --no-deps /kaggle/input/scikit-learn-1-6-1/scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n\n#!/usr/bin/env python\n# coding: utf-8\n\n# # Importable version of https://www.kaggle.com/code/metric/cmi-2025\n\n# In[ ]:\n\n\n\"\"\"\nHierarchical macro F1 metric for the CMI 2025 Challenge.\n\nThis script defines a single entry point `score(solution, submission, row_id_column_name)`\nthat the Kaggle metrics orchestrator will call.\nIt performs validation on submission IDs and computes a combined binary & multiclass F1 score.\n\"\"\"\n\nimport pandas as pd\nfrom sklearn.metrics import f1_score\n\n\nclass ParticipantVisibleError(Exception):\n    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n    pass\n\n\nclass CompetitionMetric:\n    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n    def __init__(self):\n        self.target_gestures = [\n            'Above ear - pull hair',\n            'Cheek - pinch skin',\n            'Eyebrow - pull hair',\n            'Eyelash - pull hair',\n            'Forehead - pull hairline',\n            'Forehead - scratch',\n            'Neck - pinch skin',\n            'Neck - scratch',\n        ]\n        self.non_target_gestures = [\n            'Write name on leg',\n            'Wave hello',\n            'Glasses on/off',\n            'Text on phone',\n            'Write name in air',\n            'Feel around in tray and pull out an object',\n            'Scratch knee/leg skin',\n            'Pull air toward your face',\n            'Drink from bottle/cup',\n            'Pinch knee/leg skin'\n        ]\n        self.all_classes = self.target_gestures + self.non_target_gestures\n\n    def calculate_hierarchical_f1(\n        self,\n        sol: pd.DataFrame,\n        sub: pd.DataFrame\n    ) -> float:\n\n        # Validate gestures\n        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n        if invalid_types:\n            raise ParticipantVisibleError(\n                f\"Invalid gesture values in submission: {invalid_types}\"\n            )\n\n        # Compute binary F1 (Target vs Non-Target)\n        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n        f1_binary = f1_score(\n            y_true_bin,\n            y_pred_bin,\n            pos_label=True,\n            zero_division=0,\n            average='binary'\n        )\n\n        # Build multi-class labels for gestures\n        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n\n        # Compute macro F1 over all gesture classes\n        f1_macro = f1_score(\n            y_true_mc,\n            y_pred_mc,\n            average='macro',\n            zero_division=0\n        )\n\n        return 0.5 * f1_binary + 0.5 * f1_macro\n\n\ndef score(\n    solution: pd.DataFrame,\n    submission: pd.DataFrame,\n    row_id_column_name: str\n) -> float:\n    \"\"\"\n    Compute hierarchical macro F1 for the CMI 2025 challenge.\n\n    Expected input:\n      - solution and submission as pandas.DataFrame\n      - Column 'sequence_id': unique identifier for each sequence\n      - 'gesture': one of the eight target gestures or \"Non-Target\"\n\n    This metric averages:\n    1. Binary F1 on SequenceType (Target vs Non-Target)\n    2. Macro F1 on gesture (mapping non-targets to \"Non-Target\")\n\n    Raises ParticipantVisibleError for invalid submissions,\n    including invalid SequenceType or gesture values.\n\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> row_id_column_name = \"id\"\n    >>> solution = pd.DataFrame({'id': range(4), 'gesture': ['Eyebrow - pull hair']*4})\n    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Forehead - pull hairline']*4})\n    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n    0.5\n    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Text on phone']*4})\n    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n    0.0\n    >>> score(solution, solution, row_id_column_name=row_id_column_name)\n    1.0\n    \"\"\"\n    # Validate required columns\n    for col in (row_id_column_name, 'gesture'):\n        if col not in solution.columns:\n            raise ParticipantVisibleError(f\"Solution file missing required column: '{col}'\")\n        if col not in submission.columns:\n            raise ParticipantVisibleError(f\"Submission file missing required column: '{col}'\")\n\n    metric = CompetitionMetric()\n    return metric.calculate_hierarchical_f1(solution, submission)\n\n\nimport torch\nimport torch.distributed as dist\n\n\ndef zeropower_via_newtonschulz5(G, steps: int):\n    \"\"\"\n    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\n    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\n    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at\n    zero even beyond the point where the iteration no longer converges all the way to one everywhere\n    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T\n    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model\n    performance at all relative to UV^T, where USV^T = G is the SVD.\n    \"\"\"\n    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng\n    a, b, c = (3.4445, -4.7750,  2.0315)\n    X = G.bfloat16()\n    if G.size(-2) > G.size(-1):\n        X = X.mT\n\n    # Ensure spectral norm is at most 1\n    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n    # Perform the NS iterations\n    for _ in range(steps):\n        A = X @ X.mT\n        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng\n        X = a * X + B @ X\n    \n    if G.size(-2) > G.size(-1):\n        X = X.mT\n    return X\n\n\ndef muon_update(grad, momentum, beta=0.95, ns_steps=5, nesterov=True):\n    momentum.lerp_(grad, 1 - beta)\n    update = grad.lerp_(momentum, beta) if nesterov else momentum\n    if update.ndim == 4: # for the case of conv filters\n        update = update.view(len(update), -1)\n    update = zeropower_via_newtonschulz5(update, steps=ns_steps)\n    update *= max(1, grad.size(-2) / grad.size(-1))**0.5\n    return update\n\n\nclass Muon(torch.optim.Optimizer):\n    \"\"\"\n    Muon - MomentUm Orthogonalized by Newton-schulz\n\n    https://kellerjordan.github.io/posts/muon/\n\n    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-\n    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal\n    matrix. For efficient orthogonalization we use a Newton-Schulz iteration, which has the\n    advantage that it can be stably run in bfloat16 on the GPU.\n\n    Muon should only be used for hidden weight layers. The input embedding, final output layer,\n    and any internal gains or biases should be optimized using a standard method such as AdamW.\n    Hidden convolutional weights can be trained using Muon by viewing them as 2D and then\n    collapsing their last 3 dimensions.\n\n    Arguments:\n        lr: The learning rate, in units of spectral norm per update.\n        weight_decay: The AdamW-style weight decay.\n        momentum: The momentum. A value of 0.95 here is usually fine.\n    \"\"\"\n    def __init__(self, params, lr=0.02, weight_decay=0, momentum=0.95):\n        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum)\n        assert isinstance(params, list) and len(params) >= 1 and isinstance(params[0], torch.nn.Parameter)\n        params = sorted(params, key=lambda x: x.size(), reverse=True)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            params = group[\"params\"]\n            params_pad = params + [torch.empty_like(params[-1])] * (dist.get_world_size() - len(params) % dist.get_world_size())\n            for base_i in range(len(params))[::dist.get_world_size()]:\n                if base_i + dist.get_rank() < len(params):\n                    p = params[base_i + dist.get_rank()]\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"momentum_buffer\"] = torch.zeros_like(p)\n                    update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n                dist.all_gather(params_pad[base_i:base_i + dist.get_world_size()], params_pad[base_i + dist.get_rank()])\n\n        return loss\n\n\nclass SingleDeviceMuon(torch.optim.Optimizer):\n    \"\"\"\n    Muon variant for usage in non-distributed settings.\n    \"\"\"\n    def __init__(self, params, lr=0.02, weight_decay=0, momentum=0.95):\n        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"momentum_buffer\"] = torch.zeros_like(p)\n                update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n\n        return loss\n\n\ndef adam_update(grad, buf1, buf2, step, betas, eps):\n    buf1.lerp_(grad, 1 - betas[0])\n    buf2.lerp_(grad.square(), 1 - betas[1])\n    buf1c = buf1 / (1 - betas[0]**step)\n    buf2c = buf2 / (1 - betas[1]**step)\n    return buf1c / (buf2c.sqrt() + eps)\n\n\nclass MuonWithAuxAdam(torch.optim.Optimizer):\n    \"\"\"\n    Distributed Muon variant that can be used for all parameters in the network, since it runs an\n    internal AdamW for the parameters that are not compatible with Muon. The user must manually\n    specify which parameters shall be optimized with Muon and which with Adam by passing in a\n    list of param_groups with the `use_muon` flag set.\n\n    The point of this class is to allow the user to have a single optimizer in their code, rather\n    than having both a Muon and an Adam which each need to be stepped.\n\n    You can see an example usage below:\n\n    https://github.com/KellerJordan/modded-nanogpt/blob/master/records/052525_MuonWithAuxAdamExample/b01550f9-03d8-4a9c-86fe-4ab434f1c5e0.txt#L470\n    ```\n    hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and \"embed\" not in n]\n    embed_params = [p for n, p in model.named_parameters() if \"embed\" in n]\n    scalar_params = [p for p in model.parameters() if p.ndim < 2]\n    head_params = [model.lm_head.weight]\n\n    from muon import MuonWithAuxAdam\n    adam_groups = [dict(params=head_params, lr=0.22), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]\n    adam_groups = [dict(**g, betas=(0.8, 0.95), eps=1e-10, use_muon=False) for g in adam_groups]\n    muon_group = dict(params=hidden_matrix_params, lr=0.05, momentum=0.95, use_muon=True)\n    param_groups = [*adam_groups, muon_group]\n    optimizer = MuonWithAuxAdam(param_groups)\n    ```\n    \"\"\"\n    def __init__(self, param_groups):\n        for group in param_groups:\n            assert \"use_muon\" in group\n            if group[\"use_muon\"]:\n                group[\"params\"] = sorted(group[\"params\"], key=lambda x: x.size(), reverse=True)\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 0.02)\n                group[\"momentum\"] = group.get(\"momentum\", 0.95)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"momentum\", \"weight_decay\", \"use_muon\"])\n            else:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 3e-4)\n                group[\"betas\"] = group.get(\"betas\", (0.9, 0.95))\n                group[\"eps\"] = group.get(\"eps\", 1e-10)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"betas\", \"eps\", \"weight_decay\", \"use_muon\"])\n        super().__init__(param_groups, dict())\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            if group[\"use_muon\"]:\n                params = group[\"params\"]\n                params_pad = params + [torch.empty_like(params[-1])] * (dist.get_world_size() - len(params) % dist.get_world_size())\n                for base_i in range(len(params))[::dist.get_world_size()]:\n                    if base_i + dist.get_rank() < len(params):\n                        p = params[base_i + dist.get_rank()]\n                        state = self.state[p]\n                        if len(state) == 0:\n                            state[\"momentum_buffer\"] = torch.zeros_like(p)\n                        update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                        p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                        p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n                    dist.all_gather(params_pad[base_i:base_i + dist.get_world_size()], params_pad[base_i + dist.get_rank()])\n            else:\n                for p in group[\"params\"]:\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"exp_avg\"] = torch.zeros_like(p)\n                        state[\"exp_avg_sq\"] = torch.zeros_like(p)\n                        state[\"step\"] = 0\n                    state[\"step\"] += 1\n                    update = adam_update(p.grad, state[\"exp_avg\"], state[\"exp_avg_sq\"],\n                                         state[\"step\"], group[\"betas\"], group[\"eps\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update, alpha=-group[\"lr\"])\n\n        return loss\n\n\nclass SingleDeviceMuonWithAuxAdam(torch.optim.Optimizer):\n    \"\"\"\n    Non-distributed variant of MuonWithAuxAdam.\n    \"\"\"\n    def __init__(self, param_groups):\n        for group in param_groups:\n            assert \"use_muon\" in group\n            if group[\"use_muon\"]:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 0.02)\n                group[\"momentum\"] = group.get(\"momentum\", 0.95)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"momentum\", \"weight_decay\", \"use_muon\"])\n            else:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 3e-4)\n                group[\"betas\"] = group.get(\"betas\", (0.9, 0.95))\n                group[\"eps\"] = group.get(\"eps\", 1e-10)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"betas\", \"eps\", \"weight_decay\", \"use_muon\"])\n        super().__init__(param_groups, dict())\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            if group[\"use_muon\"]:\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        continue\n                        \n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"momentum_buffer\"] = torch.zeros_like(p)\n                    update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n            else:\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        continue\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"exp_avg\"] = torch.zeros_like(p)\n                        state[\"exp_avg_sq\"] = torch.zeros_like(p)\n                        state[\"step\"] = 0\n                    state[\"step\"] += 1\n                    update = adam_update(p.grad, state[\"exp_avg\"], state[\"exp_avg_sq\"],\n                                         state[\"step\"], group[\"betas\"], group[\"eps\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update, alpha=-group[\"lr\"])\n\n        return loss\n\nfrom torch.optim.lr_scheduler import _LRScheduler\nclass ConstantCosineLR(_LRScheduler):\n    \"\"\"\n    Constant learning rate followed by CosineAnnealing.\n    \"\"\"\n    def __init__(\n        self, \n        optimizer,\n        total_steps, \n        pct_cosine, \n        last_epoch=-1,\n        ):\n        self.total_steps = total_steps\n        self.milestone = int(total_steps * (pct_cosine))\n        self.cosine_steps = max(total_steps - self.milestone, 1)\n        self.min_lr = 0\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        step = self.last_epoch + 1\n        if step <= self.milestone:\n            factor = 1.\n        else:\n            s = step - self.milestone\n            factor = 0.5 * (1 + math.cos(math.pi * s / self.cosine_steps))\n        return [lr * factor for lr in self.base_lrs]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nimport random, math\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nimport sys\nsys.path.append('/root/autodl-tmp/')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import StratifiedKFold\nfrom timm.scheduler import CosineLRScheduler\nfrom scipy.signal import firwin\nimport polars as pl\nimport numpy as np\nimport random\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.spatial.transform import Rotation as R\nfrom tqdm.auto import tqdm \n\n\n\n\nif os.path.exists(\"../input/cmi-detect-behavior-with-sensor-data\"):\n    test_path1 = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv'\n    test_path2 = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\nelse:\n    if os.path.exists(\"./cmi-detect-behavior-with-sensor-data/\"):\n        test_path1 = './cmi-detect-behavior-with-sensor-data/test.csv'\n        test_path2 = './cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n    else:\n        test_path1 = './test.csv'\n        test_path2 = './test_demographics.csv'\n\nclass model_zhou_v1:\n    def __init__(self, kaggle_input_path=\"/kaggle/input/cmi3v23\"):\n        self.models = []\n\n        import os\n        if os.path.exists(\"../input/cmi-detect-behavior-with-sensor-data\"):\n            self.TRAIN = False                     \n            self.RAW_DIR = Path(\"../input/cmi-detect-behavior-with-sensor-data\")\n            self.PRETRAINED_DIR = Path(kaggle_input_path) \n            self.EXPORT_DIR = Path(\"./\")                                   \n        else:\n            if os.path.exists(\"./cmi-detect-behavior-with-sensor-data/\"):\n                self.TRAIN = True                     \n                self.RAW_DIR = Path(\"./cmi-detect-behavior-with-sensor-data/\")\n                self.PRETRAINED_DIR = Path(kaggle_input_path) \n                self.EXPORT_DIR = Path(\"./\")                                  \n            else:\n                self.TRAIN = True                    \n                self.RAW_DIR = Path(\"./\")\n                self.EXPORT_DIR = Path(\"./\")\n                self.PRETRAINED_DIR = Path(kaggle_input_path) \n\n        self.VALIDATION = False\n        self.SEED = 42\n\n        self.BATCH_SIZE = 64 * 1\n        self.PAD_PERCENTILE = 128\n        self.maxlen = self.PAD_PERCENTILE\n        self.LR_INIT = 1e-3\n        self.WD = 2e-1\n        \n        self.PATIENCE = 40\n        self.random_state = self.SEED\n        \n        self.tof_mode = 4\n        \n        self.FOLDS = 5\n        self.TRAIN_FOLDS = [0, 1, 2, 3, 4]\n        \n        self.EPOCHS = 160\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"▶ imports ready · pytorch {torch.__version__} · device: {self.device}\")\n    \n    def create_model(self, param_a, param_b, param_c, param_d):\n        class ImuFeatureExtractor(nn.Module):\n            def __init__(self, ):\n                super().__init__()\n                k = 15\n                self.lpf_all = nn.Conv1d(7, 7, kernel_size=7, padding=7//2, groups=7, bias=False)\n        \n                self.lpf_acc  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n                self.lpf_gyro = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        \n                self.lpf_acc2  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n                self.lpf_gyro2 = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        \n            def forward(self, imu):\n                # imu: \n                B, C, T = imu.shape\n                acc  = imu[:, 0:3, :]                 # acc_x, acc_y, acc_z\n                gyro = imu[:, 3:6, :]                 # gyro_x, gyro_y, gyro_z\n                extra = imu[:, 6:, :]\n        \n                # 1) magnitude\n                acc_mag  = torch.norm(acc,  dim=1, p=2, keepdim=True)          # (B,1,T)\n                gyro_mag = torch.norm(gyro, dim=1, p=2, keepdim=True)\n        \n                # 1.2) magnitude\n                acc2 = acc/acc_mag.clip(1e-12)\n                gyro2 = gyro/gyro_mag.clip(1e-12)\n        \n        \n                acc_lpf2  = self.lpf_acc2(acc2)\n                acc_hpf2  = acc2 - acc_lpf2\n                gyro_lpf2 = self.lpf_gyro2(gyro2)\n                gyro_hpf2 = gyro2 - gyro_lpf2\n                \n        \n                # 1.3) magnitude\n                acc_mag2  = torch.norm(acc,  dim=1, p=1, keepdim=True)          # (B,1,T)\n                gyro_mag2 = torch.norm(gyro, dim=1, p=1, keepdim=True)\n        \n                # 1.4) magnitude\n                acc3 = acc/acc_mag2.clip(1e-12)\n                gyro3 = gyro/gyro_mag2.clip(1e-12)\n        \n                # 2) jerk \n                jerk = F.pad(acc[:, :, 1:] - acc[:, :, :-1], (1,0))       # (B,3,T)\n                gyro_delta = F.pad(gyro[:, :, 1:] - gyro[:, :, :-1], (1,0))\n        \n                # 2) jerk level2\n                jerk2 = F.pad(acc[:, :, 2:] + acc[:, :, :-2] - acc[:, :, 1:-1] * 2, (1,1))       # (B,3,T)\n                gyro_delta2 = F.pad(gyro[:, :, 2:] + gyro[:, :, :-2] - gyro[:, :, 1:-1] * 2, (1,1))\n        \n                # 3) energy\n                acc_pow  = acc ** 2\n                gyro_pow = gyro ** 2\n        \n                # 4) LPF / HPF \n                acc_lpf  = self.lpf_acc(acc)\n                acc_hpf  = acc - acc_lpf\n                gyro_lpf = self.lpf_gyro(gyro)\n                gyro_hpf = gyro - gyro_lpf\n        \n        \n                imu_hpf = imu - self.lpf_all(imu)\n        \n                features = [\n                    acc, gyro,\n                    \n                    # acc2, gyro2,\n                    acc_mag, gyro_mag,\n                    \n                    acc3, gyro3,\n                    acc_mag2, gyro_mag2,\n                    \n                    jerk, gyro_delta,\n                    jerk2, gyro_delta2, \n                    \n                    acc_pow, gyro_pow,\n                    \n                    acc_lpf, acc_hpf,\n                    gyro_lpf, gyro_hpf,\n        \n                    acc_lpf2, acc_hpf2,\n                    gyro_lpf2, gyro_hpf2,\n        \n                    imu_hpf,\n        \n                    extra, \n                    \n                ]\n        \n                return torch.cat(features, dim=1)  # (B, C_out, T)\n                \n        class SEBlock(nn.Module):\n            def __init__(self, channels, reduction=8):\n                super().__init__()\n                self.squeeze = nn.AdaptiveAvgPool1d(1)\n                self.excitation = nn.Sequential(\n                    nn.Linear(channels, channels // reduction, bias=False),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(channels // reduction, channels, bias=False),\n                    nn.Sigmoid()\n                )\n            \n            def forward(self, x):\n                b, c, _ = x.size()\n                y = self.squeeze(x).view(b, c)\n                y = self.excitation(y).view(b, c, 1)\n                return x * y.expand_as(x)\n\n        class ResidualSECNNBlock(nn.Module):\n            def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3, weight_decay=1e-4):\n                super().__init__()\n                \n                # First conv block\n                self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n                self.bn1 = nn.BatchNorm1d(out_channels)\n                \n                # Second conv block\n                self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n                self.bn2 = nn.BatchNorm1d(out_channels)\n                \n                # SE block\n                self.se = SEBlock(out_channels)\n                \n                # Shortcut connection\n                self.shortcut = nn.Sequential()\n                if in_channels != out_channels:\n                    self.shortcut = nn.Sequential(\n                        nn.Conv1d(in_channels, out_channels, 1, bias=False),\n                        nn.BatchNorm1d(out_channels)\n                    )\n                self.pool_size = pool_size\n                self.pool = nn.MaxPool1d(pool_size)\n                self.dropout = nn.Dropout(dropout)\n        \n                self.act = nn.ReLU()\n                \n            def forward(self, x):\n                shortcut = self.shortcut(x)\n                \n                # First conv\n                out = self.act(self.bn1(self.conv1(x)))\n                # Second conv\n                out = self.bn2(self.conv2(out))\n                \n                # SE block\n                out = self.se(out)\n                \n                # Add shortcut\n                out += shortcut\n                out = self.act(out)\n                \n                # Pool and dropout\n                if self.pool_size>1:\n                    out = self.pool(out)\n                out = self.dropout(out)\n                \n                return out\n\n        class AttentionLayer(nn.Module):\n            def __init__(self, hidden_dim):\n                super().__init__()\n                self.attention = nn.Linear(hidden_dim, 1)\n                \n            def forward(self, x):\n                # x shape: (batch, seq_len, hidden_dim)\n                scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n                weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n                context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n                return context\n\n\n\n        tof_mode = self.tof_mode\n        \n        class TwoBranchModel(nn.Module):\n            def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n                super().__init__()\n                self.feature_engineering = feature_engineering\n                if feature_engineering:\n                    self.imu_fe = ImuFeatureExtractor(**kwargs)\n                    imu_dim = 32 + 1 + 14 + 7 + 6 + 6\n                else:\n                    self.imu_fe = nn.Identity()\n                    imu_dim = imu_dim_raw   \n                \n                self.imu_dim = imu_dim\n                self.tof_dim = tof_dim\n        \n                self.fir_nchan = 7 + 7\n                self.thm_nchan = 5\n                self.tof_nchan = 5 * (9 + 4 * tof_mode)\n        \n                weight_decay = 3e-3\n        \n                \n                # IMU deep branch\n                self.imu_block1 = ResidualSECNNBlock(imu_dim * 1, 160, 3, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                self.imu_block2 = ResidualSECNNBlock(160, 256, 3, dropout=dropouts[1], pool_size=1, weight_decay=weight_decay)\n        \n                self.imu_block12 = ResidualSECNNBlock(imu_dim * 1, 160, 3, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                self.imu_block22 = ResidualSECNNBlock(160, 256, 3, dropout=dropouts[1], pool_size=1, weight_decay=weight_decay)\n        \n                self.thm_block = nn.Sequential(\n                    ResidualSECNNBlock(self.thm_nchan * 1, 32, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay),\n                    ResidualSECNNBlock(32, 32, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                )\n                \n                self.tof_block = nn.Sequential(\n                    ResidualSECNNBlock(self.tof_nchan * 1, 64, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay),\n                    ResidualSECNNBlock(64, 64, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                )\n        \n                self.emb_all = 256 + 256 + 32 + 64\n        \n                self.dropout1d = nn.Dropout1d(0.15)\n                \n                # BiLSTM\n                self.dim_lstm = 256\n                self.dim_encoder = self.dim_lstm * 2\n        \n                self.bilstm = nn.LSTM(self.emb_all, self.dim_lstm, num_layers=1, bidirectional=True, batch_first=True)\n            \n                self.lstm_dropout = nn.Dropout(dropouts[4])\n        \n                self.output2 = nn.Linear(self.dim_encoder, 5)\n                \n                # Dense layers\n            \n                self.dense1 = nn.Linear(self.dim_encoder * 2, 512, bias=False)\n                self.bn_dense1 = nn.BatchNorm1d(512)\n                self.drop1 = nn.Dropout(dropouts[5])\n                \n                self.dense2 = nn.Linear(512, 256, bias=False)\n                self.bn_dense2 = nn.BatchNorm1d(256)\n                self.drop2 = nn.Dropout(dropouts[6])\n        \n                self.output3 = nn.Linear(256, 5)\n                self.classifier = nn.Linear(256, n_classes)\n        \n                self.scale = nn.Parameter(torch.ones((1, 256, 1)))\n                self.bias = nn.Parameter(torch.zeros((1, 256, 1)))\n        \n                self.scale2 = nn.Parameter(torch.ones((1, 256, 1)))\n                self.bias2 = nn.Parameter(torch.zeros((1, 256, 1)))\n        \n                self.scale3 = nn.Parameter(torch.ones((1, 256, 1)))\n                self.bias3 = nn.Parameter(torch.zeros((1, 256, 1)))\n        \n                self.scale4 = nn.Parameter(torch.ones((1, 512, 1)))\n                self.bias4 = nn.Parameter(torch.zeros((1, 512, 1)))\n        \n                self.act = nn.GELU()\n                \n            def forward(self, x, ):\n                # Split input\n        \n                mask_all = (x.abs().max(-1)[0]!=0).float()[:,:,None]\n                mask_all_trans = mask_all.transpose(1, 2)\n                \n                imu = x[:, :, :self.fir_nchan//2].transpose(1, 2)  # (batch, imu_dim, seq_len)\n                imu2 = x[:, :, self.fir_nchan//2:self.fir_nchan].transpose(1, 2)\n                \n                thm = x[:, :, self.fir_nchan:self.fir_nchan + self.thm_nchan].transpose(1, 2)  # (batch, thm_dim, seq_len)\n                tof = x[:, :, self.fir_nchan + self.thm_nchan:].transpose(1, 2)  # (batch, tof_dim, seq_len)\n        \n                imu = self.imu_fe(imu)   # (B, imu_dim, T)\n                imu2 = self.imu_fe(imu2)   # (B, imu_dim, T)\n                \n                imu = (imu * self.scale[:,:imu.shape[1],:] + self.bias[:,:imu.shape[1],:]) * mask_all.transpose(1, 2)\n                imu2 = (imu2 * self.scale2[:,:imu2.shape[1],:] + self.bias2[:,:imu2.shape[1],:]) * mask_all.transpose(1, 2)\n                \n                thm = (thm * self.scale3[:,:thm.shape[1],:] + self.bias3[:,:thm.shape[1],:]) * mask_all.transpose(1, 2)\n                tof = (tof * self.scale4[:,:tof.shape[1],:] + self.bias4[:,:tof.shape[1],:]) * mask_all.transpose(1, 2)\n                \n        \n                thm = self.dropout1d(thm)\n                tof = self.dropout1d(tof)\n                imu = self.dropout1d(imu)\n                imu2 = self.dropout1d(imu2)\n                \n        \n                thm = self.thm_block(thm)\n                tof = self.tof_block(tof)\n        \n                \n                # IMU branch\n                x1 = self.imu_block1(imu)\n                x1 = self.imu_block2(x1)\n        \n                x12 = self.imu_block12(imu2)\n                x12 = self.imu_block22(x12)\n        \n                x1 = torch.cat((x1, x12, thm, tof), 1)\n        \n                merged = x1.transpose(1, 2)  # (batch, seq_len, 256)\n                \n                # BiLSTM\n                lstm_out, _ = self.bilstm(merged)\n        \n                logits2 = self.output2(self.lstm_dropout(lstm_out))\n                \n                attended = torch.cat(((lstm_out).max(1)[0], (lstm_out).mean(1), ), -1)\n                attended = self.lstm_dropout(attended)\n                \n                # Dense layers\n                x = self.act(self.bn_dense1(self.dense1(attended)))\n                x = self.drop1(x)\n                x = self.act(self.bn_dense2(self.dense2(x)))\n                x = self.drop2(x)\n                \n                # Classification\n                logits = (self.classifier(x))\n                logits3 = (self.output3(x))\n        \n                if not self.training:\n                    return logits\n                \n                return logits, logits2, logits3\n\n\n        return TwoBranchModel(param_a, param_b, param_c, param_d)\n\n    def preprocess_sequence(self, df_seq: pd.DataFrame, feature_cols: list, scaler: StandardScaler):\n        \"\"\"Normalizes and cleans the time series sequence\"\"\"\n        mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n        return (mat).astype('float32')\n        \n    def pad_sequences_torch(self, sequences, maxlen, padding='pre', truncating='pre', value=0.0):\n        \"\"\"PyTorch equivalent of Keras pad_sequences\"\"\"\n        result = []\n        for seq in sequences:\n            if len(seq) >= maxlen:\n                if truncating == 'post':\n                    seq = seq[:maxlen]\n                else:  # 'pre'\n                    seq = seq[-maxlen:]\n            else:\n                pad_len = maxlen - len(seq)\n                if padding == 'post':\n                    seq = np.concatenate([seq, np.full((pad_len, seq.shape[1]), value)])\n                else:  # 'pre'\n                    seq = np.concatenate([np.full((pad_len, seq.shape[1]), value), seq])\n            result.append(seq)\n        return np.array(result, dtype=np.float32)\n        \n    \n    def train(self, ):\n        class CMI3Dataset(Dataset):\n            def __init__(self,\n                         X_list,\n                         y_list, y_list2, y_list3,\n                         maxlen,\n                         mode=\"train\",\n                         imu_dim=7,\n                         augment=None,\n                         epoch_multiplier=1,\n                        ):\n                self.X_list = X_list\n                self.mode = mode\n                self.y_list = y_list\n                self.y_list2 = y_list2\n                self.y_list3 = y_list3\n                self.maxlen = maxlen\n                self.imu_dim = imu_dim     \n                self.augment = augment\n                self.epoch_multiplier = epoch_multiplier\n        \n            def pad_sequences_torch(self, seq, maxlen, padding='post', truncating='post', value=0.0):\n        \n                if seq.shape[0] >= maxlen:\n                    if truncating == 'post':\n                        seq = seq[:maxlen]\n                    else:  # 'pre'\n                        seq = seq[-maxlen:]\n                else:\n                    pad_len = maxlen - seq.shape[0]\n                    if padding == 'post':\n                        seq = np.concatenate([seq, np.full((pad_len, seq.shape[1]), value)])\n                    else:  # 'pre'\n                        seq = np.concatenate([np.full((pad_len, seq.shape[1]), value), seq])\n                return seq  \n                \n            def __getitem__(self, index):\n                X = self.X_list[index//self.epoch_multiplier]\n                y = self.y_list[index//self.epoch_multiplier]\n                y2 = self.y_list2[index//self.epoch_multiplier]\n                y3 = self.y_list3[index//self.epoch_multiplier]\n        \n                return X, y, y2, y3\n            \n            def __len__(self):\n                return len(self.X_list) * self.epoch_multiplier\n\n        class EMA:\n            def __init__(self, model, decay=0.999):\n                self.decay = decay\n                self.shadow = {}\n                self.backup = {}\n        \n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        self.shadow[name] = param.data.clone()\n        \n            def update(self, model):\n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        assert name in self.shadow\n                        new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n                        self.shadow[name] = new_average.clone()\n        \n            def apply_shadow(self, model):\n                self.backup = {}\n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        self.backup[name] = param.data.clone()\n                        param.data = self.shadow[name]\n        \n            def restore(self, model):\n                for name, param in model.named_parameters():\n                    if param.requires_grad and name in self.backup:\n                        param.data = self.backup[name]\n                self.backup = {}\n\n        def set_seed(seed: int = 42):\n            import numpy as np\n            \n            random.seed(seed)\n        \n            os.environ['PYTHONHASHSEED'] = str(seed)\n        \n            np.random.seed(seed)\n        \n            torch.manual_seed(seed)\n            torch.cuda.manual_seed(seed)\n            torch.cuda.manual_seed_all(seed) \n            # torch.backends.cudnn.deterministic = True\n            # torch.backends.cudnn.benchmark = False\n            # torch.use_deterministic_algorithms(True)\n        \n        set_seed(self.SEED)\n\n        class RDROPLoss(nn.Module):\n            \"\"\"\n            RDROP损失函数实现\n            结合原始损失和KL散度约束\n            \"\"\"\n            def __init__(self, alpha=0.5):\n                super(RDROPLoss, self).__init__()\n                self.alpha = alpha  # KL损失的权重系数\n                self.kl_div = nn.KLDivLoss(reduction='batchmean')\n        \n            def forward(self, logits1, logits2):\n                # KL散度约束：两次次输出分布的一致性\n                p1 = F.log_softmax(logits1, dim=1)\n                p2 = F.softmax(logits2, dim=1)\n                kl_loss1 = self.kl_div(p1, p2)\n                \n                p2 = F.log_softmax(logits2, dim=1)\n                p1 = F.softmax(logits1, dim=1)\n                kl_loss2 = self.kl_div(p2, p1)\n                \n                # 总损失 = 分类损失 + alpha * KL散度损失\n                total_loss = self.alpha * (kl_loss1 + kl_loss2)\n                return total_loss\n                \n        import numpy as np\n        import pandas as pd\n        from scipy.spatial.transform import Rotation as R\n        from tqdm.auto import tqdm \n        \n        print(\"▶ TRAIN MODE – loading dataset …\")\n        df = pd.read_csv(self.RAW_DIR / \"train.csv\")\n    \n        dict_ = dict(zip(df['subject'].unique(), list(range(df['subject'].nunique()))))\n        df['subject_id_new'] = df['subject'].map(dict_)\n    \n        df = df[~df['subject'].isin({'SUBJ_045235', 'SUBJ_019262'})]\n    \n        dict_behavior = {'Relaxes and moves hand to target location': 1,\n                         'Hand at target location': 2,\n                         'Performs gesture': 3,\n                         'Moves hand to target location': 4}\n        \n        dict_orientation = {'Seated Lean Non Dom - FACE DOWN': 1,\n                         'Lie on Side - Non Dominant': 2,\n                         'Seated Straight': 3,\n                         'Lie on Back': 4}\n    \n        df['bid'] = df['behavior'].map(dict_behavior)\n        df['oid'] = df['orientation'].map(dict_orientation)\n    \n        df, new_feat_cols, new_feat_cols2 = self.get_new_features(df)\n    \n        # Label encoding\n        le = LabelEncoder()\n        df['gesture_int'] = le.fit_transform(df['gesture'])\n        np.save(self.EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n    \n        # Feature list\n        meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n                     'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter', 'subject_id_new'}\n        feature_cols = [c for c in df.columns if c not in meta_cols]\n        imu_cols = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n        # tof_cols = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n    \n        thm_cols = [c for c in feature_cols if c.startswith('thm_')]\n        print(thm_cols)\n        \n        tof_cols = [] # [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n    \n        imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w',]\n        \n        feature_cols = imu_cols + new_feat_cols + thm_cols + new_feat_cols2\n        \n        print(f\"  IMU {len(imu_cols)+len(new_feat_cols)} | THM {len(thm_cols)} | TOF {len(new_feat_cols2)}  | total {len(feature_cols)} features\")\n    \n        # Save feature_cols\n        np.save(self.EXPORT_DIR / \"feature_cols.npy\", np.array(feature_cols))\n        pad_len = self.PAD_PERCENTILE\n        \n        # Group sequences\n        seq_gp = df.groupby('sequence_id')\n        X_list_raw, y_list, id_list, subject_list, y2list, y3list = [], [], [], [], [], []\n        for seq_id, seq in seq_gp:\n            mat = seq[feature_cols].ffill().bfill().fillna(0).values\n            X_list_raw.append(mat)\n            y_list.append(seq['gesture_int'].iloc[0])\n            id_list.append(seq_id)\n            subject_list.append(seq['subject_id_new'].iloc[0])\n    \n            if len(seq) < pad_len:\n                bid = np.zeros(pad_len)\n                bid[-len(seq):] = seq['bid'].values.ravel()\n            else:\n                bid = seq['bid'].values.ravel()[-pad_len:]\n            \n            y2list.append(bid)\n            y3list.append(seq['oid'].iloc[0])\n    \n        pad_len = self.PAD_PERCENTILE\n        np.save(self.EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    \n        id_list = np.array(id_list)\n        y_list_all = np.eye(len(le.classes_))[y_list].astype(np.float32)  # one-hot\n    \n        y_list_all2 = np.vstack(y2list).astype(int)\n        y_list_all2 = (np.eye(5)[y_list_all2.reshape(-1, 1)]).reshape(-1, pad_len, 5).astype(np.float32)\n        y_list_all3 = np.eye(5)[y3list].astype(np.float32)\n    \n        augmenter = None\n        metrics = []\n    \n        criterion_rdrop = RDROPLoss(alpha=0.5)\n\n        from sklearn.model_selection import GroupKFold\n        gkf = GroupKFold(\n                         n_splits=self.FOLDS, \n                         shuffle=True, \n                         random_state=self.random_state\n                        )\n    \n        def clipped_cross_entropy(logits, y, clipval=0.6, num=18):\n            return -torch.sum(F.log_softmax(logits, dim=1) * y.clip((1-clipval)/num, clipval), dim=1).mean() \n            \n        idlistall = []\n        targetfinalall = []\n        predimuonlyall = []\n        predallfeatall = []\n        for fold, (train_idx, val_idx) in enumerate(gkf.split(id_list, id_list, groups=subject_list)):\n            \n        # skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=self.random_state)\n        # for fold, (train_idx, val_idx) in enumerate(skf.split(id_list, np.argmax(y_list_all, axis=1))):  \n            \n            if fold not in self.TRAIN_FOLDS:\n                continue\n    \n            print(f\"\\n▶ Fold {fold}\")\n            \n            X_list_scaled = [x for x in X_list_raw]\n            X_list_all = self.pad_sequences_torch(X_list_scaled, maxlen=pad_len, padding='pre', truncating='pre')\n    \n            # Prepare train/val sets\n            train_list = X_list_all[train_idx]\n            train_y_list = y_list_all[train_idx]\n            train_y_list2 = y_list_all2[train_idx]\n            train_y_list3 = y_list_all3[train_idx]\n    \n            \n            val_list = X_list_all[val_idx]\n            val_y_list = y_list_all[val_idx]\n    \n            val_y_list2 = y_list_all2[val_idx]\n            val_y_list3 = y_list_all3[val_idx]\n\n            id_list_valid = id_list[val_idx]\n            idlistall.append(id_list_valid)\n    \n            # Data loaders\n            train_dataset = CMI3Dataset(train_list, train_y_list, train_y_list2, train_y_list3, pad_len, mode=\"train\", imu_dim=len(imu_cols),\n                                        augment=augmenter)\n            train_loader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=6, drop_last=False, pin_memory=True)\n            \n            val_dataset = CMI3Dataset(val_list, val_y_list, val_y_list2, val_y_list3, pad_len, mode=\"val\")\n            val_loader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, shuffle=False, num_workers=6, drop_last=False, pin_memory=True)\n\n            device = self.device\n            \n            # Model & EMA\n            model = self.create_model(pad_len, len(imu_cols), len(tof_cols), len(le.classes_)).to(device)\n\n            if self.VALIDATION==True:\n                checkpoint = torch.load(self.PRETRAINED_DIR / f'gesture_two_branch_fold{fold}.pth', map_location=device)\n                model.load_state_dict({k.replace('_orig_mod.', ''):v for k, v in checkpoint['model_state_dict'].items()})\n            \n            ema = EMA(model, decay=0.998)\n    \n            # Optimizer\n            hidden_weights = [p for p in model.parameters() if p.ndim >= 2 and p.requires_grad]\n            hidden_gains_biases = [p for p in model.parameters() if p.ndim < 2 and p.requires_grad]\n            param_groups = [\n                dict(params=hidden_weights, use_muon=True, lr=0.005, weight_decay=self.WD),\n                dict(params=hidden_gains_biases, use_muon=False, lr=self.LR_INIT, betas=(0.9, 0.95), weight_decay=self.WD),\n            ]\n            optimizer = SingleDeviceMuonWithAuxAdam(param_groups)\n    \n            nbatch = len(train_loader)\n            nsteps = self.EPOCHS * nbatch\n    \n            scheduler = ConstantCosineLR(optimizer, nsteps, 0.)    \n            print(\"▶ Starting training...\")\n    \n            best_val_acc = 0\n            for epoch in tqdm(range(self.EPOCHS)):\n                model.train()\n                train_preds, train_targets = [], []\n                train_loss = 0.0\n    \n                for X, y, y2, y3 in train_loader:\n                    if self.VALIDATION==True:\n                        break\n                        \n                    BS = X.shape[0]\n    \n                    X_imuonly = X[:].clone()\n                    X_imuonly[:, :, 14:] = 0.0\n                    \n                    X, X_imuonly, y = X.float().to(device), X_imuonly.float().to(device), y.to(device)\n                    y2, y3 = y2.float().to(device), y3.to(device)\n                    \n                    optimizer.zero_grad()\n                    \n                    logits, logits2, logits3 = model(X)\n                    # logits_, logits2_, logits3_ = model(X_imuonly)\n    \n                    clipval = 0.6\n                    loss = clipped_cross_entropy(logits, y, clipval, 18) \n                    loss += clipped_cross_entropy(logits2, y2, clipval, 5)  * 0.4\n                    loss += clipped_cross_entropy(logits3, y3, clipval, 5)  * 0.4\n    \n                    # loss += clipped_cross_entropy(logits_, y, clipval, 18) * 0.1\n                    # loss += clipped_cross_entropy(logits2_, y2, clipval, 5)  * 0.4 * 0.1\n                    # loss += clipped_cross_entropy(logits3_, y3, clipval, 5)  * 0.4 * 0.1\n    \n                    # loss += 1 * (criterion_rdrop(logits, logits_) + criterion_rdrop(logits2, logits2_) + criterion_rdrop(logits3, logits3_))\n                    \n                    loss.backward()\n                    \n                    optimizer.step()\n                    ema.update(model)\n    \n                    train_preds.append(logits.argmax(dim=1).cpu().numpy())\n                    train_targets.append(y.argmax(dim=1).cpu().numpy())\n    \n                    scheduler.step()\n                    train_loss += loss.item()\n                \n                model.eval()\n                ema.apply_shadow(model)\n                \n                val_loss = 0.0\n                val_preds, val_targets = [], []\n                val_preds_imuonly, val_targets_imuonly = [], []\n                val_preds_all, val_targets_all = [], []\n\n                val_preds_logits = []\n                val_preds_imuonly_logits = []\n\n                \n                with torch.inference_mode():\n                    for X, y, y2, y3 in val_loader:\n                        X_imuonly = X[:].clone()\n                        X_imuonly[:, :, 14:] = 0.0\n                    \n                        X, y = X.float().to(device), y.to(device)\n                        X_imuonly = X_imuonly.float().to(device)\n                        \n                        logits = model(X)\n                        logits_imuonly = model(X_imuonly)\n    \n                        val_preds.append(logits.argmax(dim=1).cpu().numpy())\n                        val_preds_imuonly.append(logits_imuonly.argmax(dim=1).cpu().numpy())\n\n                        val_preds_logits.append(logits.cpu().numpy())\n                        val_preds_imuonly_logits.append(logits_imuonly.cpu().numpy())\n                        \n                        val_preds_all.append(logits.argmax(dim=1).cpu().numpy())\n                        val_preds_all.append(logits_imuonly.argmax(dim=1).cpu().numpy())\n                        \n                        val_targets.append(y.argmax(dim=1).cpu().numpy())\n                        val_targets_imuonly.append(y.argmax(dim=1).cpu().numpy())\n    \n                        val_targets_all.append(y.argmax(dim=1).cpu().numpy())\n                        val_targets_all.append(y.argmax(dim=1).cpu().numpy())\n    \n                        loss = F.cross_entropy(logits, y)\n                        val_loss += loss.item()\n    \n                if len(train_targets) >= 0:\n                    train_acc = 0.\n                    try:\n                        train_acc = CompetitionMetric().calculate_hierarchical_f1(\n                            pd.DataFrame({'gesture': le.classes_[np.concatenate(train_targets)]}),\n                            pd.DataFrame({'gesture': le.classes_[np.concatenate(train_preds)]})\n                        )\n                    except:\n                        pass\n                    val_acc = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds)]})\n                    )\n                    val_acc_imuonly = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_imuonly)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_imuonly)]})\n                    )\n                    val_acc_split = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_all)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_all)]})\n                    )\n\n                        \n                    train_loss = np.mean(train_loss)\n                    val_loss /= len(val_loader)\n                    print('epoch', epoch, 'loss : ', round(train_loss, 4), '| TRAIN : ', round(train_acc, 4), '| IMUONLY : ', round(val_acc_imuonly, 4), '| ALL : ', round(val_acc, 4),  '| SPLIT : ', round(val_acc_split, 4), '| LR : ', optimizer.param_groups[0]['lr'])\n    \n                    metric = val_acc\n                    \n                    if metric > best_val_acc:\n                        best_val_acc = metric\n                        # Save model\n                        torch.save({\n                            'model_state_dict': model.state_dict(),\n                            'imu_dim': len(imu_cols),\n                            'tof_dim': len(tof_cols),\n                            'n_classes': len(le.classes_),\n                            'pad_len': pad_len\n                        }, self.EXPORT_DIR / f\"gesture_two_branch_fold{fold}.pth\")\n                        print(f\"fold: {fold} val_all_acc: {metric:.4f}\")\n                        print(\"✔ Training done – artefacts saved in\", self.EXPORT_DIR)\n                    \n                    ema.restore(model)\n\n                targetfinalall.append(np.concatenate(val_targets))\n                predimuonlyall.append(np.concatenate(val_preds_imuonly_logits, 0))\n                predallfeatall.append(np.concatenate(val_preds_logits, 0))\n                \n                if self.VALIDATION:\n                    break\n                \n            \n            ema.apply_shadow(model)\n            metrics.append(best_val_acc)\n\n        print(metrics, sum(metrics)/len(metrics))\n\n        import joblib\n        name = str(self.PRETRAINED_DIR).replace('/', '_')\n        joblib.dump(\n            {\n                'guestures': le.classes_, \n                'pred_all': np.concatenate(predallfeatall, 0), \n                'pred_imuonly': np.concatenate(predimuonlyall, 0), \n                'targets': np.concatenate(targetfinalall), \n                'idlist': np.concatenate(idlistall),\n            }, \n                    f\"oof_{name}.joblib\", \n                   )\n\n        return le.classes_, np.concatenate(predallfeatall, 0), np.concatenate(predimuonlyall, 0), np.concatenate(targetfinalall), np.concatenate(idlistall)\n        \n    def get_new_features(self, df):\n        # 优化后的函数\n        def remove_gravity_from_acc(acc_data, rot_data):\n            if isinstance(acc_data, pd.DataFrame):\n                acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n            else:\n                acc_values = np.asarray(acc_data)\n                \n            if isinstance(rot_data, pd.DataFrame):\n                quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            else:\n                quat_values = np.asarray(rot_data)\n            \n            num_samples = acc_values.shape[0]\n            linear_accel = np.zeros_like(acc_values)\n            gravity_world = np.array([0, 0, 9.81])\n            \n            quat_norms = np.linalg.norm(quat_values, axis=1)\n            valid_mask = ~(np.isnan(quat_norms) | np.isclose(quat_norms, 0))\n            \n            valid_quats = quat_values[valid_mask]\n            valid_quats_normalized = valid_quats / quat_norms[valid_mask, np.newaxis]\n            try:\n                rotations = R.from_quat(valid_quats_normalized)\n                    \n                gravity_sensor_frame = rotations.apply(gravity_world, inverse=True)\n            \n                linear_accel[valid_mask] = acc_values[valid_mask] - gravity_sensor_frame\n            except:\n                linear_accel[valid_mask] = acc_values[valid_mask]\n            linear_accel[~valid_mask] = acc_values[~valid_mask]\n            \n            return linear_accel\n        \n        \n        def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200):\n            if isinstance(rot_data, pd.DataFrame):\n                quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            else:\n                quat_values = np.asarray(rot_data)\n            \n            num_samples = quat_values.shape[0]\n            angular_vel = np.zeros((num_samples, 3))\n            \n            if num_samples < 2:\n                return angular_vel\n            \n            quat_norms = np.linalg.norm(quat_values, axis=1)\n            valid_mask = ~(np.isnan(quat_norms) | np.isclose(quat_norms, 0))\n            valid_pairs_mask = valid_mask[:-1] & valid_mask[1:]\n            \n            if np.any(valid_pairs_mask):\n                q_t = quat_values[:-1][valid_pairs_mask]\n                q_t_plus_dt = quat_values[1:][valid_pairs_mask]\n                \n                q_t_norms = quat_norms[:-1][valid_pairs_mask]\n                q_t_plus_dt_norms = quat_norms[1:][valid_pairs_mask]\n                \n                q_t_norm = q_t / q_t_norms[:, np.newaxis]\n                q_t_plus_dt_norm = q_t_plus_dt / q_t_plus_dt_norms[:, np.newaxis]\n                \n                rot_t = R.from_quat(q_t_norm)\n                rot_t_plus_dt = R.from_quat(q_t_plus_dt_norm)\n                delta_rot = rot_t.inv() * rot_t_plus_dt\n                \n                angular_vel[:-1][valid_pairs_mask] = delta_rot.as_rotvec() / time_delta\n            \n            angular_vel[-1, :] = angular_vel[-2, :] if num_samples > 1 else 0\n                    \n            return angular_vel\n        \n        \n        def calculate_angular_distance(rot_data, cumulative=False):\n            if isinstance(rot_data, pd.DataFrame):\n                quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            else:\n                quat_values = np.asarray(rot_data)\n            \n            num_samples = quat_values.shape[0]\n            angular_dist = np.zeros(num_samples)\n            \n            if num_samples < 2:\n                return angular_dist\n            \n            quat_norms = np.linalg.norm(quat_values, axis=1)\n            valid_mask = ~(np.isnan(quat_norms) | np.isclose(quat_norms, 0))\n            valid_pairs_mask = valid_mask[:-1] & valid_mask[1:]\n            \n            if np.any(valid_pairs_mask):\n                q1 = quat_values[:-1][valid_pairs_mask]\n                q2 = quat_values[1:][valid_pairs_mask]\n                \n                q1_norms = quat_norms[:-1][valid_pairs_mask]\n                q2_norms = quat_norms[1:][valid_pairs_mask]\n                \n                q1_norm = q1 / q1_norms[:, np.newaxis]\n                q2_norm = q2 / q2_norms[:, np.newaxis]\n                \n                r1 = R.from_quat(q1_norm)\n                r2 = R.from_quat(q2_norm)\n                relative_rotation = r1.inv() * r2\n                \n                angular_dist[:-1][valid_pairs_mask] = np.linalg.norm(relative_rotation.as_rotvec(), axis=1)\n            \n            if num_samples > 1:\n                angular_dist[-1] = angular_dist[-2] if cumulative else 0\n                \n            if cumulative:\n                angular_dist = np.cumsum(angular_dist)\n                    \n            return angular_dist\n    \n    \n        \n        linear_accel_list = []\n        for _, group in tqdm(df.groupby('sequence_id')):\n            acc_data_group = group[['acc_x', 'acc_y', 'acc_z']].values\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            linear_accel_group = remove_gravity_from_acc(acc_data_group, rot_data_group)\n            linear_accel_list.append(pd.DataFrame(linear_accel_group, columns=['f1', 'f2', 'f3'], index=group.index))\n        df_linear_accel = pd.concat(linear_accel_list)\n        df = pd.concat([df, df_linear_accel], axis=1)\n    \n        angular_vel_list = []\n        for _, group in tqdm(df.groupby('sequence_id')):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            angular_vel_group = calculate_angular_velocity_from_quat(rot_data_group)\n            angular_vel_list.append(pd.DataFrame(angular_vel_group, columns=['f4', 'f5', 'f6'], index=group.index))\n        df_angular_vel = pd.concat(angular_vel_list)\n        df = pd.concat([df, df_angular_vel], axis=1)\n    \n        angular_distance_list = []\n        for _, group in tqdm(df.groupby('sequence_id')):\n            rot_data_group = group[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n            angular_dist_group = calculate_angular_distance(rot_data_group)\n            angular_distance_list.append(pd.DataFrame(angular_dist_group, columns=['f7'], index=group.index))\n        df_angular_distance = pd.concat(angular_distance_list)\n        df = pd.concat([df, df_angular_distance], axis=1)\n    \n        feature_names = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']\n    \n    \n        thm_mean = df[['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']].mean(1)\n    \n        for col in ['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']:\n            df[col] = (np.where(df[col].isna(), thm_mean, df[col]) ) / 5.                                                                                                                                             \n        \n        new_columns = {} \n        for i in range(1, 6):\n            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n            \n            new_columns.update({\n                f'tof_{i}_isna_mean1': (df[pixel_cols]==-1).mean(axis=1),\n                f'tof_{i}_isna_mean2': (df[pixel_cols].isna()).mean(axis=1),\n            })\n    \n            df[pixel_cols] = df[pixel_cols].replace(-1, 255.) / 50. \n            \n            tof_data = df[pixel_cols]\n    \n            new_columns.update({\n                f'tof_{i}_mean': tof_data.mean(axis=1),\n                f'tof_{i}_std': tof_data.std(axis=1),\n                f'tof_{i}_min': tof_data.min(axis=1),\n                f'tof_{i}_max': tof_data.max(axis=1),\n                \n                f'tof_{i}_median_norm': tof_data.median(axis=1)/tof_data.mean(axis=1).clip(1),\n                f'tof_{i}_max_norm': tof_data.min(axis=1)/tof_data.mean(axis=1).clip(1),\n                f'tof_{i}_min_norm': tof_data.max(axis=1)/tof_data.mean(axis=1).clip(1),\n            })\n            if self.tof_mode > 1:\n                region_size = 64 // self.tof_mode\n                for r in tqdm(range(self.tof_mode)):\n                    region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                    new_columns.update({\n                        f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                        f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                        f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                        f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1),\n                    })\n                    \n            if self.tof_mode == -1:\n                for mode in [2, 4, 8, 16, 32]:\n                    region_size = 64 // mode\n                    for r in tqdm(range(mode)):\n                        region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                        new_columns.update({\n                            f'tof{mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                            f'tof{mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                            f'tof{mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                            f'tof{mode}_{i}_region_{r}_max': region_data.max(axis=1)\n                        })\n        df_tof = pd.DataFrame(new_columns)\n        df = pd.concat([df, df_tof], axis=1)\n    \n        \n        return df, feature_names, list(df_tof.columns)\n        \n\n    def get_model(self, ):    \n        print(\"▶ INFERENCE MODE – loading artefacts from\", self.PRETRAINED_DIR)\n        self.feature_cols = np.load(self.PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n        self.pad_len = int(np.load(self.PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n        self.gesture_classes = np.load(self.PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n    \n        self.imu_cols = [c for c in self.feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n        self.tof_cols = [c for c in self.feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n        # Load model\n        MODELS = [f'gesture_two_branch_fold{i}.pth' for i in range(5) if i in self.TRAIN_FOLDS]\n        \n        self.models = []\n        for path in MODELS:\n            checkpoint = torch.load(self.PRETRAINED_DIR / path, map_location=self.device)\n            \n            model = self.create_model(\n                checkpoint['pad_len'], \n                checkpoint['imu_dim'], \n                checkpoint['tof_dim'], \n                checkpoint['n_classes']\n                ).to(self.device)\n    \n            \n            \n            model.load_state_dict({k.replace('_orig_mod.', ''):v for k, v in checkpoint['model_state_dict'].items()})\n            model.eval()\n            self.models.append(model)\n    \n        print(\"  model, scaler, pads loaded – ready for evaluation\")\n    \n        return \n    \n    def predict(self, sequence: pl.DataFrame, demographics: pl.DataFrame, nanratio=0.):        \n        df_seq = sequence.to_pandas()\n        df_seq, _, _ = self.get_new_features(df_seq)\n        \n        with torch.no_grad():\n            outputs = None\n            for model in self.models:\n                mat = self.preprocess_sequence(df_seq, self.feature_cols, None)\n                pad = self.pad_sequences_torch([mat], maxlen=self.pad_len, padding='pre', truncating='pre')\n                x = torch.FloatTensor(pad).to(self.device)\n                \n                model.eval()\n                p = model(x)\n                if outputs is None: outputs = p\n                else: outputs += p\n            outputs /= len(self.models)\n                    \n        return self.gesture_classes, outputs.cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for local training, prepare all the data under ./cmi-detect-behavior-with-sensor-data/ folder\n\nmodel_zhou_inference_v1_2 = model_zhou_v1('/kaggle/input/cmi3v38')\n\nmodel_zhou_inference_v1_2.TRAIN_FOLDS = [0, 1, 2, 3, 4]\nmodel_zhou_inference_v1_2.VALIDATION = False\nmodel_zhou_inference_v1_2.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for seed in [\n#              # 42,\n#              6665252, \n#              # 88885252, \n#              #12345252, \n#              #325252,\n#              #885252,\n#              #99995252,\n#              #115252,\n#             ]:\n#     model_zhou_inference_v0 = model_zhou_v15(f'./{seed}', seed=seed, save_path=f'./{seed}')\n    \n#     model_zhou_inference_v0.TRAIN_FOLDS = [0, 1, 2, 3, 4]\n\n#     model_zhou_inference_v0.VALIDATION = False\n    \n#     model_zhou_inference_v0.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}