{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install --no-deps /kaggle/input/scikit-learn-1-6-1/scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n\n#!/usr/bin/env python\n# coding: utf-8\n\n# # Importable version of https://www.kaggle.com/code/metric/cmi-2025\n\n# In[ ]:\n\n\n\"\"\"\nHierarchical macro F1 metric for the CMI 2025 Challenge.\n\nThis script defines a single entry point `score(solution, submission, row_id_column_name)`\nthat the Kaggle metrics orchestrator will call.\nIt performs validation on submission IDs and computes a combined binary & multiclass F1 score.\n\"\"\"\n\nimport pandas as pd\nfrom sklearn.metrics import f1_score\n\n\nclass ParticipantVisibleError(Exception):\n    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n    pass\n\n\nclass CompetitionMetric:\n    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n    def __init__(self):\n        self.target_gestures = [\n            'Above ear - pull hair',\n            'Cheek - pinch skin',\n            'Eyebrow - pull hair',\n            'Eyelash - pull hair',\n            'Forehead - pull hairline',\n            'Forehead - scratch',\n            'Neck - pinch skin',\n            'Neck - scratch',\n        ]\n        self.non_target_gestures = [\n            'Write name on leg',\n            'Wave hello',\n            'Glasses on/off',\n            'Text on phone',\n            'Write name in air',\n            'Feel around in tray and pull out an object',\n            'Scratch knee/leg skin',\n            'Pull air toward your face',\n            'Drink from bottle/cup',\n            'Pinch knee/leg skin'\n        ]\n        self.all_classes = self.target_gestures + self.non_target_gestures\n\n    def calculate_hierarchical_f1(\n        self,\n        sol: pd.DataFrame,\n        sub: pd.DataFrame\n    ) -> float:\n\n        # Validate gestures\n        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n        if invalid_types:\n            raise ParticipantVisibleError(\n                f\"Invalid gesture values in submission: {invalid_types}\"\n            )\n\n        # Compute binary F1 (Target vs Non-Target)\n        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n        f1_binary = f1_score(\n            y_true_bin,\n            y_pred_bin,\n            pos_label=True,\n            zero_division=0,\n            average='binary'\n        )\n\n        # Build multi-class labels for gestures\n        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n\n        # Compute macro F1 over all gesture classes\n        f1_macro = f1_score(\n            y_true_mc,\n            y_pred_mc,\n            average='macro',\n            zero_division=0\n        )\n\n        return 0.5 * f1_binary + 0.5 * f1_macro\n\n\ndef score(\n    solution: pd.DataFrame,\n    submission: pd.DataFrame,\n    row_id_column_name: str\n) -> float:\n    \"\"\"\n    Compute hierarchical macro F1 for the CMI 2025 challenge.\n\n    Expected input:\n      - solution and submission as pandas.DataFrame\n      - Column 'sequence_id': unique identifier for each sequence\n      - 'gesture': one of the eight target gestures or \"Non-Target\"\n\n    This metric averages:\n    1. Binary F1 on SequenceType (Target vs Non-Target)\n    2. Macro F1 on gesture (mapping non-targets to \"Non-Target\")\n\n    Raises ParticipantVisibleError for invalid submissions,\n    including invalid SequenceType or gesture values.\n\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> row_id_column_name = \"id\"\n    >>> solution = pd.DataFrame({'id': range(4), 'gesture': ['Eyebrow - pull hair']*4})\n    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Forehead - pull hairline']*4})\n    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n    0.5\n    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Text on phone']*4})\n    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n    0.0\n    >>> score(solution, solution, row_id_column_name=row_id_column_name)\n    1.0\n    \"\"\"\n    # Validate required columns\n    for col in (row_id_column_name, 'gesture'):\n        if col not in solution.columns:\n            raise ParticipantVisibleError(f\"Solution file missing required column: '{col}'\")\n        if col not in submission.columns:\n            raise ParticipantVisibleError(f\"Submission file missing required column: '{col}'\")\n\n    metric = CompetitionMetric()\n    return metric.calculate_hierarchical_f1(solution, submission)\n\n\nimport torch\nimport torch.distributed as dist\n\n\ndef zeropower_via_newtonschulz5(G, steps: int):\n    \"\"\"\n    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\n    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\n    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at\n    zero even beyond the point where the iteration no longer converges all the way to one everywhere\n    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T\n    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model\n    performance at all relative to UV^T, where USV^T = G is the SVD.\n    \"\"\"\n    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng\n    a, b, c = (3.4445, -4.7750,  2.0315)\n    X = G.bfloat16()\n    if G.size(-2) > G.size(-1):\n        X = X.mT\n\n    # Ensure spectral norm is at most 1\n    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n    # Perform the NS iterations\n    for _ in range(steps):\n        A = X @ X.mT\n        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng\n        X = a * X + B @ X\n    \n    if G.size(-2) > G.size(-1):\n        X = X.mT\n    return X\n\n\ndef muon_update(grad, momentum, beta=0.95, ns_steps=5, nesterov=True):\n    momentum.lerp_(grad, 1 - beta)\n    update = grad.lerp_(momentum, beta) if nesterov else momentum\n    if update.ndim == 4: # for the case of conv filters\n        update = update.view(len(update), -1)\n    update = zeropower_via_newtonschulz5(update, steps=ns_steps)\n    update *= max(1, grad.size(-2) / grad.size(-1))**0.5\n    return update\n\n\nclass Muon(torch.optim.Optimizer):\n    \"\"\"\n    Muon - MomentUm Orthogonalized by Newton-schulz\n\n    https://kellerjordan.github.io/posts/muon/\n\n    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-\n    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal\n    matrix. For efficient orthogonalization we use a Newton-Schulz iteration, which has the\n    advantage that it can be stably run in bfloat16 on the GPU.\n\n    Muon should only be used for hidden weight layers. The input embedding, final output layer,\n    and any internal gains or biases should be optimized using a standard method such as AdamW.\n    Hidden convolutional weights can be trained using Muon by viewing them as 2D and then\n    collapsing their last 3 dimensions.\n\n    Arguments:\n        lr: The learning rate, in units of spectral norm per update.\n        weight_decay: The AdamW-style weight decay.\n        momentum: The momentum. A value of 0.95 here is usually fine.\n    \"\"\"\n    def __init__(self, params, lr=0.02, weight_decay=0, momentum=0.95):\n        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum)\n        assert isinstance(params, list) and len(params) >= 1 and isinstance(params[0], torch.nn.Parameter)\n        params = sorted(params, key=lambda x: x.size(), reverse=True)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            params = group[\"params\"]\n            params_pad = params + [torch.empty_like(params[-1])] * (dist.get_world_size() - len(params) % dist.get_world_size())\n            for base_i in range(len(params))[::dist.get_world_size()]:\n                if base_i + dist.get_rank() < len(params):\n                    p = params[base_i + dist.get_rank()]\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"momentum_buffer\"] = torch.zeros_like(p)\n                    update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n                dist.all_gather(params_pad[base_i:base_i + dist.get_world_size()], params_pad[base_i + dist.get_rank()])\n\n        return loss\n\n\nclass SingleDeviceMuon(torch.optim.Optimizer):\n    \"\"\"\n    Muon variant for usage in non-distributed settings.\n    \"\"\"\n    def __init__(self, params, lr=0.02, weight_decay=0, momentum=0.95):\n        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum)\n        super().__init__(params, defaults)\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"momentum_buffer\"] = torch.zeros_like(p)\n                update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n\n        return loss\n\n\ndef adam_update(grad, buf1, buf2, step, betas, eps):\n    buf1.lerp_(grad, 1 - betas[0])\n    buf2.lerp_(grad.square(), 1 - betas[1])\n    buf1c = buf1 / (1 - betas[0]**step)\n    buf2c = buf2 / (1 - betas[1]**step)\n    return buf1c / (buf2c.sqrt() + eps)\n\n\nclass MuonWithAuxAdam(torch.optim.Optimizer):\n    \"\"\"\n    Distributed Muon variant that can be used for all parameters in the network, since it runs an\n    internal AdamW for the parameters that are not compatible with Muon. The user must manually\n    specify which parameters shall be optimized with Muon and which with Adam by passing in a\n    list of param_groups with the `use_muon` flag set.\n\n    The point of this class is to allow the user to have a single optimizer in their code, rather\n    than having both a Muon and an Adam which each need to be stepped.\n\n    You can see an example usage below:\n\n    https://github.com/KellerJordan/modded-nanogpt/blob/master/records/052525_MuonWithAuxAdamExample/b01550f9-03d8-4a9c-86fe-4ab434f1c5e0.txt#L470\n    ```\n    hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and \"embed\" not in n]\n    embed_params = [p for n, p in model.named_parameters() if \"embed\" in n]\n    scalar_params = [p for p in model.parameters() if p.ndim < 2]\n    head_params = [model.lm_head.weight]\n\n    from muon import MuonWithAuxAdam\n    adam_groups = [dict(params=head_params, lr=0.22), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]\n    adam_groups = [dict(**g, betas=(0.8, 0.95), eps=1e-10, use_muon=False) for g in adam_groups]\n    muon_group = dict(params=hidden_matrix_params, lr=0.05, momentum=0.95, use_muon=True)\n    param_groups = [*adam_groups, muon_group]\n    optimizer = MuonWithAuxAdam(param_groups)\n    ```\n    \"\"\"\n    def __init__(self, param_groups):\n        for group in param_groups:\n            assert \"use_muon\" in group\n            if group[\"use_muon\"]:\n                group[\"params\"] = sorted(group[\"params\"], key=lambda x: x.size(), reverse=True)\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 0.02)\n                group[\"momentum\"] = group.get(\"momentum\", 0.95)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"momentum\", \"weight_decay\", \"use_muon\"])\n            else:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 3e-4)\n                group[\"betas\"] = group.get(\"betas\", (0.9, 0.95))\n                group[\"eps\"] = group.get(\"eps\", 1e-10)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"betas\", \"eps\", \"weight_decay\", \"use_muon\"])\n        super().__init__(param_groups, dict())\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            if group[\"use_muon\"]:\n                params = group[\"params\"]\n                params_pad = params + [torch.empty_like(params[-1])] * (dist.get_world_size() - len(params) % dist.get_world_size())\n                for base_i in range(len(params))[::dist.get_world_size()]:\n                    if base_i + dist.get_rank() < len(params):\n                        p = params[base_i + dist.get_rank()]\n                        state = self.state[p]\n                        if len(state) == 0:\n                            state[\"momentum_buffer\"] = torch.zeros_like(p)\n                        update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                        p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                        p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n                    dist.all_gather(params_pad[base_i:base_i + dist.get_world_size()], params_pad[base_i + dist.get_rank()])\n            else:\n                for p in group[\"params\"]:\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"exp_avg\"] = torch.zeros_like(p)\n                        state[\"exp_avg_sq\"] = torch.zeros_like(p)\n                        state[\"step\"] = 0\n                    state[\"step\"] += 1\n                    update = adam_update(p.grad, state[\"exp_avg\"], state[\"exp_avg_sq\"],\n                                         state[\"step\"], group[\"betas\"], group[\"eps\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update, alpha=-group[\"lr\"])\n\n        return loss\n\n\nclass SingleDeviceMuonWithAuxAdam(torch.optim.Optimizer):\n    \"\"\"\n    Non-distributed variant of MuonWithAuxAdam.\n    \"\"\"\n    def __init__(self, param_groups):\n        for group in param_groups:\n            assert \"use_muon\" in group\n            if group[\"use_muon\"]:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 0.02)\n                group[\"momentum\"] = group.get(\"momentum\", 0.95)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"momentum\", \"weight_decay\", \"use_muon\"])\n            else:\n                # defaults\n                group[\"lr\"] = group.get(\"lr\", 3e-4)\n                group[\"betas\"] = group.get(\"betas\", (0.9, 0.95))\n                group[\"eps\"] = group.get(\"eps\", 1e-10)\n                group[\"weight_decay\"] = group.get(\"weight_decay\", 0)\n                assert set(group.keys()) == set([\"params\", \"lr\", \"betas\", \"eps\", \"weight_decay\", \"use_muon\"])\n        super().__init__(param_groups, dict())\n\n    @torch.no_grad()\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            if group[\"use_muon\"]:\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        continue\n                        \n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"momentum_buffer\"] = torch.zeros_like(p)\n                    update = muon_update(p.grad, state[\"momentum_buffer\"], beta=group[\"momentum\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update.reshape(p.shape), alpha=-group[\"lr\"])\n            else:\n                for p in group[\"params\"]:\n                    if p.grad is None:\n                        continue\n                    state = self.state[p]\n                    if len(state) == 0:\n                        state[\"exp_avg\"] = torch.zeros_like(p)\n                        state[\"exp_avg_sq\"] = torch.zeros_like(p)\n                        state[\"step\"] = 0\n                    state[\"step\"] += 1\n                    update = adam_update(p.grad, state[\"exp_avg\"], state[\"exp_avg_sq\"],\n                                         state[\"step\"], group[\"betas\"], group[\"eps\"])\n                    p.mul_(1 - group[\"lr\"] * group[\"weight_decay\"])\n                    p.add_(update, alpha=-group[\"lr\"])\n\n        return loss\n\nfrom torch.optim.lr_scheduler import _LRScheduler\nclass ConstantCosineLR(_LRScheduler):\n    \"\"\"\n    Constant learning rate followed by CosineAnnealing.\n    \"\"\"\n    def __init__(\n        self, \n        optimizer,\n        total_steps, \n        pct_cosine, \n        last_epoch=-1,\n        ):\n        self.total_steps = total_steps\n        self.milestone = int(total_steps * (pct_cosine))\n        self.cosine_steps = max(total_steps - self.milestone, 1)\n        self.min_lr = 0\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        step = self.last_epoch + 1\n        if step <= self.milestone:\n            factor = 1.\n        else:\n            s = step - self.milestone\n            factor = 0.5 * (1 + math.cos(math.pi * s / self.cosine_steps))\n        return [lr * factor for lr in self.base_lrs]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, json, joblib, numpy as np, pandas as pd\nimport random, math\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nimport sys\nsys.path.append('/root/autodl-tmp/')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import StratifiedKFold\nfrom timm.scheduler import CosineLRScheduler\nfrom scipy.signal import firwin\nimport polars as pl\nimport numpy as np\nimport random\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.spatial.transform import Rotation as R\nfrom tqdm.auto import tqdm \n\n\nclass SignalTransform:\n    def __init__(self, always_apply: bool = False, p: float = 0.5):\n        self.always_apply = always_apply\n        self.p = p\n\n    def __call__(self, y: np.ndarray):\n        if self.always_apply:\n            return self.apply(y)\n        else:\n            if np.random.rand() < self.p:\n                return self.apply(y)\n            else:\n                return y\n\n    def apply(self, y: np.ndarray):\n        raise NotImplementedError\n\n\nclass Compose:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray):\n        for trns in self.transforms:\n            y = trns(y)\n        return y\n\n\nclass OneOf:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray):\n        n_trns = len(self.transforms)\n        trns_idx = np.random.choice(n_trns)\n        trns = self.transforms[trns_idx]\n        return trns(y)\n\nclass TimeStretch(SignalTransform):\n    def __init__(self, max_rate=1.5, min_rate=0.5, always_apply=False, p=0.5):\n        super().__init__(always_apply, p)\n        self.max_rate = max_rate\n        self.min_rate = min_rate\n        self.always_apply = always_apply\n        self.p = p\n\n    def apply(self, x: np.ndarray):\n        \"\"\"\n        Stretch a 1D or 2D array in time using linear interpolation.\n        After stretching, pad or crop at the beginning to match the original length.\n        Padding value is 0.\n        - x: np.ndarray of shape (L,) or (L, N)\n        \"\"\"\n        rate = np.random.uniform(self.min_rate, self.max_rate)\n        L = x.shape[0]\n        L_new = int(L / rate)\n        orig_idx = np.linspace(0, L - 1, num=L)\n        new_idx = np.linspace(0, L - 1, num=L_new)\n\n        if x.ndim == 1:\n            stretched = np.interp(new_idx, orig_idx, x)\n            # Pad or crop at the beginning\n            if L_new < L:\n                # Pad at the beginning\n                padded = np.zeros(L, dtype=stretched.dtype)\n                padded[-L_new:] = stretched\n                return padded\n            elif L_new > L:\n                # Crop at the beginning\n                return stretched[-L:]\n            else:\n                return stretched\n        elif x.ndim == 2:\n            stretched = np.stack([\n                np.interp(new_idx, orig_idx, x[:, i]) for i in range(x.shape[1])\n            ], axis=1)\n            if L_new < L:\n                padded = np.zeros((L, x.shape[1]), dtype=stretched.dtype)\n                padded[-L_new:, :] = stretched\n                return padded\n            elif L_new > L:\n                return stretched[-L:, :]\n            else:\n                return stretched\n        else:\n            raise ValueError(\"Only 1D or 2D arrays are supported.\")\n\n\nclass TimeShift(SignalTransform):\n    def __init__(self, always_apply=False, p=0.5, max_shift_pct=0.25, padding_mode=\"replace\"):\n        super().__init__(always_apply, p)\n        \n        assert 0 <= max_shift_pct <= 1.0, \"`max_shift_pct` must be between 0 and 1\"\n        assert padding_mode in [\"replace\", \"zero\"], \"`padding_mode` must be either 'replace' or 'zero'\"\n        \n        self.max_shift_pct = max_shift_pct\n        self.padding_mode = padding_mode\n\n    def apply(self, x: np.ndarray, **params):\n        assert x.ndim == 2, \"`x` must be a 2D array with shape (L, N)\"\n        \n        L = x.shape[0]\n        max_shift = int(L * self.max_shift_pct)\n        shift = np.random.randint(-max_shift, max_shift + 1)\n\n        # Roll along time axis (axis=0)\n        augmented = np.roll(x, shift, axis=0)\n\n        if self.padding_mode == \"zero\":\n            if shift > 0:\n                augmented[:shift, :] = 0\n            elif shift < 0:\n                augmented[shift:, :] = 0\n\n        return augmented\n\ntransforms_custom = Compose([\n    TimeShift(p=0.25, padding_mode=\"replace\", max_shift_pct=0.25),\n    TimeStretch(p=0.25, max_rate=1.5, min_rate=0.5),\n])\n\n\n\nif os.path.exists(\"../input/cmi-detect-behavior-with-sensor-data\"):\n    test_path1 = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv'\n    test_path2 = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\nelse:\n    if os.path.exists(\"./cmi-detect-behavior-with-sensor-data/\"):\n        test_path1 = './cmi-detect-behavior-with-sensor-data/test.csv'\n        test_path2 = './cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n    else:\n        test_path1 = './test.csv'\n        test_path2 = './test_demographics.csv'\n\nclass model_zhou_v26:\n    def __init__(self, kaggle_input_path=\"/kaggle/input/cmi3v23\", seed=42, save_path='./'):\n        self.models = []\n\n        import os\n        if os.path.exists(\"../input/cmi-detect-behavior-with-sensor-data\"):\n            self.TRAIN = False                     \n            self.RAW_DIR = Path(\"../input/cmi-detect-behavior-with-sensor-data\")\n            self.PRETRAINED_DIR = Path(kaggle_input_path) \n            self.EXPORT_DIR = Path(save_path)                                   \n        else:\n            if os.path.exists(\"./cmi-detect-behavior-with-sensor-data/\"):\n                self.TRAIN = True                     \n                self.RAW_DIR = Path(\"./cmi-detect-behavior-with-sensor-data/\")\n                self.PRETRAINED_DIR = Path(kaggle_input_path) \n                self.EXPORT_DIR = Path(save_path)                                  \n            else:\n                self.TRAIN = True                    \n                self.RAW_DIR = Path(\"./\")\n                self.EXPORT_DIR = Path(save_path)\n                self.PRETRAINED_DIR = Path(kaggle_input_path) \n\n        if not os.path.exists(self.EXPORT_DIR):\n            os.system(f'mkdir {self.EXPORT_DIR}')\n            \n        self.VALIDATION = False\n        self.SEED = seed\n\n        self.BATCH_SIZE = 64 * 1\n        self.PAD_PERCENTILE = 128 + 64\n        self.maxlen = self.PAD_PERCENTILE\n        self.LR_INIT = 1e-3\n        self.WD = 2e-1\n        \n        self.PATIENCE = 40\n        self.random_state = self.SEED\n        \n        self.tof_mode = 4\n        \n        self.FOLDS = 5\n        self.TRAIN_FOLDS = [0, 1, 2, 3, 4,]\n        \n        self.EPOCHS = 160\n\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"▶ imports ready · pytorch {torch.__version__} · device: {self.device}\")\n    \n    def create_model(self, param_a, param_b, param_c, param_d):        \n        def get_gravity(quat):\n            g=9.81\n             # 四元数旋转\n            x = quat[..., 0:1]  # rot_x\n            y = quat[..., 1:2]  # rot_y\n            z = quat[..., 2:3]  # rot_z\n            w = quat[..., 3:4]  # rot_w\n            g_x = 2 * g * (x * z - w * y)\n            g_y = 2 * g * (y * z + w * x)\n            g_z = g * (w**2 - x**2 - y**2 + z**2)\n            gravity = np.concatenate([g_x, g_y, g_z], -1)\n            return gravity\n            \n        def rotate_quaternion_np(quat: np.ndarray, angle_range: tuple = [(-10, 10), (-10, 10), (-10, 10), ]) -> np.ndarray:\n            # 确保输入形状正确\n            if quat.ndim != 2 or quat.shape[1] != 4:\n                raise ValueError(\"输入四元数必须是形状为[len, 4]的数组\")\n            \n            seq_len = quat.shape[0]\n            \n            # 1. 生成绕x、y、z轴的随机旋转角度（度）\n            angle_x = np.random.uniform(angle_range[0][0], angle_range[0][1])\n            angle_y = np.random.uniform(angle_range[1][0], angle_range[1][1])\n            angle_z = np.random.uniform(angle_range[2][0], angle_range[2][1])\n            \n            # 2. 将角度转换为弧度\n            rad_x = math.pi * angle_x / 180.0\n            rad_y = math.pi * angle_y / 180.0\n            rad_z = math.pi * angle_z / 180.0\n            \n            # 3. 生成绕各轴旋转的四元数\n            qx = np.array([math.sin(rad_x/2), 0, 0, math.cos(rad_x/2)], dtype=np.float32)  # x轴旋转\n            qy = np.array([0, math.sin(rad_y/2), 0, math.cos(rad_y/2)], dtype=np.float32)  # y轴旋转\n            qz = np.array([0, 0, math.sin(rad_z/2), math.cos(rad_z/2)], dtype=np.float32)  # z轴旋转\n            \n            # 4. 组合旋转四元数 (q_total = qz * qy * qx，注意乘法顺序)\n            q_zy = _quat_mul(qz, qy)\n            q_total = _quat_mul(q_zy, qx)\n            \n            # 5. 将组合旋转应用到每个四元数上\n            # 扩展旋转四元数以匹配序列长度\n            q_total_expanded = np.tile(q_total, (seq_len, 1))  # [len, 4]\n            rotated_quat = _quat_mul(q_total_expanded, quat)\n            \n            # 6. 归一化确保四元数有效性\n            norms = np.linalg.norm(rotated_quat, axis=1, keepdims=True)\n            rotated_quat = rotated_quat / np.maximum(norms, 1e-8)  # 防止除零\n            \n            return rotated_quat\n        \n        def _quat_mul(q1: np.ndarray, q2: np.ndarray) -> np.ndarray:\n            # 提取分量（利用广播机制自动适配维度）\n            x1, y1, z1, w1 = q1[..., 0], q1[..., 1], q1[..., 2], q1[..., 3]\n            x2, y2, z2, w2 = q2[..., 0], q2[..., 1], q2[..., 2], q2[..., 3]\n            \n            # 四元数乘法公式（完全向量化）\n            x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n            y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n            z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n            w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n            \n            # 堆叠结果（保持维度）\n            return np.stack([x, y, z, w], axis=-1).astype(q1.dtype)\n        \n        \n        def remove_average_rotation_optimized(q: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n            \"\"\"\n            从四元数序列中移除平均旋转，忽略全零四元数，并旋转到指定方向\n            Args:\n                q: 输入四元数序列，形状 [bs, len, 4]，顺序 [rot_x, rot_y, rot_z, rot_w]\n                eps: 数值稳定性阈值\n            Returns:\n                q_final: 移除平均旋转并旋转到[0.5,0.5,0.5,0.5]方向后的四元数序列，形状 [bs, len, 4]\n                         原始全零的位置仍为零\n            \"\"\"\n            def is_zero_quaternion(q: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n                \"\"\"\n                判断四元数是否为全零（或接近全零）\n                Args:\n                    q: 四元数，形状 [..., 4]\n                    eps: 接近零的阈值\n                Returns:\n                    布尔张量，形状 [...], 指示每个四元数是否为零\n                \"\"\"\n                return torch.norm(q, dim=-1) < eps\n            \n            def safe_normalize(q: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n                \"\"\"\n                安全地规范化四元数，避免除零错误\n                Args:\n                    q: 四元数，形状 [..., 4]\n                    eps: 最小范数阈值\n                Returns:\n                    规范化后的四元数\n                \"\"\"\n                norm = torch.norm(q, dim=-1, keepdim=True)\n                # 添加最小范数保护\n                norm = torch.clamp(norm, min=eps)\n                return q / norm\n            \n            def quat_multiply(q1: torch.Tensor, q2: torch.Tensor) -> torch.Tensor:\n                \"\"\"\n                批量四元数乘法 (q1 * q2)\n                Args:\n                    q1: 形状 [..., 4]，四元数 [x1,y1,z1,w1]\n                    q2: 形状 [..., 4]，四元数 [x2,y2,z2,w2]\n                Returns:\n                    q: 形状 [..., 4]，乘积 q1*q2 [x,y,z,w]\n                \"\"\"\n                x1, y1, z1, w1 = q1[..., 0], q1[..., 1], q1[..., 2], q1[..., 3]\n                x2, y2, z2, w2 = q2[..., 0], q2[..., 1], q2[..., 2], q2[..., 3]\n                \n                x = w1*x2 + x1*w2 + y1*z2 - z1*y2\n                y = w1*y2 - x1*z2 + y1*w2 + z1*x2\n                z = w1*z2 + x1*y2 - y1*x2 + z1*w2\n                w = w1*w2 - x1*x2 - y1*y2 - z1*z2\n                \n                return torch.stack([x, y, z, w], dim=-1)\n            \n            def find_first_valid_indices(mask: torch.Tensor) -> torch.Tensor:\n                \"\"\"\n                向量化方法查找每个batch中第一个有效四元数的索引\n                Args:\n                    mask: 有效掩码，形状 [bs, len]\n                Returns:\n                    indices: 每个batch的第一个有效索引，形状 [bs]\n                \"\"\"\n                bs, seq_len = mask.shape\n                device = mask.device\n                \n                # 创建索引矩阵\n                indices = torch.arange(seq_len, device=device).expand(bs, seq_len)\n                # 将无效位置的索引设置为大数\n                indices = torch.where(mask, indices, seq_len)\n                # 找到最小索引（第一个有效位置）\n                first_valid = torch.min(indices, dim=1)[0]\n                # 处理全无效的情况\n                all_invalid = first_valid == seq_len\n                first_valid[all_invalid] = 0  # 设置为0，后续会处理\n                \n                return first_valid\n            \n            def quaternion_average_frechet_optimized(q: torch.Tensor, mask: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n                \"\"\"\n                计算批量四元数的Frechet均值（优化版本）\n                Args:\n                    q: 输入四元数，形状 [bs, len, 4]，顺序 [rot_x, rot_y, rot_z, rot_w]\n                    mask: 有效四元数掩码，形状 [bs, len]，1表示有效，0表示无效\n                    eps: 数值稳定性阈值\n                Returns:\n                    q_avg: 平均四元数，形状 [bs, 4]\n                \"\"\"\n                bs, len_q, _ = q.shape\n                device = q.device\n                \n                # 步骤1：安全地单位化四元数\n                q_normalized = safe_normalize(q, eps=eps)\n                \n                # 应用掩码：无效四元数置为零\n                mask_keepdim = mask.unsqueeze(-1)  # [bs, len, 1]\n                q_normalized = q_normalized * mask_keepdim\n                \n                # 步骤2：向量化查找参考四元数\n                first_valid_indices = find_first_valid_indices(mask)\n                q_ref = q_normalized[torch.arange(bs, device=device), first_valid_indices].unsqueeze(1)  # [bs, 1, 4]\n                \n                # 步骤3：改进的符号统一策略（添加阈值避免在接近正交时翻转）\n                dot = (q_normalized * q_ref).sum(dim=-1, keepdim=True)  # [bs, len, 1]\n                q_unified = torch.where(dot < -0.01, -q_normalized, q_normalized)\n                \n                # 步骤4：构建协方差矩阵 M [bs, 4, 4]，考虑掩码\n                q_reshaped = q_unified.unsqueeze(-1)  # [bs, len, 4, 1]\n                q_transposed = q_reshaped.transpose(2, 3)  # [bs, len, 1, 4]\n                outer_products = q_reshaped @ q_transposed  # [bs, len, 4, 4]\n                \n                # 应用掩码并求和\n                mask_4d = mask.unsqueeze(-1).unsqueeze(-1)  # [bs, len, 1, 1]\n                outer_products = outer_products * mask_4d\n                M = outer_products.sum(dim=1)  # [bs, 4, 4]\n                \n                # 处理所有四元数都无效的情况\n                valid_count = mask.sum(dim=1)  # [bs]\n                all_invalid = valid_count == 0\n                if all_invalid.any():\n                    # 对全无效的batch，使用单位四元数作为平均\n                    M[all_invalid] = torch.eye(4, device=device)\n                \n                # 步骤5：使用更稳定的特征值求解\n                # 添加小单位矩阵增强数值稳定性\n                M_stable = M + eps * torch.eye(4, device=device).unsqueeze(0)\n                w, v = torch.linalg.eigh(M_stable)  # w: [bs,4], v: [bs,4,4]\n                q_avg = v[:, :, -1]  # 最大特征值对应特征向量\n                \n                # 确保单位化 + 实部(rot_w)为正\n                q_avg = safe_normalize(q_avg, eps=eps)\n                q_avg = torch.where(q_avg[:, 3:4] < 0, -q_avg, q_avg)\n                \n                return q_avg\n            \n            bs, len_q, _ = q.shape\n            device = q.device\n            \n            # 1. 识别全零四元数\n            zero_mask = is_zero_quaternion(q, eps)  # [bs, len]\n            valid_mask = ~zero_mask  # [bs, len]，1表示有效四元数\n            \n            # 2. 计算有效四元数的平均旋转\n            q_avg = quaternion_average_frechet_optimized(q, valid_mask, eps)  # [bs, 4]\n            \n            # 3. 创建目标四元数 [0.5, 0.5, 0.5, 0.5] 并规范化\n            target_quat = torch.tensor([0, 0, 0, 1], device=device, dtype=q.dtype)\n            target_quat = safe_normalize(target_quat)\n            \n            # 4. 将目标旋转整合到平均旋转中\n            # 计算目标旋转与平均旋转的复合旋转\n            # q_composite = target_quat * q_avg_conj\n            # 这等价于先应用平均旋转的逆，然后应用目标旋转\n            \n            # 计算平均四元数的共轭（逆）\n            q_avg_conj = q_avg.clone()\n            q_avg_conj[:, :3] *= -1  # 虚部取反：[x,y,z,w] → [-x,-y,-z,w]\n            \n            # 将目标旋转与平均旋转的共轭相乘\n            q_composite = quat_multiply(\n                target_quat.unsqueeze(0).expand(bs, 4),  # 扩展目标四元数以匹配批次大小\n                q_avg_conj\n            )  # [bs, 4]\n            \n            q_composite = safe_normalize(q_composite)  # 确保复合旋转是单位四元数\n            q_composite = q_composite.unsqueeze(1)  # [bs, 1, 4]，便于广播\n            \n            # 5. 应用复合旋转：q_final = q_composite * q\n            q_final = quat_multiply(q_composite, q)  # [bs, len, 4]\n            \n            # 6. 保持原始全零位置为零\n            q_final = q_final * valid_mask.unsqueeze(-1)  # [bs, len, 4]\n            \n            return q_final\n\n        \n        class MotionFeatureExtractor(nn.Module):\n            \"\"\"\n            支持CUDA/CPU输入的运动特征提取模块\n            输入: [bs, len, 7] 张量（[acc_x, acc_y, acc_z, rot_x, rot_y, rot_z, rot_w]）\n            输出: [bs, len, 7] 张量（[线性加速度x/y/z, 角速度x/y/z, 角距离]）\n            \"\"\"\n            def __init__(self, time_delta=1/200):\n                super().__init__()\n                self.time_delta = time_delta\n                # ！修改1：不提前固定gravity_world的设备，改为使用时动态匹配输入设备\n                self.gravity_world_val = torch.tensor([0.0, 0.0, 9.81], dtype=torch.float32)\n                \n            def quat_to_rot_matrix(self, quat):\n                \"\"\"四元数（[x,y,z,w]）转旋转矩阵 [bs, len, 3, 3]\"\"\"\n                x, y, z, w = quat[..., 0], quat[..., 1], quat[..., 2], quat[..., 3]\n                \n                xx = x * x\n                yy = y * y\n                zz = z * z\n                xy = x * y\n                xz = x * z\n                yz = y * z\n                xw = x * w\n                yw = y * w\n                zw = z * w\n                ww = w * w\n                \n                # 旋转矩阵计算（基于输入quat的设备，自动在CUDA/CPU上运算）\n                rot_mat = torch.stack([\n                    xx + ww - (yy + zz), 2 * (xy - zw), 2 * (xz + yw),\n                    2 * (xy + zw), yy + ww - (xx + zz), 2 * (yz - xw),\n                    2 * (xz - yw), 2 * (yz + xw), zz + ww - (xx + yy)\n                ], dim=-1).view(*quat.shape[:-1], 3, 3)\n                \n                return rot_mat\n            \n            def rot_matrix_inverse(self, rot_mat):\n                \"\"\"旋转矩阵求逆（逆=转置，设备与输入一致）\"\"\"\n                return rot_mat.transpose(-2, -1)\n            \n            def rot_matrix_multiply(self, rot_mat1, rot_mat2):\n                \"\"\"旋转矩阵乘法（设备自动匹配）\"\"\"\n                return torch.matmul(rot_mat1, rot_mat2)\n            \n            def apply_rotation(self, rot_mat, vec):\n                \"\"\"旋转矩阵应用于向量（设备自动匹配）\"\"\"\n                return torch.matmul(rot_mat, vec.unsqueeze(-1)).squeeze(-1)\n            \n            def remove_gravity_from_acc(self, acc_data, rot_data):\n                \"\"\"从加速度中移除重力（核心：设备动态匹配）\"\"\"\n                bs, seq_len, _ = acc_data.shape\n                device = acc_data.device  # ！修改2：获取输入设备（CUDA/CPU）\n                \n                valid_quats_normalized = rot_data / torch.norm(rot_data, dim=-1, keepdim=True).clamp(min=1e-8)\n                rotations = self.quat_to_rot_matrix(valid_quats_normalized)\n                \n                # ！修改3：gravity_world动态匹配输入设备，避免CPU/CUDA不兼容\n                gravity_world = self.gravity_world_val.to(device).expand(bs, seq_len, 3)\n                # 重力向量从世界坐标系转到传感器坐标系\n                gravity_sensor_frame = self.apply_rotation(\n                    self.rot_matrix_inverse(rotations),\n                    gravity_world\n                )\n                \n                # 线性加速度计算（设备与输入一致）\n                linear_accel = acc_data - gravity_sensor_frame\n                return linear_accel\n            \n            def calculate_angular_velocity_from_quat(self, rot_data):\n                \"\"\"从四元数计算角速度（设备动态匹配）\"\"\"\n                bs, seq_len, _ = rot_data.shape\n                device = rot_data.device  # ！修改4：获取输入设备\n                angular_vel = torch.zeros(bs, seq_len, 3, device=device)  # 零张量指定设备\n                \n                if seq_len < 2:\n                    return angular_vel\n                \n                # 四元数有效性判断（torch.tensor(0.0)改为匹配设备）\n                quat_norms = torch.norm(rot_data, dim=-1)\n                # ！修改5：用rot_data.new_zeros(1)创建同设备的0张量，替代硬编码的torch.tensor(0.0)\n                valid_mask = ~(torch.isnan(quat_norms) | torch.isclose(quat_norms, rot_data.new_zeros(1)))\n                valid_pairs_mask = valid_mask[:, :-1] & valid_mask[:, 1:]\n                \n                if torch.any(valid_pairs_mask):\n                    # 提取有效四元数对\n                    q_t = rot_data[:, :-1][valid_pairs_mask]\n                    q_t_plus_dt = rot_data[:, 1:][valid_pairs_mask]\n                    \n                    # 归一化\n                    q_t_norms = quat_norms[:, :-1][valid_pairs_mask].unsqueeze(-1)\n                    q_t_plus_dt_norms = quat_norms[:, 1:][valid_pairs_mask].unsqueeze(-1)\n                    q_t_norm = q_t / q_t_norms.clamp(min=1e-8)\n                    q_t_plus_dt_norm = q_t_plus_dt / q_t_plus_dt_norms.clamp(min=1e-8)\n                    \n                    # 旋转矩阵与相对旋转计算\n                    rot_t = self.quat_to_rot_matrix(q_t_norm)\n                    rot_t_plus_dt = self.quat_to_rot_matrix(q_t_plus_dt_norm)\n                    delta_rot = self.rot_matrix_multiply(self.rot_matrix_inverse(rot_t), rot_t_plus_dt)\n                    \n                    # 罗德里格斯公式求旋转向量（设备自动匹配）\n                    trace = delta_rot[..., 0, 0] + delta_rot[..., 1, 1] + delta_rot[..., 2, 2]\n                    theta = torch.acos(torch.clamp((trace - 1) / 2, -1.0, 1.0))\n                    sin_theta = torch.sin(theta)\n                    \n                    # 旋转向量计算（零张量指定设备）\n                    rot_vec = torch.zeros_like(q_t_norm[..., :3], device=device)\n                    # ！修改6：同修改5，避免设备不兼容\n                    mask = ~torch.isclose(sin_theta, rot_data.new_zeros(1))\n                    \n                    if torch.any(mask):\n                        factor = theta / (2 * sin_theta)\n                        rot_vec[mask] = factor[mask, None] * torch.stack([\n                            delta_rot[mask, 2, 1] - delta_rot[mask, 1, 2],\n                            delta_rot[mask, 0, 2] - delta_rot[mask, 2, 0],\n                            delta_rot[mask, 1, 0] - delta_rot[mask, 0, 1]\n                        ], dim=1)\n                    \n                    # 角速度计算\n                    angular_vel[:, :-1][valid_pairs_mask] = rot_vec / self.time_delta\n                \n                # 最后一个时间步复制前一个值\n                if seq_len > 1:\n                    angular_vel[:, -1] = angular_vel[:, -2]\n                \n                return angular_vel\n            \n            def calculate_angular_distance(self, rot_data, cumulative=False):\n                \"\"\"计算角距离（设备动态匹配）\"\"\"\n                bs, seq_len, _ = rot_data.shape\n                device = rot_data.device  # ！修改7：获取输入设备\n                angular_dist = torch.zeros(bs, seq_len, 1, device=device)  # 零张量指定设备\n                \n                if seq_len < 2:\n                    return angular_dist\n                \n                # 四元数归一化\n                quat_norms = torch.norm(rot_data, dim=-1)\n                q1 = rot_data[:, :-1]\n                q2 = rot_data[:, 1:]\n                q1_norms = quat_norms[:, :-1].unsqueeze(-1)\n                q2_norms = quat_norms[:, 1:].unsqueeze(-1)\n                q1_norm = q1 / q1_norms.clamp(min=1e-8)\n                q2_norm = q2 / q2_norms.clamp(min=1e-8)\n                \n                # 相对旋转与角距离计算\n                r1 = self.quat_to_rot_matrix(q1_norm)\n                r2 = self.quat_to_rot_matrix(q2_norm)\n                relative_rotation = self.rot_matrix_multiply(self.rot_matrix_inverse(r1), r2)\n                \n                trace = relative_rotation[..., 0, 0] + relative_rotation[..., 1, 1] + relative_rotation[..., 2, 2]\n                theta = torch.acos(torch.clamp((trace - 1) / 2, -1.0, 1.0))\n                angular_dist[:, :-1, 0] = theta\n                \n                # 最后一个时间步处理\n                if seq_len > 1:\n                    angular_dist[:, -1] = angular_dist[:, -2] if cumulative else 0.0\n                \n                # 累积角距离（设备一致）\n                if cumulative:\n                    angular_dist = torch.cumsum(angular_dist, dim=1)\n                \n                return angular_dist\n            \n            def forward(self, x):\n                \"\"\"前向传播（自动适配CUDA/CPU输入）\"\"\"\n                # 分离加速度（前3维）和四元数（后4维）\n                acc_data = x[..., :3]\n                rot_data = x[..., 3:]\n                \n                # 计算三大特征（设备自动匹配输入）\n                linear_accel = self.remove_gravity_from_acc(acc_data, rot_data)\n                angular_vel = self.calculate_angular_velocity_from_quat(rot_data)\n                angular_dist = self.calculate_angular_distance(rot_data)\n                \n                # 拼接输出（设备与输入一致）\n                features = torch.cat([linear_accel, angular_vel, angular_dist], dim=-1)\n                return features\n        \n\n        \n        class ImuFeatureExtractor(nn.Module):\n            def __init__(self, ):\n                super().__init__()\n                k = 15\n                self.lpf_all = nn.Conv1d(7, 7, kernel_size=7, padding=7//2, groups=7, bias=False)\n        \n                self.lpf_acc  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n                self.lpf_gyro = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        \n                self.lpf_acc2  = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n                self.lpf_gyro2 = nn.Conv1d(3, 3, k, padding=k//2, groups=3, bias=False)\n        \n            def forward(self, imu):\n                # imu: \n                B, C, T = imu.shape\n                acc  = imu[:, 0:3, :]                 # acc_x, acc_y, acc_z\n                gyro = imu[:, 3:6, :]                 # gyro_x, gyro_y, gyro_z\n                extra = imu[:, 6:, :]\n        \n                # 1) magnitude\n                acc_mag  = torch.norm(acc,  dim=1, p=2, keepdim=True)          # (B,1,T)\n                gyro_mag = torch.norm(gyro, dim=1, p=2, keepdim=True)\n        \n                # 1.2) magnitude\n                acc2 = acc/acc_mag.clip(1e-12)\n                gyro2 = gyro/gyro_mag.clip(1e-12)\n        \n        \n                acc_lpf2  = self.lpf_acc2(acc2)\n                acc_hpf2  = acc2 - acc_lpf2\n                gyro_lpf2 = self.lpf_gyro2(gyro2)\n                gyro_hpf2 = gyro2 - gyro_lpf2\n                \n        \n                # 1.3) magnitude\n                acc_mag2  = torch.norm(acc,  dim=1, p=1, keepdim=True)          # (B,1,T)\n                gyro_mag2 = torch.norm(gyro, dim=1, p=1, keepdim=True)\n        \n                # 1.4) magnitude\n                acc3 = acc/acc_mag2.clip(1e-12)\n                gyro3 = gyro/gyro_mag2.clip(1e-12)\n        \n                # 2) jerk \n                jerk = F.pad(acc[:, :, 1:] - acc[:, :, :-1], (1,0))       # (B,3,T)\n                gyro_delta = F.pad(gyro[:, :, 1:] - gyro[:, :, :-1], (1,0))\n        \n                # 2) jerk level2\n                jerk2 = F.pad(acc[:, :, 2:] + acc[:, :, :-2] - acc[:, :, 1:-1] * 2, (1,1))       # (B,3,T)\n                gyro_delta2 = F.pad(gyro[:, :, 2:] + gyro[:, :, :-2] - gyro[:, :, 1:-1] * 2, (1,1))\n        \n                # 3) energy\n                acc_pow  = acc ** 2\n                gyro_pow = gyro ** 2\n        \n                # 4) LPF / HPF \n                acc_lpf  = self.lpf_acc(acc)\n                acc_hpf  = acc - acc_lpf\n                gyro_lpf = self.lpf_gyro(gyro)\n                gyro_hpf = gyro - gyro_lpf\n        \n        \n                imu_hpf = imu - self.lpf_all(imu)\n        \n                features = [\n                    acc, gyro,\n                    \n                    # acc2, gyro2,\n                    acc_mag, gyro_mag,\n                    \n                    acc3, gyro3,\n                    acc_mag2, gyro_mag2,\n                    \n                    jerk, gyro_delta,\n                    jerk2, gyro_delta2, \n                    \n                    acc_pow, gyro_pow,\n                    \n                    acc_lpf, acc_hpf,\n                    gyro_lpf, gyro_hpf,\n        \n                    acc_lpf2, acc_hpf2,\n                    gyro_lpf2, gyro_hpf2,\n        \n                    imu_hpf,\n        \n                    extra, imu.argsort(-1).argsort(-1)/128,\n                    \n                ]\n        \n                return torch.cat(features, dim=1)  # (B, C_out, T)\n                \n        class SEBlock(nn.Module):\n            def __init__(self, channels, reduction=8):\n                super().__init__()\n                self.squeeze = nn.AdaptiveAvgPool1d(1)\n                self.excitation = nn.Sequential(\n                    nn.Linear(channels, channels // reduction, bias=False),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(channels // reduction, channels, bias=False),\n                    nn.Sigmoid()\n                )\n            \n            def forward(self, x):\n                b, c, _ = x.size()\n                y = self.squeeze(x).view(b, c)\n                y = self.excitation(y).view(b, c, 1)\n                return x * y.expand_as(x)\n\n        class ResidualSECNNBlock(nn.Module):\n            def __init__(self, in_channels, out_channels, kernel_size, pool_size=2, dropout=0.3, weight_decay=1e-4):\n                super().__init__()\n                \n                # First conv block\n                self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n                self.bn1 = nn.BatchNorm1d(out_channels)\n                \n                # Second conv block\n                self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False)\n                self.bn2 = nn.BatchNorm1d(out_channels)\n                \n                # SE block\n                self.se = SEBlock(out_channels)\n                \n                # Shortcut connection\n                self.shortcut = nn.Sequential()\n                if in_channels != out_channels:\n                    self.shortcut = nn.Sequential(\n                        nn.Conv1d(in_channels, out_channels, 1, bias=False),\n                        nn.BatchNorm1d(out_channels)\n                    )\n                self.pool_size = pool_size\n                self.pool = nn.MaxPool1d(pool_size)\n                self.dropout = nn.Dropout(dropout)\n        \n                self.act = nn.ReLU()\n\n                self.gru = nn.GRU(out_channels, out_channels//2, batch_first=True, bidirectional=True)\n                \n            def forward(self, x):\n                shortcut = self.shortcut(x)\n                \n                # First conv\n                out = self.act(self.bn1(self.conv1(x)))\n                # Second conv\n                out = self.bn2(self.conv2(out))\n                \n                # SE block\n                out = self.se(out)\n                \n                # Add shortcut\n                \n                out += shortcut\n                \n                out = out + self.gru(out.transpose(1, 2))[0].transpose(1, 2)\n                out = self.act(out)\n\n                out = self.act(out)\n                \n                \n                # Pool and dropout\n                if self.pool_size>1:\n                    out = self.pool(out)\n                out = self.dropout(out)\n                \n                return out\n\n        class AttentionLayer(nn.Module):\n            def __init__(self, hidden_dim):\n                super().__init__()\n                self.attention = nn.Linear(hidden_dim, 1)\n                \n            def forward(self, x):\n                # x shape: (batch, seq_len, hidden_dim)\n                scores = torch.tanh(self.attention(x))  # (batch, seq_len, 1)\n                weights = F.softmax(scores.squeeze(-1), dim=1)  # (batch, seq_len)\n                context = torch.sum(x * weights.unsqueeze(-1), dim=1)  # (batch, hidden_dim)\n                return context\n\n\n        def get_gravity_torch(quat):\n            g=9.81\n             # 四元数旋转\n            x = quat[..., 0:1]  # rot_x\n            y = quat[..., 1:2]  # rot_y\n            z = quat[..., 2:3]  # rot_z\n            w = quat[..., 3:4]  # rot_w\n            g_x = 2 * g * (x * z - w * y)\n            g_y = 2 * g * (y * z + w * x)\n            g_z = g * (w**2 - x**2 - y**2 + z**2)\n            gravity = torch.concat([g_x, g_y, g_z], -1)\n            return gravity\n\n        tof_mode = self.tof_mode\n        \n        class TwoBranchModel(nn.Module):\n            def __init__(self, pad_len, imu_dim_raw, tof_dim, n_classes, dropouts=[0.3, 0.3, 0.3, 0.3, 0.4, 0.5, 0.3], feature_engineering=True, **kwargs):\n                super().__init__()\n                self.imu_fe1 = ImuFeatureExtractor(**kwargs)\n                self.imu_fe2 = ImuFeatureExtractor(**kwargs)\n                self.imu_fe3 = ImuFeatureExtractor(**kwargs)\n                \n                imu_dim = 32 + 1 + 14 + 7 + 6 + 6 + 7 \n\n                self.new_feat_module = MotionFeatureExtractor()\n                \n                self.imu_dim = imu_dim\n                self.tof_dim = tof_dim\n        \n                self.fir_nchan = 7\n                self.thm_nchan = 5\n                self.tof_nchan = 5 * (5 + 3 * tof_mode)\n        \n                weight_decay = 3e-3\n        \n                \n                # IMU deep branch\n                self.imu_block1 = ResidualSECNNBlock(imu_dim * 1, 160, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                self.imu_block2 = ResidualSECNNBlock(160, 256, 5, dropout=dropouts[1], pool_size=1, weight_decay=weight_decay)\n        \n                self.imu_block12 = ResidualSECNNBlock(imu_dim * 1, 160, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                self.imu_block22 = ResidualSECNNBlock(160, 256, 5, dropout=dropouts[1], pool_size=1, weight_decay=weight_decay)\n\n                self.thm_block = nn.Sequential(\n                    ResidualSECNNBlock(self.thm_nchan * 1, 32, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay),\n                    ResidualSECNNBlock(32, 256, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                )\n                \n                self.tof_block = nn.Sequential(\n                    ResidualSECNNBlock(self.tof_nchan * 1, 64, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay),\n                    ResidualSECNNBlock(64, 256, 5, dropout=dropouts[0], pool_size=1, weight_decay=weight_decay)\n                )\n                \n                self.emb_all = 256\n        \n                self.dropout1d = nn.Dropout1d(0.15)\n                \n                # BiLSTM\n                self.dim_lstm = 512\n                self.dim_encoder = self.dim_lstm * 2\n        \n                self.bilstm = nn.LSTM(self.emb_all, self.dim_lstm, num_layers=2, bidirectional=True, batch_first=True)\n            \n                self.lstm_dropout = nn.Dropout(dropouts[4])\n        \n                self.output2 = nn.Linear(self.dim_encoder, 5)\n                \n                # Dense layers\n            \n                self.dense1 = nn.Linear(self.dim_encoder * 2, 512, bias=False)\n                self.bn_dense1 = nn.BatchNorm1d(512)\n                self.drop1 = nn.Dropout(dropouts[5])\n                \n                self.dense2 = nn.Linear(512, 512, bias=False)\n                self.bn_dense2 = nn.BatchNorm1d(512)\n                self.drop2 = nn.Dropout(dropouts[6])\n        \n                self.output3 = nn.Linear(512, 5)\n                self.classifier = nn.Linear(512, n_classes * 4)\n        \n                self.scale = nn.Parameter(torch.ones((1, 256, 1)))\n                self.bias = nn.Parameter(torch.zeros((1, 256, 1)))\n        \n                self.scale2 = nn.Parameter(torch.ones((1, 256, 1)))\n                self.bias2 = nn.Parameter(torch.zeros((1, 256, 1)))\n        \n                self.scale3 = nn.Parameter(torch.ones((1, 512, 1)))\n                self.bias3 = nn.Parameter(torch.zeros((1, 512, 1)))\n        \n                self.scale4 = nn.Parameter(torch.ones((1, 512, 1)))\n                self.bias4 = nn.Parameter(torch.zeros((1, 512, 1)))\n\n                self.scale5 = nn.Parameter(torch.ones((1, 512, 1)))\n                self.bias5 = nn.Parameter(torch.zeros((1, 512, 1)))\n\n                self.scale6 = nn.Parameter(torch.ones((1, 512, 1)))\n                self.bias6 = nn.Parameter(torch.zeros((1, 512, 1)))\n        \n                self.act = nn.GELU()\n                \n            def forward(self, x, ):\n                # Split input\n                mask_all = (x.abs().max(-1)[0]!=0).float()[:,:,None]\n                mask_all_trans = mask_all.transpose(1, 2)\n                \n                imu = x[:, :, :self.fir_nchan] # (batch, imu_dim, seq_len)\n                imu2 = self.new_feat_module(imu)\n                imu2 = imu2[:,:,:7]\n\n                imu = imu.transpose(1, 2)\n                imu2 = imu2.transpose(1, 2)\n                \n                thm = x[:, :, self.fir_nchan:self.fir_nchan + self.thm_nchan].transpose(1, 2)  # (batch, thm_dim, seq_len)\n                tof = x[:, :, self.fir_nchan + self.thm_nchan:].transpose(1, 2)  # (batch, tof_dim, seq_len)\n        \n                imu = self.imu_fe1(imu)   # (B, imu_dim, T)\n                imu2 = self.imu_fe2(imu2)   # (B, imu_dim, T)\n                \n                imu = (imu * self.scale[:,:imu.shape[1],:] + self.bias[:,:imu.shape[1],:]) * mask_all.transpose(1, 2)\n                imu2 = (imu2 * self.scale2[:,:imu2.shape[1],:] + self.bias2[:,:imu2.shape[1],:]) * mask_all.transpose(1, 2)\n                \n                thm = (thm * self.scale5[:,:thm.shape[1],:]  + self.bias5[:,:thm.shape[1],:] ) * mask_all.transpose(1, 2)\n                tof = (tof * self.scale6[:,:tof.shape[1],:]  + self.bias6[:,:tof.shape[1],:] ) * mask_all.transpose(1, 2)\n        \n                thm = self.dropout1d(thm)\n                tof = self.dropout1d(tof)\n                imu = self.dropout1d(imu)\n                imu2 = self.dropout1d(imu2)\n                \n                thm = self.thm_block(thm)\n                tof = self.tof_block(tof)\n        \n                \n                # IMU branch\n                x1 = self.imu_block1(imu)\n                x1 = self.imu_block2(x1)\n        \n                x12 = self.imu_block12(imu2)\n                x12 = self.imu_block22(x12)\n                \n                x1 = (x1 + x12 + thm + tof)\n        \n                merged = x1.transpose(1, 2)  # (batch, seq_len, 256)\n                \n                # BiLSTM\n                lstm_out, _ = self.bilstm(merged)\n        \n                logits2 = self.output2(self.lstm_dropout(lstm_out))\n                \n                attended = torch.cat(((lstm_out).max(1)[0], (lstm_out).mean(1), ), -1)\n                attended = self.lstm_dropout(attended)\n                \n                \n                # Dense layers\n                x = self.act(self.bn_dense1(self.dense1(attended)))\n                x = self.drop1(x)\n                x = self.act(self.bn_dense2(self.dense2(x)))\n                x = self.drop2(x)\n                \n                # Classification\n                logits = (self.classifier(x))\n                logits3 = (self.output3(x))\n        \n                if not self.training:\n                    return logits.reshape(logits.shape[0], 4, 18).mean(1), logits3\n                \n                return logits, logits2, logits3\n\n\n        return TwoBranchModel(param_a, param_b, param_c, param_d)\n\n    def preprocess_sequence(self, df_seq: pd.DataFrame, feature_cols: list, scaler: StandardScaler):\n        \"\"\"Normalizes and cleans the time series sequence\"\"\"\n        mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n        return (mat).astype('float32')\n        \n    def pad_sequences_torch(self, sequences, maxlen, padding='pre', truncating='pre', value=0.0):\n        \"\"\"PyTorch equivalent of Keras pad_sequences\"\"\"\n        result = []\n        for seq in sequences:\n            if len(seq) >= maxlen:\n                if truncating == 'post':\n                    seq = seq[:maxlen]\n                else:  # 'pre'\n                    seq = seq[-maxlen:]\n            else:\n                pad_len = maxlen - len(seq)\n                if padding == 'post':\n                    seq = np.concatenate([seq, np.full((pad_len, seq.shape[1]), value)])\n                else:  # 'pre'\n                    seq = np.concatenate([np.full((pad_len, seq.shape[1]), value), seq])\n            result.append(seq)\n        return np.array(result, dtype=np.float32)\n        \n    def preprocess_left_handed(self, l_tr):\n        def handle_quaternion_missing_values(rot_data: np.ndarray) -> np.ndarray:\n            \"\"\"\n            Handle missing values in quaternion data intelligently\n            \n            Key insight: Quaternions must have unit length |q| = 1\n            If one component is missing, we can reconstruct it from the others\n            \"\"\"\n            rot_cleaned = rot_data.copy()\n            \n            for i in range(len(rot_data)):\n                row = rot_data[i]\n                missing_count = np.isnan(row).sum()\n                \n                if missing_count == 0:\n                    # No missing values, normalize to unit quaternion\n                    norm = np.linalg.norm(row)\n                    if norm > 1e-8:\n                        rot_cleaned[i] = row / norm\n                    else:\n                        rot_cleaned[i] = [0.0, 0.0, 0.0, 0.0]  # Identity quaternion\n                        \n                elif missing_count == 1:\n                    # One missing value, reconstruct using unit quaternion constraint\n                    # |w|² + |x|² + |y|² + |z|² = 1\n                    missing_idx = np.where(np.isnan(row))[0][0]\n                    valid_values = row[~np.isnan(row)]\n                    \n                    sum_squares = np.sum(valid_values**2)\n                    if sum_squares <= 1.0:\n                        missing_value = np.sqrt(max(0, 1.0 - sum_squares))\n                        # Choose sign for continuity with previous quaternion\n                        if i > 0 and not np.isnan(rot_cleaned[i-1, missing_idx]):\n                            if rot_cleaned[i-1, missing_idx] < 0:\n                                missing_value = -missing_value\n                        rot_cleaned[i, missing_idx] = missing_value\n                        rot_cleaned[i, ~np.isnan(row)] = valid_values\n                    else:\n                        rot_cleaned[i] = [0.0, 0.0, 0.0, 0.0]\n                else:\n                    # More than one missing value, use identity quaternion\n                    rot_cleaned[i] = [0.0, 0.0, 0.0, 0.0]\n            \n            return rot_cleaned\n    \n        rot_cleaned = handle_quaternion_missing_values(l_tr[[\"rot_w\",\"rot_x\", \"rot_y\", \"rot_z\"]].to_numpy())\n        rot_scipy = rot_cleaned[:, [1, 2, 3, 0]]\n        \n        norms = np.linalg.norm(rot_scipy, axis=1)\n        if np.any(norms < 1e-8):\n            # Replace problematic quaternions with identity\n            mask = norms < 1e-8\n            rot_scipy[mask] = [0.0, 0.0, 0.0, 1.0]  # Identity quaternion in scipy format\n        \n        r = R.from_quat(rot_scipy)\n        tmp = r.as_euler(\"xyz\")\n        tmp[:,1] = - tmp[:,1]\n        tmp[:,2] = - tmp[:,2] \n        r = R.from_euler(\"xyz\", tmp)\n        tmp = r.as_quat()\n        \n        if np.any(norms < 1e-8):\n            mask = norms < 1e-8\n            tmp[mask] = [0.0, 0.0, 0.0, 0.0]\n        \n        l_tr = l_tr.with_columns(pl.DataFrame(tmp, schema=[\"rot_x\", \"rot_y\", \"rot_z\", \"rot_w\"]))\n        l_tr = l_tr.with_columns(-pl.col(\"acc_x\"))\n        \n        tmp = l_tr[[\"thm_3\", \"thm_5\"]]\n        tmp.columns = [\"thm_5\", \"thm_3\"]\n        l_tr = l_tr.with_columns(tmp)\n        \n        swap_1_2_4_base = [[0,7],[1,6],[2,5],[3,4], [4,3], [5,2],[6,1],[7,0]]\n        swap_3_5_base = [[0,56],[8,48],[16,40], [24,32],[32,24], [40,16],[48,8], [56,0]]\n        \n        swap_1_2_4 = list()\n        for i in range(0,64,8):\n            ll = list()\n            for (k,l) in swap_1_2_4_base:\n                ll.append([k+i, l+i])\n            swap_1_2_4 += ll\n        \n        swap_3_5 = list()\n        for i in range(8):\n            ll = list()\n            for (k,l) in swap_3_5_base:\n                ll.append([k+i, l+i])\n            swap_3_5 += ll\n        \n        l_df = l_tr\n        \n        for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n            l_tr = l_tr.with_columns(l_df[k].alias(l))\n        \n        for (k,l) in zip([\"tof_3_v\" + str(x) for x in range(64)], [\"tof_5_v\" + str(x) for x in range(64)]):\n            l_tr = l_tr.with_columns(l_df[l].alias(k))\n        \n        l_df = l_tr\n        \n        for i in [1,2,4]:\n            for (k, l) in swap_1_2_4:\n                l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n        \n        for i in [3,5]:\n            for (k, l) in swap_3_5:\n                l_tr = l_tr.with_columns(l_df[\"tof_\" + str(i) + \"_v\"+str(k)].alias(\"tof_\" + str(i) + \"_v\"+str(l)))\n        return l_tr\n        \n    def train(self, ):\n        class CMI3Dataset(Dataset):\n            def __init__(self,\n                         X_list,\n                         y_list, y_list2, y_list3,\n                         maxlen,\n                         mode=\"train\",\n                         imu_dim=7,\n                         augment=None,\n                         epoch_multiplier=1,\n                        ):\n                self.X_list = X_list\n                self.mode = mode\n                self.y_list = y_list\n                self.y_list2 = y_list2\n                self.y_list3 = y_list3\n                self.maxlen = maxlen\n                self.imu_dim = imu_dim     \n                self.augment = augment\n                self.epoch_multiplier = epoch_multiplier\n                \n            def __getitem__(self, index):\n                X = self.X_list[index//self.epoch_multiplier]\n                y = self.y_list[index//self.epoch_multiplier]\n                y2 = self.y_list2[index//self.epoch_multiplier]\n                y3 = self.y_list3[index//self.epoch_multiplier]\n\n                if self.mode=='train':\n                        X_ = np.concatenate([X, y2], -1)\n        \n                        X_ = transforms_custom(X_)\n        \n                        X = X_[:,:X.shape[-1]]\n                        y2 = X_[:,X.shape[-1]:]\n    \n                        X[:,3:7] = X[:,3:7]/(np.sqrt((X[:,3:7]**2).sum(-1))+1e-6)[:,None]\n            \n                return X, y, y2, y3\n            \n            def __len__(self):\n                return len(self.X_list) * self.epoch_multiplier\n\n        class EMA:\n            def __init__(self, model, decay=0.999):\n                self.decay = decay\n                self.shadow = {}\n                self.backup = {}\n        \n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        self.shadow[name] = param.data.clone()\n        \n            def update(self, model):\n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        assert name in self.shadow\n                        new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n                        self.shadow[name] = new_average.clone()\n        \n            def apply_shadow(self, model):\n                self.backup = {}\n                for name, param in model.named_parameters():\n                    if param.requires_grad:\n                        self.backup[name] = param.data.clone()\n                        param.data = self.shadow[name]\n        \n            def restore(self, model):\n                for name, param in model.named_parameters():\n                    if param.requires_grad and name in self.backup:\n                        param.data = self.backup[name]\n                self.backup = {}\n\n        def set_seed(seed: int = 42):\n            import numpy as np\n            \n            random.seed(seed)\n        \n            os.environ['PYTHONHASHSEED'] = str(seed)\n        \n            np.random.seed(seed)\n        \n            torch.manual_seed(seed)\n            torch.cuda.manual_seed(seed)\n            torch.cuda.manual_seed_all(seed) \n            # torch.backends.cudnn.deterministic = True\n            # torch.backends.cudnn.benchmark = False\n            # torch.use_deterministic_algorithms(True)\n        \n        set_seed(self.SEED)\n\n        class RDROPLoss(nn.Module):\n            \"\"\"\n            RDROP损失函数实现\n            结合原始损失和KL散度约束\n            \"\"\"\n            def __init__(self, alpha=0.5):\n                super(RDROPLoss, self).__init__()\n                self.alpha = alpha  # KL损失的权重系数\n                self.kl_div = nn.KLDivLoss(reduction='batchmean')\n        \n            def forward(self, logits1, logits2):\n                # KL散度约束：两次次输出分布的一致性\n                p1 = F.log_softmax(logits1, dim=1)\n                p2 = F.softmax(logits2, dim=1)\n                kl_loss1 = self.kl_div(p1, p2)\n                \n                p2 = F.log_softmax(logits2, dim=1)\n                p1 = F.softmax(logits1, dim=1)\n                kl_loss2 = self.kl_div(p2, p1)\n                \n                # 总损失 = 分类损失 + alpha * KL散度损失\n                total_loss = self.alpha * (kl_loss1 + kl_loss2)\n                return total_loss\n                \n        import numpy as np\n        import pandas as pd\n        from scipy.spatial.transform import Rotation as R\n        from tqdm.auto import tqdm \n        \n        print(\"▶ TRAIN MODE – loading dataset …\")\n        df = pd.read_csv(self.RAW_DIR / \"train.csv\")\n        self.demo = pd.read_csv(self.RAW_DIR / \"train_demographics.csv\")\n\n\n\n        \n        group_list = []\n        for _, group in tqdm(df.groupby('sequence_id')):\n            index_old = group.index\n            if self.demo[self.demo['subject']==group['subject'].values[0]]['handedness'].values[0] ==0:\n                ###################################################################################\n                group = self.preprocess_left_handed(pl.from_pandas(group)).to_pandas()\n                group.index = index_old\n                \n                group_list.append(group)\n        df.update(pd.concat(group_list))\n\n\n        \n    \n        dict_ = dict(zip(df['subject'].unique(), list(range(df['subject'].nunique()))))\n        df['subject_id_new'] = df['subject'].map(dict_)\n    \n        #df = df[~df['subject'].isin({'SUBJ_045235', 'SUBJ_019262'})]\n    \n        dict_behavior = {'Relaxes and moves hand to target location': 1,\n                         'Hand at target location': 2,\n                         'Performs gesture': 3,\n                         'Moves hand to target location': 4}\n        \n        dict_orientation = {\n                            'Lie on Back': 0,\n                            'Lie on Side - Non Dominant': 1,\n                            'Seated Lean Non Dom - FACE DOWN': 2,\n                            'Seated Straight': 3,\n                           }\n    \n        df['bid'] = df['behavior'].map(dict_behavior)\n        df['oid'] = df['orientation'].map(dict_orientation)\n    \n        df, new_feat_cols, new_feat_cols2 = self.get_new_features(df)\n    \n        # Label encoding\n        le = LabelEncoder()\n        df['gesture_int'] = le.fit_transform(df['gesture'])\n\n\n        df['gesture_int'] = df['gesture_int'] + df['oid'] * 18\n\n        \n        np.save(self.EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n    \n        # Feature list\n        meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n                     'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter', 'subject_id_new'}\n        feature_cols = [c for c in df.columns if c not in meta_cols]\n        imu_cols = [c for c in feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n        # tof_cols = [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n    \n        thm_cols = [c for c in feature_cols if c.startswith('thm_')]\n        print(thm_cols)\n        \n        tof_cols = [] # [c for c in feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n    \n        imu_cols = ['acc_x', 'acc_y', 'acc_z', 'rot_x', 'rot_y', 'rot_z', 'rot_w',]\n        \n        feature_cols = imu_cols + new_feat_cols + thm_cols + new_feat_cols2\n        \n        print(f\"  IMU {len(imu_cols)+len(new_feat_cols)} | THM {len(thm_cols)} | TOF {len(new_feat_cols2)}  | total {len(feature_cols)} features\")\n    \n        # Save feature_cols\n        np.save(self.EXPORT_DIR / \"feature_cols.npy\", np.array(feature_cols))\n        pad_len = self.PAD_PERCENTILE\n        \n        # Group sequences\n        seq_gp = df.groupby('sequence_id')\n        X_list_raw, y_list, id_list, subject_list, y2list, y3list = [], [], [], [], [], []\n        for seq_id, seq in seq_gp:\n            mat = seq[feature_cols].ffill().bfill().fillna(0).values\n            X_list_raw.append(mat)\n            y_list.append(seq['gesture_int'].iloc[0])\n            id_list.append(seq_id)\n            subject_list.append(seq['subject_id_new'].iloc[0])\n    \n            if len(seq) < pad_len:\n                bid = np.zeros(pad_len)\n                bid[-len(seq):] = seq['bid'].values.ravel()\n            else:\n                bid = seq['bid'].values.ravel()[-pad_len:]\n            \n            y2list.append(bid)\n            y3list.append(seq['oid'].iloc[0])\n    \n        pad_len = self.PAD_PERCENTILE\n        np.save(self.EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n    \n        id_list = np.array(id_list)\n        y_list_all = np.eye(4 * len(le.classes_))[y_list].astype(np.float32)  # one-hot\n    \n        y_list_all2 = np.vstack(y2list).astype(int)\n        y_list_all2 = (np.eye(5)[y_list_all2.reshape(-1, 1)]).reshape(-1, pad_len, 5).astype(np.float32)\n        y_list_all3 = np.eye(5)[y3list].astype(np.float32)\n    \n        augmenter = None\n        metrics = []\n    \n        criterion_rdrop = RDROPLoss(alpha=0.5)\n\n        from sklearn.model_selection import GroupKFold\n        gkf = GroupKFold(\n                         n_splits=self.FOLDS, \n                         shuffle=True, \n                         random_state=self.random_state\n                        )\n    \n        def clipped_cross_entropy(logits, y, clipval=0.6, num=18):\n            return -torch.sum(F.log_softmax(logits, dim=1) * y.clip((1-clipval)/num, clipval), dim=1).mean() \n\n            # return 1 - (logits.softmax(-1) * y).mean()\n            \n        idlistall = []\n        targetfinalall = []\n        predimuonlyall = []\n        predallfeatall = []\n        predorientationall = []\n        targetsorientations = []\n        foldlistall = []\n        for fold, (train_idx, val_idx) in enumerate(gkf.split(id_list, id_list, groups=subject_list)):\n            \n        # skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=self.random_state)\n        # for fold, (train_idx, val_idx) in enumerate(skf.split(id_list, np.argmax(y_list_all, axis=1))):  \n            \n            if fold not in self.TRAIN_FOLDS:\n                continue\n    \n            print(f\"\\n▶ Fold {fold}\")\n            \n            X_list_scaled = [x for x in X_list_raw]\n            X_list_all = self.pad_sequences_torch(X_list_scaled, maxlen=pad_len, padding='pre', truncating='pre')\n    \n            # Prepare train/val sets\n            train_list = X_list_all[train_idx]\n            train_y_list = y_list_all[train_idx]\n            train_y_list2 = y_list_all2[train_idx]\n            train_y_list3 = y_list_all3[train_idx]\n    \n            \n            val_list = X_list_all[val_idx]\n            val_y_list = y_list_all[val_idx]\n    \n            val_y_list2 = y_list_all2[val_idx]\n            val_y_list3 = y_list_all3[val_idx]\n\n            id_list_valid = id_list[val_idx]\n\n            print(len(id_list_valid))\n            idlistall.append(id_list_valid)\n            foldlistall.append([fold for _ in range(len(id_list_valid))])\n    \n            # Data loaders\n            train_dataset = CMI3Dataset(train_list, train_y_list, train_y_list2, train_y_list3, pad_len, mode=\"train\", imu_dim=len(imu_cols),\n                                        augment=augmenter)\n            train_loader = DataLoader(train_dataset, batch_size=self.BATCH_SIZE, shuffle=True, num_workers=6, drop_last=False, pin_memory=True)\n            \n            val_dataset = CMI3Dataset(val_list, val_y_list, val_y_list2, val_y_list3, pad_len, mode=\"val\")\n            val_loader = DataLoader(val_dataset, batch_size=self.BATCH_SIZE, shuffle=False, num_workers=6, drop_last=False, pin_memory=True)\n\n            device = self.device\n            \n            # Model & EMA \n            model = self.create_model(pad_len, len(imu_cols), len(tof_cols), len(le.classes_)).to(device)\n            model2 = self.create_model(pad_len, len(imu_cols), len(tof_cols), len(le.classes_)).to(device)\n\n            if self.VALIDATION==True:\n                checkpoint = torch.load(self.PRETRAINED_DIR / f'gesture_two_branch_fold{fold}.pth', map_location=device)\n                model.load_state_dict({k.replace('_orig_mod.', ''):v for k, v in checkpoint['model_state_dict'].items()})\n            \n            ema = EMA(model, decay=0.998)\n    \n            # Optimizer\n            hidden_weights = [p for p in model.parameters() if p.ndim >= 2 and p.requires_grad]\n            hidden_gains_biases = [p for p in model.parameters() if p.ndim < 2 and p.requires_grad]\n            param_groups = [\n                dict(params=hidden_weights, use_muon=True, lr=0.005, weight_decay=self.WD),\n                dict(params=hidden_gains_biases, use_muon=False, lr=self.LR_INIT, betas=(0.9, 0.95), weight_decay=self.WD),\n            ]\n            optimizer = SingleDeviceMuonWithAuxAdam(param_groups)\n\n            hidden_weights2 = [p for p in model2.parameters() if p.ndim >= 2 and p.requires_grad]\n            hidden_gains_biases2 = [p for p in model2.parameters() if p.ndim < 2 and p.requires_grad]\n            param_groups2 = [\n                dict(params=hidden_weights2, use_muon=True, lr=0.005, weight_decay=self.WD),\n                dict(params=hidden_gains_biases2, use_muon=False, lr=self.LR_INIT, betas=(0.9, 0.95), weight_decay=self.WD),\n            ]\n            optimizer2 = SingleDeviceMuonWithAuxAdam(param_groups2)\n    \n            nbatch = len(train_loader)\n            nsteps = self.EPOCHS * nbatch\n    \n            scheduler = ConstantCosineLR(optimizer, nsteps, 0.)    \n            print(\"▶ Starting training...\")\n    \n            best_val_acc = 0\n            for epoch in tqdm(range(self.EPOCHS)):\n                model.train()\n                model2.train()\n                \n                train_preds, train_targets = [], []\n                train_loss = 0.0\n    \n                for X, y, y2, y3 in train_loader:\n                    if self.VALIDATION==True:\n                        break\n                        \n                    BS = X.shape[0]\n                    X0 = X.clone()\n\n                    X[BS//8:,:,7:] = 0.\n\n                    if np.random.random() > 0.5:\n                        X[:BS//8*2,:,3:7] = 0.\n                    else:\n                        X[:BS//8*2,:,:3] = 0.\n                    \n                    X, y = X.float().to(device), y.to(device)\n                    y2, y3 = y2.float().to(device), y3.to(device)\n                    X0 = X0.float().to(device)\n                    \n                    optimizer.zero_grad()\n                    optimizer2.zero_grad()\n                    \n                    LEN = 1200 + np.random.randint(80)\n                    \n                    logits, logits2, logits3 = model(X[:,-LEN:])\n                    \n                    logits_, logits2_, logits3_ = model2(X0[:,-LEN:])\n    \n                    clipval = 0.6\n                    loss = clipped_cross_entropy(logits, y, clipval, 18) \n                    loss += clipped_cross_entropy(logits2, y2[:,-LEN:], clipval, 5)  * 0.5\n                    loss += clipped_cross_entropy(logits3, y3, clipval, 5)  * 0.5\n\n                    clipval = 0.6\n                    loss2 = clipped_cross_entropy(logits_, y, clipval, 18) \n                    loss2 += clipped_cross_entropy(logits2_, y2[:,-LEN:], clipval, 5)  * 0.5\n                    loss2 += clipped_cross_entropy(logits3_, y3, clipval, 5)  * 0.5\n\n                    if epoch > 40:\n                        loss = loss + loss2 + criterion_rdrop(logits, logits_)\n                    else:\n                        loss = loss + loss2 \n                    \n                    loss.backward()\n                    \n                    optimizer.step()\n                    optimizer2.step()\n                    \n                    ema.update(model)\n    \n                    train_preds.append(logits.argmax(dim=1).cpu().numpy())\n                    train_targets.append(y.argmax(dim=1).cpu().numpy())\n    \n                    scheduler.step()\n                    train_loss += loss.item()\n\n                model2.eval()\n                model.eval()\n                ema.apply_shadow(model)\n                \n                val_loss = 0.0\n                val_preds_accmask, val_targets_accmask = [], []\n                val_preds_imuonly, val_targets_imuonly = [], []\n                val_preds_rotmask, val_targets_rotmask = [], []\n\n                val_preds_mother, val_targets_rotmask = [], []\n\n                val_preds_logits = []\n                val_preds_imuonly_logits = []\n\n                val_preds_orientation, val_targets_orientation = [], []\n                val_preds_orientation_logits = []\n                \n                \n                with torch.inference_mode():\n                    for X, y, y2, y3 in val_loader:\n                        X_imuonly = X[:].clone()\n                        X_imuonly[:, :, 7:] = 0.0\n\n                        X_accmask = X[:].clone()\n                        X_accmask[:, :, 7:] = 0.0\n                        X_accmask[:, :, 0:3] = 0.0\n\n                        X_rotmask = X[:].clone()\n                        X_rotmask[:, :, 7:] = 0.0\n                        X_rotmask[:, :, 3:7] = 0.0\n                    \n                        X, y = X.float().to(device), y.to(device)\n                        X_imuonly = X_imuonly.float().to(device)\n                        X_accmask = X_accmask.float().to(device)\n                        X_rotmask = X_rotmask.float().to(device)\n\n                        logits_mother, logits_orientation = model(X)\n                        \n                        logits_rotmask, _  = model(X_rotmask)\n                        logits_accmask, _  = model(X_accmask)\n                        logits_imuonly, _  = model(X_imuonly)\n\n                        val_preds_mother.append(logits_mother.argmax(dim=1).cpu().numpy())\n                        val_preds_accmask.append(logits_accmask.argmax(dim=1).cpu().numpy())\n                        val_preds_rotmask.append(logits_rotmask.argmax(dim=1).cpu().numpy())\n                        val_preds_imuonly.append(logits_imuonly.argmax(dim=1).cpu().numpy())\n                        \n                        val_preds_logits.append(logits_mother.cpu().numpy())\n                        val_preds_imuonly_logits.append(logits_imuonly.cpu().numpy())\n                        \n                        val_targets_imuonly.append(y.reshape(y.shape[0], 4, 18).sum(1).argmax(dim=1).cpu().numpy())\n\n\n                        val_preds_orientation_logits.append(logits_orientation.cpu().numpy())\n                        val_preds_orientation.append(logits_orientation.argmax(dim=1).cpu().numpy())\n                        val_targets_orientation.append(y3.argmax(dim=1).cpu().numpy())\n    \n    \n                if len(train_targets) >= 0:\n                    train_acc = 0.\n                    try:\n                        train_acc = CompetitionMetric().calculate_hierarchical_f1(\n                            pd.DataFrame({'gesture': le.classes_[np.concatenate(train_targets)]}),\n                            pd.DataFrame({'gesture': le.classes_[np.concatenate(train_preds)]})\n                        )\n                    except:\n                        pass\n                    val_acc_rotmask = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_imuonly)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_rotmask)]})\n                    )\n                    val_acc_imuonly = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_imuonly)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_imuonly)]})\n                    )\n                    val_acc_accmask = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_imuonly)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_accmask)]})\n                    )\n                    val_acc_mother = CompetitionMetric().calculate_hierarchical_f1(\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_targets_imuonly)]}),\n                        pd.DataFrame({'gesture': le.classes_[np.concatenate(val_preds_mother)]})\n                    )\n\n                    val_acc_orientation = np.mean(\n                        np.concatenate(val_preds_orientation)==np.concatenate(val_targets_orientation)\n                    )\n                    \n                    train_loss = np.mean(train_loss)\n                    print('epoch', epoch, 'loss : ', round(train_loss, 4), '| TRAIN : ', round(train_acc, 4), '| ORIENTATION: ', round(val_acc_orientation, 4), '| IMUONLY : ', round(val_acc_imuonly, 4), '| ROTMASK : ', round(val_acc_rotmask, 4),  '| ACCMASK : ', round(val_acc_accmask, 4),  '| MOTHER : ', round(val_acc_mother, 4), '| LR : ', optimizer.param_groups[0]['lr'])\n    \n                    metric = val_acc_orientation # val_acc\n                    \n                    if metric > best_val_acc:\n                        best_val_acc = metric\n                        # Save model\n                        torch.save({\n                            'model_state_dict': model.state_dict(),\n                            'imu_dim': len(imu_cols),\n                            'tof_dim': len(tof_cols),\n                            'n_classes': len(le.classes_),\n                            'pad_len': pad_len,\n                            \n                        }, self.EXPORT_DIR / f\"gesture_two_branch_fold{fold}.pth\")\n                        print(f\"fold: {fold} val_all_acc: {metric:.4f}\")\n                        print(\"✔ Training done – artefacts saved in\", self.EXPORT_DIR)\n                    \n                    ema.restore(model)\n\n                targetfinalall.append(np.concatenate(val_targets_imuonly))\n                predimuonlyall.append(np.concatenate(val_preds_imuonly_logits, 0))\n                predallfeatall.append(np.concatenate(val_preds_logits, 0))\n                predorientationall.append(np.concatenate(val_preds_orientation_logits, 0))\n                targetsorientations.append(np.concatenate(val_targets_orientation))\n                if self.VALIDATION:\n                    break\n                \n            \n            ema.apply_shadow(model)\n            metrics.append(best_val_acc)\n\n        print(metrics, sum(metrics)/len(metrics))\n\n        import joblib\n        name = str(self.PRETRAINED_DIR).replace('/', '_')\n        joblib.dump(\n            {\n                'guestures': le.classes_, \n                'pred_all': np.concatenate(predallfeatall, 0), \n                'pred_imuonly': np.concatenate(predimuonlyall, 0), \n                'targets': np.concatenate(targetfinalall), \n                'idlist': np.concatenate(idlistall),\n                'fold': np.concatenate(foldlistall),\n                'pred_orientation' : np.concatenate(predorientationall, 0),\n                'target_orientation' : np.concatenate(targetsorientations), \n            }, \n                    f\"oof_{name}.joblib\", \n                   )\n\n        return le.classes_, np.concatenate(predallfeatall, 0), np.concatenate(predimuonlyall, 0), np.concatenate(targetfinalall), np.concatenate(idlistall), np.concatenate(predorientationall, 0), np.concatenate(targetsorientations)\n        \n        \n    def get_new_features(self, df):\n        feature_names = []\n        \n        for col in ['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']:\n            df[col] = df[col] / 5.                                                                                                                                             \n        \n        new_columns = {} \n        for i in range(1, 6):\n            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]\n            \n            new_columns.update({\n                f'tof_{i}_isna_mean1': (df[pixel_cols]==-1).mean(axis=1),\n                f'tof_{i}_isna_mean2': 1 - (df[pixel_cols].isna()).mean(axis=1),\n            })\n    \n            df[pixel_cols] = 6 - df[pixel_cols].replace(-1, 255.) / 50. \n            \n            tof_data = df[pixel_cols]\n    \n            new_columns.update({\n                f'tof_{i}_mean': tof_data.mean(axis=1),\n                f'tof_{i}_std': tof_data.std(axis=1),\n                # f'tof_{i}_min': tof_data.min(axis=1),\n                f'tof_{i}_max': tof_data.max(axis=1),\n                \n                # f'tof_{i}_median_norm': tof_data.median(axis=1)/tof_data.mean(axis=1).clip(1),\n                # f'tof_{i}_max_norm': tof_data.min(axis=1)/tof_data.mean(axis=1).clip(1),\n                # f'tof_{i}_min_norm': tof_data.max(axis=1)/tof_data.mean(axis=1).clip(1),\n            })\n            if self.tof_mode > 1:\n                region_size = 64 // self.tof_mode\n                for r in (range(self.tof_mode)):\n                    region_data = tof_data.iloc[:, r*region_size : (r+1)*region_size]\n                    new_columns.update({\n                        f'tof{self.tof_mode}_{i}_region_{r}_mean': region_data.mean(axis=1),\n                        f'tof{self.tof_mode}_{i}_region_{r}_std': region_data.std(axis=1),\n                        # f'tof{self.tof_mode}_{i}_region_{r}_min': region_data.min(axis=1),\n                        f'tof{self.tof_mode}_{i}_region_{r}_max': region_data.max(axis=1),\n                    })\n                    \n        df_tof = pd.DataFrame(new_columns)\n        df = pd.concat([df, df_tof], axis=1)\n    \n        \n        return df, feature_names, list(df_tof.columns)\n        \n\n    def get_model(self, ):    \n        print(\"▶ INFERENCE MODE – loading artefacts from\", self.PRETRAINED_DIR)\n        self.feature_cols = np.load(self.PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n        self.pad_len = int(np.load(self.PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n        self.gesture_classes = np.load(self.PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n    \n        self.imu_cols = [c for c in self.feature_cols if not (c.startswith('thm_') or c.startswith('tof_'))]\n        self.tof_cols = [c for c in self.feature_cols if c.startswith('thm_') or c.startswith('tof_')]\n        # Load model\n        MODELS = [f'gesture_two_branch_fold{i}.pth' for i in range(self.FOLDS) if i in self.TRAIN_FOLDS]\n        \n        self.models = []\n        for path in MODELS:\n            checkpoint = torch.load(self.PRETRAINED_DIR / path, map_location=self.device)\n            \n            model = self.create_model(\n                checkpoint['pad_len'], \n                checkpoint['imu_dim'], \n                checkpoint['tof_dim'], \n                checkpoint['n_classes']\n                ).to(self.device)\n    \n            \n            \n            model.load_state_dict({k.replace('_orig_mod.', ''):v for k, v in checkpoint['model_state_dict'].items()})\n            model.eval()\n            self.models.append(model)\n    \n        print(\"  model, scaler, pads loaded – ready for evaluation\")\n    \n        return \n    \n    def predict(self, sequence: pl.DataFrame, demographics: pl.DataFrame, nanratio = 0):         \n        if demographics[0, \"handedness\"] == 0: \n            sequence = self.preprocess_left_handed(sequence)\n        \n        df_seq = sequence.to_pandas()\n        df_seq, _, _ = self.get_new_features(df_seq)\n        \n        with torch.no_grad():\n            outputs = None\n            outputs2 = None\n            \n            mat = self.preprocess_sequence(df_seq, self.feature_cols, None)\n            pad = self.pad_sequences_torch([mat], maxlen=self.pad_len, padding='pre', truncating='pre')\n            x = torch.FloatTensor(pad).float().to(self.device)\n\n            if nanratio==1:\n                x[:,:,7:] = 0.\n            \n            for model in self.models:\n                model.eval()\n                p, p2 = model(x)\n                if outputs is None: \n                    outputs = p\n                    outputs2 = p2\n                else: \n                    outputs += p\n                    outputs2 += p2\n                    \n            outputs /= len(self.models)\n            outputs2 /= len(self.models)\n\n        return self.gesture_classes, (outputs.cpu().numpy(), outputs2.cpu().numpy()[:,:4])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for local training, prepare all the data under ./cmi-detect-behavior-with-sensor-data/ folder\n\nmodel_zhou_inference_v26_1 = model_zhou_v26('/kaggle/input/cmi3v90', 42, './42')\n\nmodel_zhou_inference_v26_1.TRAIN_FOLDS = [0, 1, 2, 3, 4, ]\nmodel_zhou_inference_v26_1.VALIDATION = False\nmodel_zhou_inference_v26_1.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for seed in [\n#              # 42,\n#              6665252, \n#              # 88885252, \n#              #12345252, \n#              #325252,\n#              #885252,\n#              #99995252,\n#              #115252,\n#             ]:\n#     model_zhou_inference_v0 = model_zhou_v15(f'./{seed}', seed=seed, save_path=f'./{seed}')\n    \n#     model_zhou_inference_v0.TRAIN_FOLDS = [0, 1, 2, 3, 4]\n\n#     model_zhou_inference_v0.VALIDATION = False\n    \n#     model_zhou_inference_v0.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}